{
    "repository": "scrapy/scrapyd",
    "clone_url": "https://github.com/scrapy/scrapyd.git",
    "timestamp": "2023-05-29T14:42:32.794806Z",
    "clone_success": true,
    "number of actions": 3,
    "number_of_test_actions": 1,
    "actions_successful": false,
    "actions_stdout": "[Tests/tests] \ud83d\ude80  Start image=crawlergpt:latest\n[Tests/tests]   \ud83d\udc33  docker pull image=crawlergpt:latest platform= username= forcePull=false\n[Tests/tests]   \ud83d\udc33  docker create image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[Tests/tests]   \ud83d\udc33  docker run image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[Tests/tests]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1000 /tmp/de65f406-fe28-11ed-a890-af2cc187fc11/scrapy-scrapyd] user=0 workdir=\n[Tests/tests]   \u2601  git clone 'https://github.com/actions/setup-python' # ref=v2\n[Tests/tests]   \u2601  git clone 'https://github.com/codecov/codecov-action' # ref=v2\n[Tests/tests] \ud83e\uddea  Matrix: map[python-version:3.7]\n[Tests/tests] \u2b50 Run Main actions/checkout@v2\n[Tests/tests]   \u2705  Success - Main actions/checkout@v2\n[Tests/tests] \u2b50 Run Main Set up Python 3.7\n[Tests/tests]   \ud83d\udc33  docker cp src=/home/andre-silva/.cache/act/actions-setup-python@v2/ dst=/var/run/act/actions/actions-setup-python@v2/\n[Tests/tests]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1000 /var/run/act/actions/actions-setup-python@v2/] user=0 workdir=\n[Tests/tests]   \ud83d\udc33  docker exec cmd=[node /var/run/act/actions/actions-setup-python@v2/dist/setup/index.js] user= workdir=\n[Tests/tests]   \ud83d\udcac  ::debug::Semantic version spec of 3.7 is 3.7\n[Tests/tests]   \ud83d\udcac  ::debug::isExplicit: \n[Tests/tests]   \ud83d\udcac  ::debug::explicit? false\n[Tests/tests]   \ud83d\udcac  ::debug::isExplicit: 2.7.18\n[Tests/tests]   \ud83d\udcac  ::debug::explicit? true\n[Tests/tests]   \ud83d\udcac  ::debug::isExplicit: 3.5.10\n[Tests/tests]   \ud83d\udcac  ::debug::explicit? true\n[Tests/tests]   \ud83d\udcac  ::debug::isExplicit: 3.6.14\n[Tests/tests]   \ud83d\udcac  ::debug::explicit? true\n[Tests/tests]   \ud83d\udcac  ::debug::isExplicit: 3.7.11\n[Tests/tests]   \ud83d\udcac  ::debug::explicit? true\n[Tests/tests]   \ud83d\udcac  ::debug::isExplicit: 3.8.11\n[Tests/tests]   \ud83d\udcac  ::debug::explicit? true\n[Tests/tests]   \ud83d\udcac  ::debug::isExplicit: 3.9.6\n[Tests/tests]   \ud83d\udcac  ::debug::explicit? true\n[Tests/tests]   \ud83d\udcac  ::debug::evaluating 6 versions\n[Tests/tests]   \ud83d\udcac  ::debug::matched: 3.7.11\n[Tests/tests]   \ud83d\udcac  ::debug::checking cache: /opt/hostedtoolcache/Python/3.7.11/x64\n[Tests/tests]   \ud83d\udcac  ::debug::Found tool in cache Python 3.7.11 x64\n[Tests/tests]   | Successfully setup CPython (3.7.11)\n[Tests/tests]   \u2753 add-matcher /run/act/actions/actions-setup-python@v2/.github/python.json\n[Tests/tests]   \u2705  Success - Main Set up Python 3.7\n[Tests/tests]   \u2699  ::set-env:: pythonLocation=/opt/hostedtoolcache/Python/3.7.11/x64\n[Tests/tests]   \u2699  ::set-env:: LD_LIBRARY_PATH=/opt/hostedtoolcache/Python/3.7.11/x64/lib\n[Tests/tests]   \u2699  ::set-output:: python-version=3.7.11\n[Tests/tests]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.7.11/x64\n[Tests/tests]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.7.11/x64/bin\n[Tests/tests] \u2b50 Run Main install requirements\n[Tests/tests]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/2] user= workdir=\n[Tests/tests]   | Requirement already satisfied: pip in /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages (21.2.4)\n[Tests/tests]   | Collecting pip\n[Tests/tests]   |   Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n[Tests/tests]   | Installing collected packages: pip\n[Tests/tests]   |   Attempting uninstall: pip\n[Tests/tests]   |     Found existing installation: pip 21.2.4\n[Tests/tests]   |     Uninstalling pip-21.2.4:\n[Tests/tests]   |       Successfully uninstalled pip-21.2.4\n[Tests/tests]   | Successfully installed pip-23.1.2\n[Tests/tests]   | Obtaining file:///tmp/de65f406-fe28-11ed-a890-af2cc187fc11/scrapy-scrapyd\n[Tests/tests]   |   Installing build dependencies: started\n[Tests/tests]   |   Installing build dependencies: finished with status 'done'\n[Tests/tests]   |   Checking if build backend supports build_editable: started\n[Tests/tests]   |   Checking if build backend supports build_editable: finished with status 'done'\n[Tests/tests]   |   Getting requirements to build editable: started\n[Tests/tests]   |   Getting requirements to build editable: finished with status 'done'\n[Tests/tests]   |   Preparing editable metadata (pyproject.toml): started\n[Tests/tests]   |   Preparing editable metadata (pyproject.toml): finished with status 'done'\n[Tests/tests]   | Collecting packaging (from scrapyd==1.4.2)\n[Tests/tests]   |   Downloading packaging-23.1-py3-none-any.whl (48 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 48.9/48.9 kB 5.3 MB/s eta 0:00:00\n[Tests/tests]   | Collecting twisted>=17.9 (from scrapyd==1.4.2)\n[Tests/tests]   |   Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.1/3.1 MB 39.2 MB/s eta 0:00:00\n[Tests/tests]   | Collecting scrapy>=2.0.0 (from scrapyd==1.4.2)\n[Tests/tests]   |   Downloading Scrapy-2.9.0-py2.py3-none-any.whl (277 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 277.2/277.2 kB 19.5 MB/s eta 0:00:00\n[Tests/tests]   | Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages (from scrapyd==1.4.2) (47.1.0)\n[Tests/tests]   | Collecting w3lib (from scrapyd==1.4.2)\n[Tests/tests]   |   Downloading w3lib-2.1.1-py3-none-any.whl (21 kB)\n[Tests/tests]   | Collecting zope.interface (from scrapyd==1.4.2)\n[Tests/tests]   |   Downloading zope.interface-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 241.5/241.5 kB 22.0 MB/s eta 0:00:00\n[Tests/tests]   | Collecting pytest (from scrapyd==1.4.2)\n[Tests/tests]   |   Downloading pytest-7.3.1-py3-none-any.whl (320 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 320.5/320.5 kB 22.8 MB/s eta 0:00:00\n[Tests/tests]   | Collecting pytest-cov (from scrapyd==1.4.2)\n[Tests/tests]   |   Downloading pytest_cov-4.1.0-py3-none-any.whl (21 kB)\n[Tests/tests]   | Collecting requests (from scrapyd==1.4.2)\n[Tests/tests]   |   Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 62.6/62.6 kB 1.7 MB/s eta 0:00:00\n[Tests/tests]   | Collecting cryptography>=3.4.6 (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading cryptography-40.0.2-cp36-abi3-manylinux_2_28_x86_64.whl (3.7 MB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.7/3.7 MB 44.8 MB/s eta 0:00:00\n[Tests/tests]   | Collecting cssselect>=0.9.1 (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n[Tests/tests]   | Collecting itemloaders>=1.0.1 (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\n[Tests/tests]   | Collecting parsel>=1.5.0 (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n[Tests/tests]   | Collecting pyOpenSSL>=21.0.0 (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading pyOpenSSL-23.1.1-py3-none-any.whl (57 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 57.9/57.9 kB 6.8 MB/s eta 0:00:00\n[Tests/tests]   | Collecting queuelib>=1.4.2 (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n[Tests/tests]   | Collecting service-identity>=18.1.0 (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n[Tests/tests]   | Collecting protego>=0.1.15 (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n[Tests/tests]   | Collecting itemadapter>=0.1.0 (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\n[Tests/tests]   | Collecting tldextract (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading tldextract-3.4.4-py3-none-any.whl (93 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 93.3/93.3 kB 7.4 MB/s eta 0:00:00\n[Tests/tests]   | Collecting lxml>=4.3.0 (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading lxml-4.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.6 MB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 39.3 MB/s eta 0:00:00\n[Tests/tests]   | Collecting PyDispatcher>=2.0.5 (from scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n[Tests/tests]   | Collecting constantly>=15.1 (from twisted>=17.9->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n[Tests/tests]   | Collecting incremental>=21.3.0 (from twisted>=17.9->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n[Tests/tests]   | Collecting Automat>=0.8.0 (from twisted>=17.9->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n[Tests/tests]   | Collecting hyperlink>=17.1.1 (from twisted>=17.9->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 74.6/74.6 kB 6.0 MB/s eta 0:00:00\n[Tests/tests]   | Collecting attrs>=19.2.0 (from twisted>=17.9->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 61.2/61.2 kB 4.3 MB/s eta 0:00:00\n[Tests/tests]   | Collecting typing-extensions>=3.6.5 (from twisted>=17.9->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading typing_extensions-4.6.2-py3-none-any.whl (31 kB)\n[Tests/tests]   | Collecting iniconfig (from pytest->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n[Tests/tests]   | Collecting pluggy<2.0,>=0.12 (from pytest->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n[Tests/tests]   | Collecting exceptiongroup>=1.0.0rc8 (from pytest->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\n[Tests/tests]   | Collecting tomli>=1.0.0 (from pytest->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n[Tests/tests]   | Collecting importlib-metadata>=0.12 (from pytest->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n[Tests/tests]   | Collecting coverage[toml]>=5.2.1 (from pytest-cov->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading coverage-7.2.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 225.5/225.5 kB 15.8 MB/s eta 0:00:00\n[Tests/tests]   | Collecting charset-normalizer<4,>=2 (from requests->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading charset_normalizer-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (171 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 171.0/171.0 kB 11.7 MB/s eta 0:00:00\n[Tests/tests]   | Collecting idna<4,>=2.5 (from requests->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading idna-3.4-py3-none-any.whl (61 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 61.5/61.5 kB 7.3 MB/s eta 0:00:00\n[Tests/tests]   | Collecting urllib3<3,>=1.21.1 (from requests->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 123.2/123.2 kB 9.0 MB/s eta 0:00:00\n[Tests/tests]   | Collecting certifi>=2017.4.17 (from requests->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 157.0/157.0 kB 3.3 MB/s eta 0:00:00\n[Tests/tests]   | Collecting six (from Automat>=0.8.0->twisted>=17.9->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n[Tests/tests]   | Collecting cffi>=1.12 (from cryptography>=3.4.6->scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading cffi-1.15.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 427.9/427.9 kB 23.6 MB/s eta 0:00:00\n[Tests/tests]   | Collecting zipp>=0.5 (from importlib-metadata>=0.12->pytest->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n[Tests/tests]   | Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n[Tests/tests]   | Collecting pyasn1-modules (from service-identity>=18.1.0->scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 181.3/181.3 kB 7.3 MB/s eta 0:00:00\n[Tests/tests]   | Collecting pyasn1 (from service-identity>=18.1.0->scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 83.9/83.9 kB 17.5 MB/s eta 0:00:00\n[Tests/tests]   | Collecting requests-file>=1.4 (from tldextract->scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n[Tests/tests]   | Collecting filelock>=3.0.8 (from tldextract->scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n[Tests/tests]   | Collecting pycparser (from cffi>=1.12->cryptography>=3.4.6->scrapy>=2.0.0->scrapyd==1.4.2)\n[Tests/tests]   |   Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n[Tests/tests]   |      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 118.7/118.7 kB 11.6 MB/s eta 0:00:00\n[Tests/tests]   | Building wheels for collected packages: scrapyd\n[Tests/tests]   |   Building editable for scrapyd (pyproject.toml): started\n[Tests/tests]   |   Building editable for scrapyd (pyproject.toml): finished with status 'done'\n[Tests/tests]   |   Created wheel for scrapyd: filename=scrapyd-1.4.2-0.editable-py2.py3-none-any.whl size=4353 sha256=fa945f0a9f7498eb32717d686d9aa2265ca85006929a54178b7a9df67859e25d\n[Tests/tests]   |   Stored in directory: /tmp/pip-ephem-wheel-cache-c522lygz/wheels/80/47/67/a9fbe98c825ebc564548914322e34e7645c90a61d7605ffa54\n[Tests/tests]   | Successfully built scrapyd\n[Tests/tests]   | Installing collected packages: PyDispatcher, incremental, constantly, zope.interface, zipp, w3lib, urllib3, typing-extensions, tomli, six, queuelib, pycparser, pyasn1, packaging, lxml, jmespath, itemadapter, iniconfig, idna, filelock, exceptiongroup, cssselect, coverage, charset-normalizer, certifi, requests, pyasn1-modules, protego, parsel, importlib-metadata, hyperlink, cffi, requests-file, pluggy, itemloaders, cryptography, attrs, tldextract, service-identity, pytest, pyOpenSSL, Automat, twisted, pytest-cov, scrapy, scrapyd\n[Tests/tests]   | Successfully installed Automat-22.10.0 PyDispatcher-2.0.7 attrs-23.1.0 certifi-2023.5.7 cffi-1.15.1 charset-normalizer-3.1.0 constantly-15.1.0 coverage-7.2.6 cryptography-40.0.2 cssselect-1.2.0 exceptiongroup-1.1.1 filelock-3.12.0 hyperlink-21.0.0 idna-3.4 importlib-metadata-6.6.0 incremental-22.10.0 iniconfig-2.0.0 itemadapter-0.8.0 itemloaders-1.1.0 jmespath-1.0.1 lxml-4.9.2 packaging-23.1 parsel-1.8.1 pluggy-1.0.0 protego-0.2.1 pyOpenSSL-23.1.1 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycparser-2.21 pytest-7.3.1 pytest-cov-4.1.0 queuelib-1.6.2 requests-2.31.0 requests-file-1.5.1 scrapy-2.9.0 scrapyd-1.4.2 service-identity-21.1.0 six-1.16.0 tldextract-3.4.4 tomli-2.0.1 twisted-22.10.0 typing-extensions-4.6.2 urllib3-2.0.2 w3lib-2.1.1 zipp-3.15.0 zope.interface-6.0\n[Tests/tests]   | \n[Tests/tests]   | [notice] A new release of pip is available: 20.1.1 -> 23.1.2\n[Tests/tests]   | [notice] To update, run: pip install --upgrade pip\n[Tests/tests]   \u2705  Success - Main install requirements\n[Tests/tests] \u2b50 Run Main Run unit tests\n[Tests/tests]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/3] user= workdir=\n[Tests/tests]   | ============================= test session starts ==============================\n[Tests/tests]   | platform linux -- Python 3.7.11, pytest-7.3.1, pluggy-1.0.0\n[Tests/tests]   | rootdir: /tmp/de65f406-fe28-11ed-a890-af2cc187fc11/scrapy-scrapyd\n[Tests/tests]   | plugins: cov-4.1.0\n[Tests/tests]   | collected 82 items\n[Tests/tests]   | \n[Tests/tests]   | scrapyd/tests/test_dont_load_settings.py .                               [  1%]\n[Tests/tests]   | scrapyd/tests/test_eggstorage.py .....                                   [  7%]\n[Tests/tests]   | scrapyd/tests/test_endpoints.py .FFF.FFF                                 [ 17%]\n[Tests/tests]   | scrapyd/tests/test_environ.py ...                                        [ 20%]\n[Tests/tests]   | scrapyd/tests/test_jobstorage.py .......                                 [ 29%]\n[Tests/tests]   | scrapyd/tests/test_poller.py ..                                          [ 31%]\n[Tests/tests]   | scrapyd/tests/test_scheduler.py ...                                      [ 35%]\n[Tests/tests]   | scrapyd/tests/test_scripts.py ...                                        [ 39%]\n[Tests/tests]   | scrapyd/tests/test_spiderqueue.py ....                                   [ 43%]\n[Tests/tests]   | scrapyd/tests/test_sqlite.py ...............                             [ 62%]\n[Tests/tests]   | scrapyd/tests/test_utils.py .........                                    [ 73%]\n[Tests/tests]   | scrapyd/tests/test_webservice.py ..................                      [ 95%]\n[Tests/tests]   | scrapyd/tests/test_website.py ....                                       [100%]\n[Tests/tests]   | \n[Tests/tests]   | =================================== FAILURES ===================================\n[Tests/tests]   | ____________________________ TestEndpoint.test_root ____________________________\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0b896450>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   | >               socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:204: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 52469), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   |                 sock.connect(sa)\n[Tests/tests]   |                 # Break explicitly a reference cycle\n[Tests/tests]   |                 err = None\n[Tests/tests]   |                 return sock\n[Tests/tests]   |     \n[Tests/tests]   |             except OSError as _:\n[Tests/tests]   |                 err = _\n[Tests/tests]   |                 if sock is not None:\n[Tests/tests]   |                     sock.close()\n[Tests/tests]   |     \n[Tests/tests]   |         if err is not None:\n[Tests/tests]   |             try:\n[Tests/tests]   | >               raise err\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:85: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 52469), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   | >               sock.connect(sa)\n[Tests/tests]   | E               ConnectionRefusedError: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:73: ConnectionRefusedError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0b974f50>\n[Tests/tests]   | method = 'GET', url = '/', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:802: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0b974f50>\n[Tests/tests]   | conn = <urllib3.connection.HTTPConnection object at 0x7fdc0b896450>\n[Tests/tests]   | method = 'GET', url = '/', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), chunked = False\n[Tests/tests]   | response_conn = <urllib3.connection.HTTPConnection object at 0x7fdc0b896450>\n[Tests/tests]   | preload_content = False, decode_content = False, enforce_content_length = True\n[Tests/tests]   | \n[Tests/tests]   |     def _make_request(\n[Tests/tests]   |         self,\n[Tests/tests]   |         conn: BaseHTTPConnection,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | None = None,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         response_conn: BaseHTTPConnection | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Perform a request on a given urllib connection object taken from our\n[Tests/tests]   |         pool.\n[Tests/tests]   |     \n[Tests/tests]   |         :param conn:\n[Tests/tests]   |             a connection from one of our connection pools\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response_conn:\n[Tests/tests]   |             Set this to ``None`` if you will handle releasing the connection or\n[Tests/tests]   |             set the connection to have the response release it.\n[Tests/tests]   |     \n[Tests/tests]   |         :param preload_content:\n[Tests/tests]   |           If True, the response's body will be preloaded during construction.\n[Tests/tests]   |     \n[Tests/tests]   |         :param decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param enforce_content_length:\n[Tests/tests]   |             Enforce content length checking. Body returned by server must match\n[Tests/tests]   |             value of Content-Length header, if present. Otherwise, raise error.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self.num_requests += 1\n[Tests/tests]   |     \n[Tests/tests]   |         timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |         timeout_obj.start_connect()\n[Tests/tests]   |         conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Trigger any extra validation we need to do.\n[Tests/tests]   |             try:\n[Tests/tests]   |                 self._validate_conn(conn)\n[Tests/tests]   |             except (SocketTimeout, BaseSSLError) as e:\n[Tests/tests]   |                 self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n[Tests/tests]   |                 raise\n[Tests/tests]   |     \n[Tests/tests]   |         # _validate_conn() starts the connection to an HTTPS proxy\n[Tests/tests]   |         # so we need to wrap errors with 'ProxyError' here too.\n[Tests/tests]   |         except (\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             NewConnectionError,\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             # If the connection didn't successfully connect to it's proxy\n[Tests/tests]   |             # then there\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e, (OSError, NewConnectionError, TimeoutError, SSLError)\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             raise new_e\n[Tests/tests]   |     \n[Tests/tests]   |         # conn.request() calls http.client.*.request, not the method in\n[Tests/tests]   |         # urllib3.request. It also calls makefile (recv) on the socket.\n[Tests/tests]   |         try:\n[Tests/tests]   |             conn.request(\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               enforce_content_length=enforce_content_length,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:504: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0b896450>\n[Tests/tests]   | method = 'GET', url = '/', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | \n[Tests/tests]   |     def request(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         *,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> None:\n[Tests/tests]   |         # Update the inner socket's timeout value to send the request.\n[Tests/tests]   |         # This only triggers if the connection is re-used.\n[Tests/tests]   |         if self.sock is not None:\n[Tests/tests]   |             self.sock.settimeout(self.timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         # Store these values to be fed into the HTTPResponse\n[Tests/tests]   |         # object later. TODO: Remove this in favor of a real\n[Tests/tests]   |         # HTTP lifecycle mechanism.\n[Tests/tests]   |     \n[Tests/tests]   |         # We have to store these before we call .request()\n[Tests/tests]   |         # because sometimes we can still salvage a response\n[Tests/tests]   |         # off the wire even if we aren't able to completely\n[Tests/tests]   |         # send the request body.\n[Tests/tests]   |         self._response_options = _ResponseOptions(\n[Tests/tests]   |             request_method=method,\n[Tests/tests]   |             request_url=url,\n[Tests/tests]   |             preload_content=preload_content,\n[Tests/tests]   |             decode_content=decode_content,\n[Tests/tests]   |             enforce_content_length=enforce_content_length,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = {}\n[Tests/tests]   |         header_keys = frozenset(to_str(k.lower()) for k in headers)\n[Tests/tests]   |         skip_accept_encoding = \"accept-encoding\" in header_keys\n[Tests/tests]   |         skip_host = \"host\" in header_keys\n[Tests/tests]   |         self.putrequest(\n[Tests/tests]   |             method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Transform the body into an iterable of sendall()-able chunks\n[Tests/tests]   |         # and detect if an explicit Content-Length is doable.\n[Tests/tests]   |         chunks_and_cl = body_to_chunks(body, method=method, blocksize=self.blocksize)\n[Tests/tests]   |         chunks = chunks_and_cl.chunks\n[Tests/tests]   |         content_length = chunks_and_cl.content_length\n[Tests/tests]   |     \n[Tests/tests]   |         # When chunked is explicit set to 'True' we respect that.\n[Tests/tests]   |         if chunked:\n[Tests/tests]   |             if \"transfer-encoding\" not in header_keys:\n[Tests/tests]   |                 self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |         else:\n[Tests/tests]   |             # Detect whether a framing mechanism is already in use. If so\n[Tests/tests]   |             # we respect that value, otherwise we pick chunked vs content-length\n[Tests/tests]   |             # depending on the type of 'body'.\n[Tests/tests]   |             if \"content-length\" in header_keys:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |             elif \"transfer-encoding\" in header_keys:\n[Tests/tests]   |                 chunked = True\n[Tests/tests]   |     \n[Tests/tests]   |             # Otherwise we go off the recommendation of 'body_to_chunks()'.\n[Tests/tests]   |             else:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |                 if content_length is None:\n[Tests/tests]   |                     if chunks is not None:\n[Tests/tests]   |                         chunked = True\n[Tests/tests]   |                         self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |                 else:\n[Tests/tests]   |                     self.putheader(\"Content-Length\", str(content_length))\n[Tests/tests]   |     \n[Tests/tests]   |         # Now that framing headers are out of the way we send all the other headers.\n[Tests/tests]   |         if \"user-agent\" not in header_keys:\n[Tests/tests]   |             self.putheader(\"User-Agent\", _get_default_user_agent())\n[Tests/tests]   |         for header, value in headers.items():\n[Tests/tests]   |             self.putheader(header, value)\n[Tests/tests]   | >       self.endheaders()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:388: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0b896450>\n[Tests/tests]   | message_body = None\n[Tests/tests]   | \n[Tests/tests]   |     def endheaders(self, message_body=None, *, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Indicate that the last header line has been sent to the server.\n[Tests/tests]   |     \n[Tests/tests]   |         This method sends the request to the server.  The optional message_body\n[Tests/tests]   |         argument can be used to pass a message body associated with the\n[Tests/tests]   |         request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.__state == _CS_REQ_STARTED:\n[Tests/tests]   |             self.__state = _CS_REQ_SENT\n[Tests/tests]   |         else:\n[Tests/tests]   |             raise CannotSendHeader()\n[Tests/tests]   | >       self._send_output(message_body, encode_chunked=encode_chunked)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1276: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0b896450>\n[Tests/tests]   | message_body = None, encode_chunked = False\n[Tests/tests]   | \n[Tests/tests]   |     def _send_output(self, message_body=None, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Send the currently buffered request and clear the buffer.\n[Tests/tests]   |     \n[Tests/tests]   |         Appends an extra \\\\r\\\\n to the buffer.\n[Tests/tests]   |         A message_body may be specified, to be appended to the request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self._buffer.extend((b\"\", b\"\"))\n[Tests/tests]   |         msg = b\"\\r\\n\".join(self._buffer)\n[Tests/tests]   |         del self._buffer[:]\n[Tests/tests]   | >       self.send(msg)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1036: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0b896450>\n[Tests/tests]   | data = b'GET / HTTP/1.1\\r\\nHost: 127.0.0.1:52469\\r\\nUser-Agent: python-requests/2.31.0\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept: */*\\r\\nConnection: keep-alive\\r\\n\\r\\n'\n[Tests/tests]   | \n[Tests/tests]   |     def send(self, data):\n[Tests/tests]   |         \"\"\"Send `data' to the server.\n[Tests/tests]   |         ``data`` can be a string object, a bytes object, an array object, a\n[Tests/tests]   |         file-like object that supports a .read() method, or an iterable object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         if self.sock is None:\n[Tests/tests]   |             if self.auto_open:\n[Tests/tests]   | >               self.connect()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:976: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0b896450>\n[Tests/tests]   | \n[Tests/tests]   |     def connect(self) -> None:\n[Tests/tests]   | >       self.sock = self._new_conn()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:236: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0b896450>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   |                 socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   |         except socket.gaierror as e:\n[Tests/tests]   |             raise NameResolutionError(self.host, self, e) from e\n[Tests/tests]   |         except SocketTimeout as e:\n[Tests/tests]   |             raise ConnectTimeoutError(\n[Tests/tests]   |                 self,\n[Tests/tests]   |                 f\"Connection to {self.host} timed out. (connect timeout={self.timeout})\",\n[Tests/tests]   |             ) from e\n[Tests/tests]   |     \n[Tests/tests]   |         except OSError as e:\n[Tests/tests]   |             raise NewConnectionError(\n[Tests/tests]   |                 self, f\"Failed to establish a new connection: {e}\"\n[Tests/tests]   | >           ) from e\n[Tests/tests]   | E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fdc0b896450>: Failed to establish a new connection: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:217: NewConnectionError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0b972990>\n[Tests/tests]   | request = <PreparedRequest [GET]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   | >               chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:497: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0b974f50>\n[Tests/tests]   | method = 'GET', url = '/', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   |                 **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |             # Everything went great!\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |     \n[Tests/tests]   |         except EmptyPoolError:\n[Tests/tests]   |             # Didn't get a connection from the pool, no need to clean up\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |             release_this_conn = False\n[Tests/tests]   |             raise\n[Tests/tests]   |     \n[Tests/tests]   |         except (\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             HTTPException,\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             ProtocolError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             ProxyError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             # Discard the connection for these exceptions. It will be\n[Tests/tests]   |             # replaced during the next _get_conn() call.\n[Tests/tests]   |             clean_exit = False\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e,\n[Tests/tests]   |                 (\n[Tests/tests]   |                     OSError,\n[Tests/tests]   |                     NewConnectionError,\n[Tests/tests]   |                     TimeoutError,\n[Tests/tests]   |                     SSLError,\n[Tests/tests]   |                     HTTPException,\n[Tests/tests]   |                 ),\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             elif isinstance(new_e, (OSError, HTTPException)):\n[Tests/tests]   |                 new_e = ProtocolError(\"Connection aborted.\", new_e)\n[Tests/tests]   |     \n[Tests/tests]   |             retries = retries.increment(\n[Tests/tests]   | >               method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:845: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | method = 'GET', url = '/', response = None\n[Tests/tests]   | error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0b896450>: Failed to establish a new connection: [Errno 111] Connection refused')\n[Tests/tests]   | _pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0b974f50>\n[Tests/tests]   | _stacktrace = <traceback object at 0x7fdc0b881cd0>\n[Tests/tests]   | \n[Tests/tests]   |     def increment(\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str | None = None,\n[Tests/tests]   |         url: str | None = None,\n[Tests/tests]   |         response: BaseHTTPResponse | None = None,\n[Tests/tests]   |         error: Exception | None = None,\n[Tests/tests]   |         _pool: ConnectionPool | None = None,\n[Tests/tests]   |         _stacktrace: TracebackType | None = None,\n[Tests/tests]   |     ) -> Retry:\n[Tests/tests]   |         \"\"\"Return a new Retry object with incremented retry counters.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response: A response object, or None, if the server did not\n[Tests/tests]   |             return a response.\n[Tests/tests]   |         :type response: :class:`~urllib3.response.BaseHTTPResponse`\n[Tests/tests]   |         :param Exception error: An error encountered during the request, or\n[Tests/tests]   |             None if the response was received successfully.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: A new ``Retry`` object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.total is False and error:\n[Tests/tests]   |             # Disabled, indicate to re-raise the error.\n[Tests/tests]   |             raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |     \n[Tests/tests]   |         total = self.total\n[Tests/tests]   |         if total is not None:\n[Tests/tests]   |             total -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         connect = self.connect\n[Tests/tests]   |         read = self.read\n[Tests/tests]   |         redirect = self.redirect\n[Tests/tests]   |         status_count = self.status\n[Tests/tests]   |         other = self.other\n[Tests/tests]   |         cause = \"unknown\"\n[Tests/tests]   |         status = None\n[Tests/tests]   |         redirect_location = None\n[Tests/tests]   |     \n[Tests/tests]   |         if error and self._is_connection_error(error):\n[Tests/tests]   |             # Connect retry?\n[Tests/tests]   |             if connect is False:\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif connect is not None:\n[Tests/tests]   |                 connect -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error and self._is_read_error(error):\n[Tests/tests]   |             # Read retry?\n[Tests/tests]   |             if read is False or method is None or not self._is_method_retryable(method):\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif read is not None:\n[Tests/tests]   |                 read -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error:\n[Tests/tests]   |             # Other retry?\n[Tests/tests]   |             if other is not None:\n[Tests/tests]   |                 other -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif response and response.get_redirect_location():\n[Tests/tests]   |             # Redirect retry?\n[Tests/tests]   |             if redirect is not None:\n[Tests/tests]   |                 redirect -= 1\n[Tests/tests]   |             cause = \"too many redirects\"\n[Tests/tests]   |             response_redirect_location = response.get_redirect_location()\n[Tests/tests]   |             if response_redirect_location:\n[Tests/tests]   |                 redirect_location = response_redirect_location\n[Tests/tests]   |             status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         else:\n[Tests/tests]   |             # Incrementing because of a server error like a 500 in\n[Tests/tests]   |             # status_forcelist and the given method is in the allowed_methods\n[Tests/tests]   |             cause = ResponseError.GENERIC_ERROR\n[Tests/tests]   |             if response and response.status:\n[Tests/tests]   |                 if status_count is not None:\n[Tests/tests]   |                     status_count -= 1\n[Tests/tests]   |                 cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n[Tests/tests]   |                 status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         history = self.history + (\n[Tests/tests]   |             RequestHistory(method, url, error, status, redirect_location),\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         new_retry = self.new(\n[Tests/tests]   |             total=total,\n[Tests/tests]   |             connect=connect,\n[Tests/tests]   |             read=read,\n[Tests/tests]   |             redirect=redirect,\n[Tests/tests]   |             status=status_count,\n[Tests/tests]   |             other=other,\n[Tests/tests]   |             history=history,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if new_retry.is_exhausted():\n[Tests/tests]   |             reason = error or ResponseError(cause)\n[Tests/tests]   | >           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n[Tests/tests]   | E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=52469): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0b896450>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/retry.py:515: MaxRetryError\n[Tests/tests]   | \n[Tests/tests]   | During handling of the above exception, another exception occurred:\n[Tests/tests]   | \n[Tests/tests]   | self = <scrapyd.tests.test_endpoints.TestEndpoint object at 0x7fdc0c28b0d0>\n[Tests/tests]   | mock_scrapyd = <scrapyd.tests.mockserver.MockScrapyDServer object at 0x7fdc0b8a0410>\n[Tests/tests]   | \n[Tests/tests]   |     def test_root(self, mock_scrapyd):\n[Tests/tests]   | >       resp = requests.get(mock_scrapyd.url)\n[Tests/tests]   | \n[Tests/tests]   | scrapyd/tests/test_endpoints.py:37: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:73: in get\n[Tests/tests]   |     return request(\"get\", url, params=params, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:59: in request\n[Tests/tests]   |     return session.request(method=method, url=url, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:589: in request\n[Tests/tests]   |     resp = self.send(prep, **send_kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:703: in send\n[Tests/tests]   |     r = adapter.send(request, **kwargs)\n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0b972990>\n[Tests/tests]   | request = <PreparedRequest [GET]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |         except (ProtocolError, OSError) as err:\n[Tests/tests]   |             raise ConnectionError(err, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         except MaxRetryError as e:\n[Tests/tests]   |             if isinstance(e.reason, ConnectTimeoutError):\n[Tests/tests]   |                 # TODO: Remove this in 3.0.0: see #2811\n[Tests/tests]   |                 if not isinstance(e.reason, NewConnectionError):\n[Tests/tests]   |                     raise ConnectTimeout(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, ResponseError):\n[Tests/tests]   |                 raise RetryError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _ProxyError):\n[Tests/tests]   |                 raise ProxyError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _SSLError):\n[Tests/tests]   |                 # This branch is for urllib3 v1.22 and later.\n[Tests/tests]   |                 raise SSLError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   | >           raise ConnectionError(e, request=request)\n[Tests/tests]   | E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=52469): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0b896450>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:519: ConnectionError\n[Tests/tests]   | ____________________________ TestEndpoint.test_auth ____________________________\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   | >               socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:204: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 47429), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   |                 sock.connect(sa)\n[Tests/tests]   |                 # Break explicitly a reference cycle\n[Tests/tests]   |                 err = None\n[Tests/tests]   |                 return sock\n[Tests/tests]   |     \n[Tests/tests]   |             except OSError as _:\n[Tests/tests]   |                 err = _\n[Tests/tests]   |                 if sock is not None:\n[Tests/tests]   |                     sock.close()\n[Tests/tests]   |     \n[Tests/tests]   |         if err is not None:\n[Tests/tests]   |             try:\n[Tests/tests]   | >               raise err\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:85: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 47429), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   | >               sock.connect(sa)\n[Tests/tests]   | E               ConnectionRefusedError: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:73: ConnectionRefusedError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bee5dd0>\n[Tests/tests]   | method = 'GET', url = '/', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:802: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bee5dd0>\n[Tests/tests]   | conn = <urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>\n[Tests/tests]   | method = 'GET', url = '/', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), chunked = False\n[Tests/tests]   | response_conn = <urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>\n[Tests/tests]   | preload_content = False, decode_content = False, enforce_content_length = True\n[Tests/tests]   | \n[Tests/tests]   |     def _make_request(\n[Tests/tests]   |         self,\n[Tests/tests]   |         conn: BaseHTTPConnection,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | None = None,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         response_conn: BaseHTTPConnection | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Perform a request on a given urllib connection object taken from our\n[Tests/tests]   |         pool.\n[Tests/tests]   |     \n[Tests/tests]   |         :param conn:\n[Tests/tests]   |             a connection from one of our connection pools\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response_conn:\n[Tests/tests]   |             Set this to ``None`` if you will handle releasing the connection or\n[Tests/tests]   |             set the connection to have the response release it.\n[Tests/tests]   |     \n[Tests/tests]   |         :param preload_content:\n[Tests/tests]   |           If True, the response's body will be preloaded during construction.\n[Tests/tests]   |     \n[Tests/tests]   |         :param decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param enforce_content_length:\n[Tests/tests]   |             Enforce content length checking. Body returned by server must match\n[Tests/tests]   |             value of Content-Length header, if present. Otherwise, raise error.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self.num_requests += 1\n[Tests/tests]   |     \n[Tests/tests]   |         timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |         timeout_obj.start_connect()\n[Tests/tests]   |         conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Trigger any extra validation we need to do.\n[Tests/tests]   |             try:\n[Tests/tests]   |                 self._validate_conn(conn)\n[Tests/tests]   |             except (SocketTimeout, BaseSSLError) as e:\n[Tests/tests]   |                 self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n[Tests/tests]   |                 raise\n[Tests/tests]   |     \n[Tests/tests]   |         # _validate_conn() starts the connection to an HTTPS proxy\n[Tests/tests]   |         # so we need to wrap errors with 'ProxyError' here too.\n[Tests/tests]   |         except (\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             NewConnectionError,\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             # If the connection didn't successfully connect to it's proxy\n[Tests/tests]   |             # then there\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e, (OSError, NewConnectionError, TimeoutError, SSLError)\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             raise new_e\n[Tests/tests]   |     \n[Tests/tests]   |         # conn.request() calls http.client.*.request, not the method in\n[Tests/tests]   |         # urllib3.request. It also calls makefile (recv) on the socket.\n[Tests/tests]   |         try:\n[Tests/tests]   |             conn.request(\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               enforce_content_length=enforce_content_length,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:504: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>\n[Tests/tests]   | method = 'GET', url = '/', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | \n[Tests/tests]   |     def request(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         *,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> None:\n[Tests/tests]   |         # Update the inner socket's timeout value to send the request.\n[Tests/tests]   |         # This only triggers if the connection is re-used.\n[Tests/tests]   |         if self.sock is not None:\n[Tests/tests]   |             self.sock.settimeout(self.timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         # Store these values to be fed into the HTTPResponse\n[Tests/tests]   |         # object later. TODO: Remove this in favor of a real\n[Tests/tests]   |         # HTTP lifecycle mechanism.\n[Tests/tests]   |     \n[Tests/tests]   |         # We have to store these before we call .request()\n[Tests/tests]   |         # because sometimes we can still salvage a response\n[Tests/tests]   |         # off the wire even if we aren't able to completely\n[Tests/tests]   |         # send the request body.\n[Tests/tests]   |         self._response_options = _ResponseOptions(\n[Tests/tests]   |             request_method=method,\n[Tests/tests]   |             request_url=url,\n[Tests/tests]   |             preload_content=preload_content,\n[Tests/tests]   |             decode_content=decode_content,\n[Tests/tests]   |             enforce_content_length=enforce_content_length,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = {}\n[Tests/tests]   |         header_keys = frozenset(to_str(k.lower()) for k in headers)\n[Tests/tests]   |         skip_accept_encoding = \"accept-encoding\" in header_keys\n[Tests/tests]   |         skip_host = \"host\" in header_keys\n[Tests/tests]   |         self.putrequest(\n[Tests/tests]   |             method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Transform the body into an iterable of sendall()-able chunks\n[Tests/tests]   |         # and detect if an explicit Content-Length is doable.\n[Tests/tests]   |         chunks_and_cl = body_to_chunks(body, method=method, blocksize=self.blocksize)\n[Tests/tests]   |         chunks = chunks_and_cl.chunks\n[Tests/tests]   |         content_length = chunks_and_cl.content_length\n[Tests/tests]   |     \n[Tests/tests]   |         # When chunked is explicit set to 'True' we respect that.\n[Tests/tests]   |         if chunked:\n[Tests/tests]   |             if \"transfer-encoding\" not in header_keys:\n[Tests/tests]   |                 self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |         else:\n[Tests/tests]   |             # Detect whether a framing mechanism is already in use. If so\n[Tests/tests]   |             # we respect that value, otherwise we pick chunked vs content-length\n[Tests/tests]   |             # depending on the type of 'body'.\n[Tests/tests]   |             if \"content-length\" in header_keys:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |             elif \"transfer-encoding\" in header_keys:\n[Tests/tests]   |                 chunked = True\n[Tests/tests]   |     \n[Tests/tests]   |             # Otherwise we go off the recommendation of 'body_to_chunks()'.\n[Tests/tests]   |             else:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |                 if content_length is None:\n[Tests/tests]   |                     if chunks is not None:\n[Tests/tests]   |                         chunked = True\n[Tests/tests]   |                         self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |                 else:\n[Tests/tests]   |                     self.putheader(\"Content-Length\", str(content_length))\n[Tests/tests]   |     \n[Tests/tests]   |         # Now that framing headers are out of the way we send all the other headers.\n[Tests/tests]   |         if \"user-agent\" not in header_keys:\n[Tests/tests]   |             self.putheader(\"User-Agent\", _get_default_user_agent())\n[Tests/tests]   |         for header, value in headers.items():\n[Tests/tests]   |             self.putheader(header, value)\n[Tests/tests]   | >       self.endheaders()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:388: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>\n[Tests/tests]   | message_body = None\n[Tests/tests]   | \n[Tests/tests]   |     def endheaders(self, message_body=None, *, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Indicate that the last header line has been sent to the server.\n[Tests/tests]   |     \n[Tests/tests]   |         This method sends the request to the server.  The optional message_body\n[Tests/tests]   |         argument can be used to pass a message body associated with the\n[Tests/tests]   |         request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.__state == _CS_REQ_STARTED:\n[Tests/tests]   |             self.__state = _CS_REQ_SENT\n[Tests/tests]   |         else:\n[Tests/tests]   |             raise CannotSendHeader()\n[Tests/tests]   | >       self._send_output(message_body, encode_chunked=encode_chunked)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1276: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>\n[Tests/tests]   | message_body = None, encode_chunked = False\n[Tests/tests]   | \n[Tests/tests]   |     def _send_output(self, message_body=None, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Send the currently buffered request and clear the buffer.\n[Tests/tests]   |     \n[Tests/tests]   |         Appends an extra \\\\r\\\\n to the buffer.\n[Tests/tests]   |         A message_body may be specified, to be appended to the request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self._buffer.extend((b\"\", b\"\"))\n[Tests/tests]   |         msg = b\"\\r\\n\".join(self._buffer)\n[Tests/tests]   |         del self._buffer[:]\n[Tests/tests]   | >       self.send(msg)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1036: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>\n[Tests/tests]   | data = b'GET / HTTP/1.1\\r\\nHost: 127.0.0.1:47429\\r\\nUser-Agent: python-requests/2.31.0\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept: */*\\r\\nConnection: keep-alive\\r\\n\\r\\n'\n[Tests/tests]   | \n[Tests/tests]   |     def send(self, data):\n[Tests/tests]   |         \"\"\"Send `data' to the server.\n[Tests/tests]   |         ``data`` can be a string object, a bytes object, an array object, a\n[Tests/tests]   |         file-like object that supports a .read() method, or an iterable object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         if self.sock is None:\n[Tests/tests]   |             if self.auto_open:\n[Tests/tests]   | >               self.connect()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:976: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>\n[Tests/tests]   | \n[Tests/tests]   |     def connect(self) -> None:\n[Tests/tests]   | >       self.sock = self._new_conn()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:236: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   |                 socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   |         except socket.gaierror as e:\n[Tests/tests]   |             raise NameResolutionError(self.host, self, e) from e\n[Tests/tests]   |         except SocketTimeout as e:\n[Tests/tests]   |             raise ConnectTimeoutError(\n[Tests/tests]   |                 self,\n[Tests/tests]   |                 f\"Connection to {self.host} timed out. (connect timeout={self.timeout})\",\n[Tests/tests]   |             ) from e\n[Tests/tests]   |     \n[Tests/tests]   |         except OSError as e:\n[Tests/tests]   |             raise NewConnectionError(\n[Tests/tests]   |                 self, f\"Failed to establish a new connection: {e}\"\n[Tests/tests]   | >           ) from e\n[Tests/tests]   | E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>: Failed to establish a new connection: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:217: NewConnectionError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0bee58d0>\n[Tests/tests]   | request = <PreparedRequest [GET]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   | >               chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:497: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bee5dd0>\n[Tests/tests]   | method = 'GET', url = '/', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   |                 **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |             # Everything went great!\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |     \n[Tests/tests]   |         except EmptyPoolError:\n[Tests/tests]   |             # Didn't get a connection from the pool, no need to clean up\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |             release_this_conn = False\n[Tests/tests]   |             raise\n[Tests/tests]   |     \n[Tests/tests]   |         except (\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             HTTPException,\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             ProtocolError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             ProxyError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             # Discard the connection for these exceptions. It will be\n[Tests/tests]   |             # replaced during the next _get_conn() call.\n[Tests/tests]   |             clean_exit = False\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e,\n[Tests/tests]   |                 (\n[Tests/tests]   |                     OSError,\n[Tests/tests]   |                     NewConnectionError,\n[Tests/tests]   |                     TimeoutError,\n[Tests/tests]   |                     SSLError,\n[Tests/tests]   |                     HTTPException,\n[Tests/tests]   |                 ),\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             elif isinstance(new_e, (OSError, HTTPException)):\n[Tests/tests]   |                 new_e = ProtocolError(\"Connection aborted.\", new_e)\n[Tests/tests]   |     \n[Tests/tests]   |             retries = retries.increment(\n[Tests/tests]   | >               method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:845: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | method = 'GET', url = '/', response = None\n[Tests/tests]   | error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>: Failed to establish a new connection: [Errno 111] Connection refused')\n[Tests/tests]   | _pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bee5dd0>\n[Tests/tests]   | _stacktrace = <traceback object at 0x7fdc0bbddf00>\n[Tests/tests]   | \n[Tests/tests]   |     def increment(\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str | None = None,\n[Tests/tests]   |         url: str | None = None,\n[Tests/tests]   |         response: BaseHTTPResponse | None = None,\n[Tests/tests]   |         error: Exception | None = None,\n[Tests/tests]   |         _pool: ConnectionPool | None = None,\n[Tests/tests]   |         _stacktrace: TracebackType | None = None,\n[Tests/tests]   |     ) -> Retry:\n[Tests/tests]   |         \"\"\"Return a new Retry object with incremented retry counters.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response: A response object, or None, if the server did not\n[Tests/tests]   |             return a response.\n[Tests/tests]   |         :type response: :class:`~urllib3.response.BaseHTTPResponse`\n[Tests/tests]   |         :param Exception error: An error encountered during the request, or\n[Tests/tests]   |             None if the response was received successfully.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: A new ``Retry`` object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.total is False and error:\n[Tests/tests]   |             # Disabled, indicate to re-raise the error.\n[Tests/tests]   |             raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |     \n[Tests/tests]   |         total = self.total\n[Tests/tests]   |         if total is not None:\n[Tests/tests]   |             total -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         connect = self.connect\n[Tests/tests]   |         read = self.read\n[Tests/tests]   |         redirect = self.redirect\n[Tests/tests]   |         status_count = self.status\n[Tests/tests]   |         other = self.other\n[Tests/tests]   |         cause = \"unknown\"\n[Tests/tests]   |         status = None\n[Tests/tests]   |         redirect_location = None\n[Tests/tests]   |     \n[Tests/tests]   |         if error and self._is_connection_error(error):\n[Tests/tests]   |             # Connect retry?\n[Tests/tests]   |             if connect is False:\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif connect is not None:\n[Tests/tests]   |                 connect -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error and self._is_read_error(error):\n[Tests/tests]   |             # Read retry?\n[Tests/tests]   |             if read is False or method is None or not self._is_method_retryable(method):\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif read is not None:\n[Tests/tests]   |                 read -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error:\n[Tests/tests]   |             # Other retry?\n[Tests/tests]   |             if other is not None:\n[Tests/tests]   |                 other -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif response and response.get_redirect_location():\n[Tests/tests]   |             # Redirect retry?\n[Tests/tests]   |             if redirect is not None:\n[Tests/tests]   |                 redirect -= 1\n[Tests/tests]   |             cause = \"too many redirects\"\n[Tests/tests]   |             response_redirect_location = response.get_redirect_location()\n[Tests/tests]   |             if response_redirect_location:\n[Tests/tests]   |                 redirect_location = response_redirect_location\n[Tests/tests]   |             status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         else:\n[Tests/tests]   |             # Incrementing because of a server error like a 500 in\n[Tests/tests]   |             # status_forcelist and the given method is in the allowed_methods\n[Tests/tests]   |             cause = ResponseError.GENERIC_ERROR\n[Tests/tests]   |             if response and response.status:\n[Tests/tests]   |                 if status_count is not None:\n[Tests/tests]   |                     status_count -= 1\n[Tests/tests]   |                 cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n[Tests/tests]   |                 status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         history = self.history + (\n[Tests/tests]   |             RequestHistory(method, url, error, status, redirect_location),\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         new_retry = self.new(\n[Tests/tests]   |             total=total,\n[Tests/tests]   |             connect=connect,\n[Tests/tests]   |             read=read,\n[Tests/tests]   |             redirect=redirect,\n[Tests/tests]   |             status=status_count,\n[Tests/tests]   |             other=other,\n[Tests/tests]   |             history=history,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if new_retry.is_exhausted():\n[Tests/tests]   |             reason = error or ResponseError(cause)\n[Tests/tests]   | >           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n[Tests/tests]   | E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=47429): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/retry.py:515: MaxRetryError\n[Tests/tests]   | \n[Tests/tests]   | During handling of the above exception, another exception occurred:\n[Tests/tests]   | \n[Tests/tests]   | self = <scrapyd.tests.test_endpoints.TestEndpoint object at 0x7fdc0c28b310>\n[Tests/tests]   | \n[Tests/tests]   |     def test_auth(self):\n[Tests/tests]   |         username, password = \"Leonardo\", \"hunter2\"\n[Tests/tests]   |     \n[Tests/tests]   |         with MockScrapyDServer(\n[Tests/tests]   |                 authentication=username + \":\" + password\n[Tests/tests]   |         ) as server:\n[Tests/tests]   | >           assert requests.get(server.url).status_code == 401\n[Tests/tests]   | \n[Tests/tests]   | scrapyd/tests/test_endpoints.py:51: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:73: in get\n[Tests/tests]   |     return request(\"get\", url, params=params, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:59: in request\n[Tests/tests]   |     return session.request(method=method, url=url, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:589: in request\n[Tests/tests]   |     resp = self.send(prep, **send_kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:703: in send\n[Tests/tests]   |     r = adapter.send(request, **kwargs)\n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0bee58d0>\n[Tests/tests]   | request = <PreparedRequest [GET]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |         except (ProtocolError, OSError) as err:\n[Tests/tests]   |             raise ConnectionError(err, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         except MaxRetryError as e:\n[Tests/tests]   |             if isinstance(e.reason, ConnectTimeoutError):\n[Tests/tests]   |                 # TODO: Remove this in 3.0.0: see #2811\n[Tests/tests]   |                 if not isinstance(e.reason, NewConnectionError):\n[Tests/tests]   |                     raise ConnectTimeout(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, ResponseError):\n[Tests/tests]   |                 raise RetryError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _ProxyError):\n[Tests/tests]   |                 raise ProxyError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _SSLError):\n[Tests/tests]   |                 # This branch is for urllib3 v1.22 and later.\n[Tests/tests]   |                 raise SSLError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   | >           raise ConnectionError(e, request=request)\n[Tests/tests]   | E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=47429): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:519: ConnectionError\n[Tests/tests]   | _____________________ TestEndpoint.test_launch_spider_get ______________________\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   | >               socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:204: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 39563), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   |                 sock.connect(sa)\n[Tests/tests]   |                 # Break explicitly a reference cycle\n[Tests/tests]   |                 err = None\n[Tests/tests]   |                 return sock\n[Tests/tests]   |     \n[Tests/tests]   |             except OSError as _:\n[Tests/tests]   |                 err = _\n[Tests/tests]   |                 if sock is not None:\n[Tests/tests]   |                     sock.close()\n[Tests/tests]   |     \n[Tests/tests]   |         if err is not None:\n[Tests/tests]   |             try:\n[Tests/tests]   | >               raise err\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:85: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 39563), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   | >               sock.connect(sa)\n[Tests/tests]   | E               ConnectionRefusedError: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:73: ConnectionRefusedError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bf151d0>\n[Tests/tests]   | method = 'GET', url = '/schedule.json', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/schedule.json', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:802: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bf151d0>\n[Tests/tests]   | conn = <urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>\n[Tests/tests]   | method = 'GET', url = '/schedule.json', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), chunked = False\n[Tests/tests]   | response_conn = <urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>\n[Tests/tests]   | preload_content = False, decode_content = False, enforce_content_length = True\n[Tests/tests]   | \n[Tests/tests]   |     def _make_request(\n[Tests/tests]   |         self,\n[Tests/tests]   |         conn: BaseHTTPConnection,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | None = None,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         response_conn: BaseHTTPConnection | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Perform a request on a given urllib connection object taken from our\n[Tests/tests]   |         pool.\n[Tests/tests]   |     \n[Tests/tests]   |         :param conn:\n[Tests/tests]   |             a connection from one of our connection pools\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response_conn:\n[Tests/tests]   |             Set this to ``None`` if you will handle releasing the connection or\n[Tests/tests]   |             set the connection to have the response release it.\n[Tests/tests]   |     \n[Tests/tests]   |         :param preload_content:\n[Tests/tests]   |           If True, the response's body will be preloaded during construction.\n[Tests/tests]   |     \n[Tests/tests]   |         :param decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param enforce_content_length:\n[Tests/tests]   |             Enforce content length checking. Body returned by server must match\n[Tests/tests]   |             value of Content-Length header, if present. Otherwise, raise error.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self.num_requests += 1\n[Tests/tests]   |     \n[Tests/tests]   |         timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |         timeout_obj.start_connect()\n[Tests/tests]   |         conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Trigger any extra validation we need to do.\n[Tests/tests]   |             try:\n[Tests/tests]   |                 self._validate_conn(conn)\n[Tests/tests]   |             except (SocketTimeout, BaseSSLError) as e:\n[Tests/tests]   |                 self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n[Tests/tests]   |                 raise\n[Tests/tests]   |     \n[Tests/tests]   |         # _validate_conn() starts the connection to an HTTPS proxy\n[Tests/tests]   |         # so we need to wrap errors with 'ProxyError' here too.\n[Tests/tests]   |         except (\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             NewConnectionError,\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             # If the connection didn't successfully connect to it's proxy\n[Tests/tests]   |             # then there\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e, (OSError, NewConnectionError, TimeoutError, SSLError)\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             raise new_e\n[Tests/tests]   |     \n[Tests/tests]   |         # conn.request() calls http.client.*.request, not the method in\n[Tests/tests]   |         # urllib3.request. It also calls makefile (recv) on the socket.\n[Tests/tests]   |         try:\n[Tests/tests]   |             conn.request(\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               enforce_content_length=enforce_content_length,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:504: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>\n[Tests/tests]   | method = 'GET', url = '/schedule.json', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | \n[Tests/tests]   |     def request(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         *,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> None:\n[Tests/tests]   |         # Update the inner socket's timeout value to send the request.\n[Tests/tests]   |         # This only triggers if the connection is re-used.\n[Tests/tests]   |         if self.sock is not None:\n[Tests/tests]   |             self.sock.settimeout(self.timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         # Store these values to be fed into the HTTPResponse\n[Tests/tests]   |         # object later. TODO: Remove this in favor of a real\n[Tests/tests]   |         # HTTP lifecycle mechanism.\n[Tests/tests]   |     \n[Tests/tests]   |         # We have to store these before we call .request()\n[Tests/tests]   |         # because sometimes we can still salvage a response\n[Tests/tests]   |         # off the wire even if we aren't able to completely\n[Tests/tests]   |         # send the request body.\n[Tests/tests]   |         self._response_options = _ResponseOptions(\n[Tests/tests]   |             request_method=method,\n[Tests/tests]   |             request_url=url,\n[Tests/tests]   |             preload_content=preload_content,\n[Tests/tests]   |             decode_content=decode_content,\n[Tests/tests]   |             enforce_content_length=enforce_content_length,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = {}\n[Tests/tests]   |         header_keys = frozenset(to_str(k.lower()) for k in headers)\n[Tests/tests]   |         skip_accept_encoding = \"accept-encoding\" in header_keys\n[Tests/tests]   |         skip_host = \"host\" in header_keys\n[Tests/tests]   |         self.putrequest(\n[Tests/tests]   |             method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Transform the body into an iterable of sendall()-able chunks\n[Tests/tests]   |         # and detect if an explicit Content-Length is doable.\n[Tests/tests]   |         chunks_and_cl = body_to_chunks(body, method=method, blocksize=self.blocksize)\n[Tests/tests]   |         chunks = chunks_and_cl.chunks\n[Tests/tests]   |         content_length = chunks_and_cl.content_length\n[Tests/tests]   |     \n[Tests/tests]   |         # When chunked is explicit set to 'True' we respect that.\n[Tests/tests]   |         if chunked:\n[Tests/tests]   |             if \"transfer-encoding\" not in header_keys:\n[Tests/tests]   |                 self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |         else:\n[Tests/tests]   |             # Detect whether a framing mechanism is already in use. If so\n[Tests/tests]   |             # we respect that value, otherwise we pick chunked vs content-length\n[Tests/tests]   |             # depending on the type of 'body'.\n[Tests/tests]   |             if \"content-length\" in header_keys:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |             elif \"transfer-encoding\" in header_keys:\n[Tests/tests]   |                 chunked = True\n[Tests/tests]   |     \n[Tests/tests]   |             # Otherwise we go off the recommendation of 'body_to_chunks()'.\n[Tests/tests]   |             else:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |                 if content_length is None:\n[Tests/tests]   |                     if chunks is not None:\n[Tests/tests]   |                         chunked = True\n[Tests/tests]   |                         self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |                 else:\n[Tests/tests]   |                     self.putheader(\"Content-Length\", str(content_length))\n[Tests/tests]   |     \n[Tests/tests]   |         # Now that framing headers are out of the way we send all the other headers.\n[Tests/tests]   |         if \"user-agent\" not in header_keys:\n[Tests/tests]   |             self.putheader(\"User-Agent\", _get_default_user_agent())\n[Tests/tests]   |         for header, value in headers.items():\n[Tests/tests]   |             self.putheader(header, value)\n[Tests/tests]   | >       self.endheaders()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:388: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>\n[Tests/tests]   | message_body = None\n[Tests/tests]   | \n[Tests/tests]   |     def endheaders(self, message_body=None, *, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Indicate that the last header line has been sent to the server.\n[Tests/tests]   |     \n[Tests/tests]   |         This method sends the request to the server.  The optional message_body\n[Tests/tests]   |         argument can be used to pass a message body associated with the\n[Tests/tests]   |         request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.__state == _CS_REQ_STARTED:\n[Tests/tests]   |             self.__state = _CS_REQ_SENT\n[Tests/tests]   |         else:\n[Tests/tests]   |             raise CannotSendHeader()\n[Tests/tests]   | >       self._send_output(message_body, encode_chunked=encode_chunked)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1276: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>\n[Tests/tests]   | message_body = None, encode_chunked = False\n[Tests/tests]   | \n[Tests/tests]   |     def _send_output(self, message_body=None, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Send the currently buffered request and clear the buffer.\n[Tests/tests]   |     \n[Tests/tests]   |         Appends an extra \\\\r\\\\n to the buffer.\n[Tests/tests]   |         A message_body may be specified, to be appended to the request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self._buffer.extend((b\"\", b\"\"))\n[Tests/tests]   |         msg = b\"\\r\\n\".join(self._buffer)\n[Tests/tests]   |         del self._buffer[:]\n[Tests/tests]   | >       self.send(msg)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1036: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>\n[Tests/tests]   | data = b'GET /schedule.json HTTP/1.1\\r\\nHost: 127.0.0.1:39563\\r\\nUser-Agent: python-requests/2.31.0\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept: */*\\r\\nConnection: keep-alive\\r\\n\\r\\n'\n[Tests/tests]   | \n[Tests/tests]   |     def send(self, data):\n[Tests/tests]   |         \"\"\"Send `data' to the server.\n[Tests/tests]   |         ``data`` can be a string object, a bytes object, an array object, a\n[Tests/tests]   |         file-like object that supports a .read() method, or an iterable object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         if self.sock is None:\n[Tests/tests]   |             if self.auto_open:\n[Tests/tests]   | >               self.connect()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:976: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>\n[Tests/tests]   | \n[Tests/tests]   |     def connect(self) -> None:\n[Tests/tests]   | >       self.sock = self._new_conn()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:236: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   |                 socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   |         except socket.gaierror as e:\n[Tests/tests]   |             raise NameResolutionError(self.host, self, e) from e\n[Tests/tests]   |         except SocketTimeout as e:\n[Tests/tests]   |             raise ConnectTimeoutError(\n[Tests/tests]   |                 self,\n[Tests/tests]   |                 f\"Connection to {self.host} timed out. (connect timeout={self.timeout})\",\n[Tests/tests]   |             ) from e\n[Tests/tests]   |     \n[Tests/tests]   |         except OSError as e:\n[Tests/tests]   |             raise NewConnectionError(\n[Tests/tests]   |                 self, f\"Failed to establish a new connection: {e}\"\n[Tests/tests]   | >           ) from e\n[Tests/tests]   | E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>: Failed to establish a new connection: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:217: NewConnectionError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0bf15e90>\n[Tests/tests]   | request = <PreparedRequest [GET]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   | >               chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:497: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bf151d0>\n[Tests/tests]   | method = 'GET', url = '/schedule.json', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/schedule.json', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   |                 **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |             # Everything went great!\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |     \n[Tests/tests]   |         except EmptyPoolError:\n[Tests/tests]   |             # Didn't get a connection from the pool, no need to clean up\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |             release_this_conn = False\n[Tests/tests]   |             raise\n[Tests/tests]   |     \n[Tests/tests]   |         except (\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             HTTPException,\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             ProtocolError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             ProxyError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             # Discard the connection for these exceptions. It will be\n[Tests/tests]   |             # replaced during the next _get_conn() call.\n[Tests/tests]   |             clean_exit = False\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e,\n[Tests/tests]   |                 (\n[Tests/tests]   |                     OSError,\n[Tests/tests]   |                     NewConnectionError,\n[Tests/tests]   |                     TimeoutError,\n[Tests/tests]   |                     SSLError,\n[Tests/tests]   |                     HTTPException,\n[Tests/tests]   |                 ),\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             elif isinstance(new_e, (OSError, HTTPException)):\n[Tests/tests]   |                 new_e = ProtocolError(\"Connection aborted.\", new_e)\n[Tests/tests]   |     \n[Tests/tests]   |             retries = retries.increment(\n[Tests/tests]   | >               method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:845: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | method = 'GET', url = '/schedule.json', response = None\n[Tests/tests]   | error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>: Failed to establish a new connection: [Errno 111] Connection refused')\n[Tests/tests]   | _pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bf151d0>\n[Tests/tests]   | _stacktrace = <traceback object at 0x7fdc0bcc7fa0>\n[Tests/tests]   | \n[Tests/tests]   |     def increment(\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str | None = None,\n[Tests/tests]   |         url: str | None = None,\n[Tests/tests]   |         response: BaseHTTPResponse | None = None,\n[Tests/tests]   |         error: Exception | None = None,\n[Tests/tests]   |         _pool: ConnectionPool | None = None,\n[Tests/tests]   |         _stacktrace: TracebackType | None = None,\n[Tests/tests]   |     ) -> Retry:\n[Tests/tests]   |         \"\"\"Return a new Retry object with incremented retry counters.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response: A response object, or None, if the server did not\n[Tests/tests]   |             return a response.\n[Tests/tests]   |         :type response: :class:`~urllib3.response.BaseHTTPResponse`\n[Tests/tests]   |         :param Exception error: An error encountered during the request, or\n[Tests/tests]   |             None if the response was received successfully.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: A new ``Retry`` object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.total is False and error:\n[Tests/tests]   |             # Disabled, indicate to re-raise the error.\n[Tests/tests]   |             raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |     \n[Tests/tests]   |         total = self.total\n[Tests/tests]   |         if total is not None:\n[Tests/tests]   |             total -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         connect = self.connect\n[Tests/tests]   |         read = self.read\n[Tests/tests]   |         redirect = self.redirect\n[Tests/tests]   |         status_count = self.status\n[Tests/tests]   |         other = self.other\n[Tests/tests]   |         cause = \"unknown\"\n[Tests/tests]   |         status = None\n[Tests/tests]   |         redirect_location = None\n[Tests/tests]   |     \n[Tests/tests]   |         if error and self._is_connection_error(error):\n[Tests/tests]   |             # Connect retry?\n[Tests/tests]   |             if connect is False:\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif connect is not None:\n[Tests/tests]   |                 connect -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error and self._is_read_error(error):\n[Tests/tests]   |             # Read retry?\n[Tests/tests]   |             if read is False or method is None or not self._is_method_retryable(method):\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif read is not None:\n[Tests/tests]   |                 read -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error:\n[Tests/tests]   |             # Other retry?\n[Tests/tests]   |             if other is not None:\n[Tests/tests]   |                 other -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif response and response.get_redirect_location():\n[Tests/tests]   |             # Redirect retry?\n[Tests/tests]   |             if redirect is not None:\n[Tests/tests]   |                 redirect -= 1\n[Tests/tests]   |             cause = \"too many redirects\"\n[Tests/tests]   |             response_redirect_location = response.get_redirect_location()\n[Tests/tests]   |             if response_redirect_location:\n[Tests/tests]   |                 redirect_location = response_redirect_location\n[Tests/tests]   |             status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         else:\n[Tests/tests]   |             # Incrementing because of a server error like a 500 in\n[Tests/tests]   |             # status_forcelist and the given method is in the allowed_methods\n[Tests/tests]   |             cause = ResponseError.GENERIC_ERROR\n[Tests/tests]   |             if response and response.status:\n[Tests/tests]   |                 if status_count is not None:\n[Tests/tests]   |                     status_count -= 1\n[Tests/tests]   |                 cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n[Tests/tests]   |                 status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         history = self.history + (\n[Tests/tests]   |             RequestHistory(method, url, error, status, redirect_location),\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         new_retry = self.new(\n[Tests/tests]   |             total=total,\n[Tests/tests]   |             connect=connect,\n[Tests/tests]   |             read=read,\n[Tests/tests]   |             redirect=redirect,\n[Tests/tests]   |             status=status_count,\n[Tests/tests]   |             other=other,\n[Tests/tests]   |             history=history,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if new_retry.is_exhausted():\n[Tests/tests]   |             reason = error or ResponseError(cause)\n[Tests/tests]   | >           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n[Tests/tests]   | E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=39563): Max retries exceeded with url: /schedule.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/retry.py:515: MaxRetryError\n[Tests/tests]   | \n[Tests/tests]   | During handling of the above exception, another exception occurred:\n[Tests/tests]   | \n[Tests/tests]   | self = <scrapyd.tests.test_endpoints.TestEndpoint object at 0x7fdc0c28b390>\n[Tests/tests]   | mock_scrapyd = <scrapyd.tests.mockserver.MockScrapyDServer object at 0x7fdc0bbe3a10>\n[Tests/tests]   | \n[Tests/tests]   |     def test_launch_spider_get(self, mock_scrapyd):\n[Tests/tests]   | >       resp = requests.get(mock_scrapyd.urljoin(\"schedule.json\"))\n[Tests/tests]   | \n[Tests/tests]   | scrapyd/tests/test_endpoints.py:63: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:73: in get\n[Tests/tests]   |     return request(\"get\", url, params=params, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:59: in request\n[Tests/tests]   |     return session.request(method=method, url=url, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:589: in request\n[Tests/tests]   |     resp = self.send(prep, **send_kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:703: in send\n[Tests/tests]   |     r = adapter.send(request, **kwargs)\n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0bf15e90>\n[Tests/tests]   | request = <PreparedRequest [GET]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |         except (ProtocolError, OSError) as err:\n[Tests/tests]   |             raise ConnectionError(err, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         except MaxRetryError as e:\n[Tests/tests]   |             if isinstance(e.reason, ConnectTimeoutError):\n[Tests/tests]   |                 # TODO: Remove this in 3.0.0: see #2811\n[Tests/tests]   |                 if not isinstance(e.reason, NewConnectionError):\n[Tests/tests]   |                     raise ConnectTimeout(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, ResponseError):\n[Tests/tests]   |                 raise RetryError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _ProxyError):\n[Tests/tests]   |                 raise ProxyError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _SSLError):\n[Tests/tests]   |                 # This branch is for urllib3 v1.22 and later.\n[Tests/tests]   |                 raise SSLError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   | >           raise ConnectionError(e, request=request)\n[Tests/tests]   | E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=39563): Max retries exceeded with url: /schedule.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:519: ConnectionError\n[Tests/tests]   | _________________ TestEndpoint.test_spider_list_project_no_egg _________________\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   | >               socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:204: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 41915), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   |                 sock.connect(sa)\n[Tests/tests]   |                 # Break explicitly a reference cycle\n[Tests/tests]   |                 err = None\n[Tests/tests]   |                 return sock\n[Tests/tests]   |     \n[Tests/tests]   |             except OSError as _:\n[Tests/tests]   |                 err = _\n[Tests/tests]   |                 if sock is not None:\n[Tests/tests]   |                     sock.close()\n[Tests/tests]   |     \n[Tests/tests]   |         if err is not None:\n[Tests/tests]   |             try:\n[Tests/tests]   | >               raise err\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:85: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 41915), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   | >               sock.connect(sa)\n[Tests/tests]   | E               ConnectionRefusedError: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:73: ConnectionRefusedError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bb8eb90>\n[Tests/tests]   | method = 'GET', url = '/listprojects.json', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/listprojects.json', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:802: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bb8eb90>\n[Tests/tests]   | conn = <urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>\n[Tests/tests]   | method = 'GET', url = '/listprojects.json', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), chunked = False\n[Tests/tests]   | response_conn = <urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>\n[Tests/tests]   | preload_content = False, decode_content = False, enforce_content_length = True\n[Tests/tests]   | \n[Tests/tests]   |     def _make_request(\n[Tests/tests]   |         self,\n[Tests/tests]   |         conn: BaseHTTPConnection,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | None = None,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         response_conn: BaseHTTPConnection | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Perform a request on a given urllib connection object taken from our\n[Tests/tests]   |         pool.\n[Tests/tests]   |     \n[Tests/tests]   |         :param conn:\n[Tests/tests]   |             a connection from one of our connection pools\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response_conn:\n[Tests/tests]   |             Set this to ``None`` if you will handle releasing the connection or\n[Tests/tests]   |             set the connection to have the response release it.\n[Tests/tests]   |     \n[Tests/tests]   |         :param preload_content:\n[Tests/tests]   |           If True, the response's body will be preloaded during construction.\n[Tests/tests]   |     \n[Tests/tests]   |         :param decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param enforce_content_length:\n[Tests/tests]   |             Enforce content length checking. Body returned by server must match\n[Tests/tests]   |             value of Content-Length header, if present. Otherwise, raise error.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self.num_requests += 1\n[Tests/tests]   |     \n[Tests/tests]   |         timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |         timeout_obj.start_connect()\n[Tests/tests]   |         conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Trigger any extra validation we need to do.\n[Tests/tests]   |             try:\n[Tests/tests]   |                 self._validate_conn(conn)\n[Tests/tests]   |             except (SocketTimeout, BaseSSLError) as e:\n[Tests/tests]   |                 self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n[Tests/tests]   |                 raise\n[Tests/tests]   |     \n[Tests/tests]   |         # _validate_conn() starts the connection to an HTTPS proxy\n[Tests/tests]   |         # so we need to wrap errors with 'ProxyError' here too.\n[Tests/tests]   |         except (\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             NewConnectionError,\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             # If the connection didn't successfully connect to it's proxy\n[Tests/tests]   |             # then there\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e, (OSError, NewConnectionError, TimeoutError, SSLError)\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             raise new_e\n[Tests/tests]   |     \n[Tests/tests]   |         # conn.request() calls http.client.*.request, not the method in\n[Tests/tests]   |         # urllib3.request. It also calls makefile (recv) on the socket.\n[Tests/tests]   |         try:\n[Tests/tests]   |             conn.request(\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               enforce_content_length=enforce_content_length,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:504: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>\n[Tests/tests]   | method = 'GET', url = '/listprojects.json', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | \n[Tests/tests]   |     def request(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         *,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> None:\n[Tests/tests]   |         # Update the inner socket's timeout value to send the request.\n[Tests/tests]   |         # This only triggers if the connection is re-used.\n[Tests/tests]   |         if self.sock is not None:\n[Tests/tests]   |             self.sock.settimeout(self.timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         # Store these values to be fed into the HTTPResponse\n[Tests/tests]   |         # object later. TODO: Remove this in favor of a real\n[Tests/tests]   |         # HTTP lifecycle mechanism.\n[Tests/tests]   |     \n[Tests/tests]   |         # We have to store these before we call .request()\n[Tests/tests]   |         # because sometimes we can still salvage a response\n[Tests/tests]   |         # off the wire even if we aren't able to completely\n[Tests/tests]   |         # send the request body.\n[Tests/tests]   |         self._response_options = _ResponseOptions(\n[Tests/tests]   |             request_method=method,\n[Tests/tests]   |             request_url=url,\n[Tests/tests]   |             preload_content=preload_content,\n[Tests/tests]   |             decode_content=decode_content,\n[Tests/tests]   |             enforce_content_length=enforce_content_length,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = {}\n[Tests/tests]   |         header_keys = frozenset(to_str(k.lower()) for k in headers)\n[Tests/tests]   |         skip_accept_encoding = \"accept-encoding\" in header_keys\n[Tests/tests]   |         skip_host = \"host\" in header_keys\n[Tests/tests]   |         self.putrequest(\n[Tests/tests]   |             method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Transform the body into an iterable of sendall()-able chunks\n[Tests/tests]   |         # and detect if an explicit Content-Length is doable.\n[Tests/tests]   |         chunks_and_cl = body_to_chunks(body, method=method, blocksize=self.blocksize)\n[Tests/tests]   |         chunks = chunks_and_cl.chunks\n[Tests/tests]   |         content_length = chunks_and_cl.content_length\n[Tests/tests]   |     \n[Tests/tests]   |         # When chunked is explicit set to 'True' we respect that.\n[Tests/tests]   |         if chunked:\n[Tests/tests]   |             if \"transfer-encoding\" not in header_keys:\n[Tests/tests]   |                 self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |         else:\n[Tests/tests]   |             # Detect whether a framing mechanism is already in use. If so\n[Tests/tests]   |             # we respect that value, otherwise we pick chunked vs content-length\n[Tests/tests]   |             # depending on the type of 'body'.\n[Tests/tests]   |             if \"content-length\" in header_keys:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |             elif \"transfer-encoding\" in header_keys:\n[Tests/tests]   |                 chunked = True\n[Tests/tests]   |     \n[Tests/tests]   |             # Otherwise we go off the recommendation of 'body_to_chunks()'.\n[Tests/tests]   |             else:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |                 if content_length is None:\n[Tests/tests]   |                     if chunks is not None:\n[Tests/tests]   |                         chunked = True\n[Tests/tests]   |                         self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |                 else:\n[Tests/tests]   |                     self.putheader(\"Content-Length\", str(content_length))\n[Tests/tests]   |     \n[Tests/tests]   |         # Now that framing headers are out of the way we send all the other headers.\n[Tests/tests]   |         if \"user-agent\" not in header_keys:\n[Tests/tests]   |             self.putheader(\"User-Agent\", _get_default_user_agent())\n[Tests/tests]   |         for header, value in headers.items():\n[Tests/tests]   |             self.putheader(header, value)\n[Tests/tests]   | >       self.endheaders()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:388: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>\n[Tests/tests]   | message_body = None\n[Tests/tests]   | \n[Tests/tests]   |     def endheaders(self, message_body=None, *, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Indicate that the last header line has been sent to the server.\n[Tests/tests]   |     \n[Tests/tests]   |         This method sends the request to the server.  The optional message_body\n[Tests/tests]   |         argument can be used to pass a message body associated with the\n[Tests/tests]   |         request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.__state == _CS_REQ_STARTED:\n[Tests/tests]   |             self.__state = _CS_REQ_SENT\n[Tests/tests]   |         else:\n[Tests/tests]   |             raise CannotSendHeader()\n[Tests/tests]   | >       self._send_output(message_body, encode_chunked=encode_chunked)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1276: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>\n[Tests/tests]   | message_body = None, encode_chunked = False\n[Tests/tests]   | \n[Tests/tests]   |     def _send_output(self, message_body=None, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Send the currently buffered request and clear the buffer.\n[Tests/tests]   |     \n[Tests/tests]   |         Appends an extra \\\\r\\\\n to the buffer.\n[Tests/tests]   |         A message_body may be specified, to be appended to the request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self._buffer.extend((b\"\", b\"\"))\n[Tests/tests]   |         msg = b\"\\r\\n\".join(self._buffer)\n[Tests/tests]   |         del self._buffer[:]\n[Tests/tests]   | >       self.send(msg)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1036: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>\n[Tests/tests]   | data = b'GET /listprojects.json HTTP/1.1\\r\\nHost: 127.0.0.1:41915\\r\\nUser-Agent: python-requests/2.31.0\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept: */*\\r\\nConnection: keep-alive\\r\\n\\r\\n'\n[Tests/tests]   | \n[Tests/tests]   |     def send(self, data):\n[Tests/tests]   |         \"\"\"Send `data' to the server.\n[Tests/tests]   |         ``data`` can be a string object, a bytes object, an array object, a\n[Tests/tests]   |         file-like object that supports a .read() method, or an iterable object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         if self.sock is None:\n[Tests/tests]   |             if self.auto_open:\n[Tests/tests]   | >               self.connect()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:976: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>\n[Tests/tests]   | \n[Tests/tests]   |     def connect(self) -> None:\n[Tests/tests]   | >       self.sock = self._new_conn()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:236: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   |                 socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   |         except socket.gaierror as e:\n[Tests/tests]   |             raise NameResolutionError(self.host, self, e) from e\n[Tests/tests]   |         except SocketTimeout as e:\n[Tests/tests]   |             raise ConnectTimeoutError(\n[Tests/tests]   |                 self,\n[Tests/tests]   |                 f\"Connection to {self.host} timed out. (connect timeout={self.timeout})\",\n[Tests/tests]   |             ) from e\n[Tests/tests]   |     \n[Tests/tests]   |         except OSError as e:\n[Tests/tests]   |             raise NewConnectionError(\n[Tests/tests]   |                 self, f\"Failed to establish a new connection: {e}\"\n[Tests/tests]   | >           ) from e\n[Tests/tests]   | E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>: Failed to establish a new connection: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:217: NewConnectionError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0bb8edd0>\n[Tests/tests]   | request = <PreparedRequest [GET]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   | >               chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:497: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bb8eb90>\n[Tests/tests]   | method = 'GET', url = '/listprojects.json', body = None\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/listprojects.json', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   |                 **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |             # Everything went great!\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |     \n[Tests/tests]   |         except EmptyPoolError:\n[Tests/tests]   |             # Didn't get a connection from the pool, no need to clean up\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |             release_this_conn = False\n[Tests/tests]   |             raise\n[Tests/tests]   |     \n[Tests/tests]   |         except (\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             HTTPException,\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             ProtocolError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             ProxyError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             # Discard the connection for these exceptions. It will be\n[Tests/tests]   |             # replaced during the next _get_conn() call.\n[Tests/tests]   |             clean_exit = False\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e,\n[Tests/tests]   |                 (\n[Tests/tests]   |                     OSError,\n[Tests/tests]   |                     NewConnectionError,\n[Tests/tests]   |                     TimeoutError,\n[Tests/tests]   |                     SSLError,\n[Tests/tests]   |                     HTTPException,\n[Tests/tests]   |                 ),\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             elif isinstance(new_e, (OSError, HTTPException)):\n[Tests/tests]   |                 new_e = ProtocolError(\"Connection aborted.\", new_e)\n[Tests/tests]   |     \n[Tests/tests]   |             retries = retries.increment(\n[Tests/tests]   | >               method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:845: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | method = 'GET', url = '/listprojects.json', response = None\n[Tests/tests]   | error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>: Failed to establish a new connection: [Errno 111] Connection refused')\n[Tests/tests]   | _pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bb8eb90>\n[Tests/tests]   | _stacktrace = <traceback object at 0x7fdc0bb8c910>\n[Tests/tests]   | \n[Tests/tests]   |     def increment(\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str | None = None,\n[Tests/tests]   |         url: str | None = None,\n[Tests/tests]   |         response: BaseHTTPResponse | None = None,\n[Tests/tests]   |         error: Exception | None = None,\n[Tests/tests]   |         _pool: ConnectionPool | None = None,\n[Tests/tests]   |         _stacktrace: TracebackType | None = None,\n[Tests/tests]   |     ) -> Retry:\n[Tests/tests]   |         \"\"\"Return a new Retry object with incremented retry counters.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response: A response object, or None, if the server did not\n[Tests/tests]   |             return a response.\n[Tests/tests]   |         :type response: :class:`~urllib3.response.BaseHTTPResponse`\n[Tests/tests]   |         :param Exception error: An error encountered during the request, or\n[Tests/tests]   |             None if the response was received successfully.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: A new ``Retry`` object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.total is False and error:\n[Tests/tests]   |             # Disabled, indicate to re-raise the error.\n[Tests/tests]   |             raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |     \n[Tests/tests]   |         total = self.total\n[Tests/tests]   |         if total is not None:\n[Tests/tests]   |             total -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         connect = self.connect\n[Tests/tests]   |         read = self.read\n[Tests/tests]   |         redirect = self.redirect\n[Tests/tests]   |         status_count = self.status\n[Tests/tests]   |         other = self.other\n[Tests/tests]   |         cause = \"unknown\"\n[Tests/tests]   |         status = None\n[Tests/tests]   |         redirect_location = None\n[Tests/tests]   |     \n[Tests/tests]   |         if error and self._is_connection_error(error):\n[Tests/tests]   |             # Connect retry?\n[Tests/tests]   |             if connect is False:\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif connect is not None:\n[Tests/tests]   |                 connect -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error and self._is_read_error(error):\n[Tests/tests]   |             # Read retry?\n[Tests/tests]   |             if read is False or method is None or not self._is_method_retryable(method):\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif read is not None:\n[Tests/tests]   |                 read -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error:\n[Tests/tests]   |             # Other retry?\n[Tests/tests]   |             if other is not None:\n[Tests/tests]   |                 other -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif response and response.get_redirect_location():\n[Tests/tests]   |             # Redirect retry?\n[Tests/tests]   |             if redirect is not None:\n[Tests/tests]   |                 redirect -= 1\n[Tests/tests]   |             cause = \"too many redirects\"\n[Tests/tests]   |             response_redirect_location = response.get_redirect_location()\n[Tests/tests]   |             if response_redirect_location:\n[Tests/tests]   |                 redirect_location = response_redirect_location\n[Tests/tests]   |             status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         else:\n[Tests/tests]   |             # Incrementing because of a server error like a 500 in\n[Tests/tests]   |             # status_forcelist and the given method is in the allowed_methods\n[Tests/tests]   |             cause = ResponseError.GENERIC_ERROR\n[Tests/tests]   |             if response and response.status:\n[Tests/tests]   |                 if status_count is not None:\n[Tests/tests]   |                     status_count -= 1\n[Tests/tests]   |                 cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n[Tests/tests]   |                 status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         history = self.history + (\n[Tests/tests]   |             RequestHistory(method, url, error, status, redirect_location),\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         new_retry = self.new(\n[Tests/tests]   |             total=total,\n[Tests/tests]   |             connect=connect,\n[Tests/tests]   |             read=read,\n[Tests/tests]   |             redirect=redirect,\n[Tests/tests]   |             status=status_count,\n[Tests/tests]   |             other=other,\n[Tests/tests]   |             history=history,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if new_retry.is_exhausted():\n[Tests/tests]   |             reason = error or ResponseError(cause)\n[Tests/tests]   | >           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n[Tests/tests]   | E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=41915): Max retries exceeded with url: /listprojects.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/retry.py:515: MaxRetryError\n[Tests/tests]   | \n[Tests/tests]   | During handling of the above exception, another exception occurred:\n[Tests/tests]   | \n[Tests/tests]   | self = <scrapyd.tests.test_endpoints.TestEndpoint object at 0x7fdc0c28b710>\n[Tests/tests]   | mock_scrapyd = <scrapyd.tests.mockserver.MockScrapyDServer object at 0x7fdc0bb8e190>\n[Tests/tests]   | \n[Tests/tests]   |     def test_spider_list_project_no_egg(self, mock_scrapyd):\n[Tests/tests]   | >       resp = requests.get(mock_scrapyd.urljoin('listprojects.json'))\n[Tests/tests]   | \n[Tests/tests]   | scrapyd/tests/test_endpoints.py:77: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:73: in get\n[Tests/tests]   |     return request(\"get\", url, params=params, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:59: in request\n[Tests/tests]   |     return session.request(method=method, url=url, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:589: in request\n[Tests/tests]   |     resp = self.send(prep, **send_kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:703: in send\n[Tests/tests]   |     r = adapter.send(request, **kwargs)\n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0bb8edd0>\n[Tests/tests]   | request = <PreparedRequest [GET]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |         except (ProtocolError, OSError) as err:\n[Tests/tests]   |             raise ConnectionError(err, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         except MaxRetryError as e:\n[Tests/tests]   |             if isinstance(e.reason, ConnectTimeoutError):\n[Tests/tests]   |                 # TODO: Remove this in 3.0.0: see #2811\n[Tests/tests]   |                 if not isinstance(e.reason, NewConnectionError):\n[Tests/tests]   |                     raise ConnectTimeout(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, ResponseError):\n[Tests/tests]   |                 raise RetryError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _ProxyError):\n[Tests/tests]   |                 raise ProxyError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _SSLError):\n[Tests/tests]   |                 # This branch is for urllib3 v1.22 and later.\n[Tests/tests]   |                 raise SSLError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   | >           raise ConnectionError(e, request=request)\n[Tests/tests]   | E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=41915): Max retries exceeded with url: /listprojects.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:519: ConnectionError\n[Tests/tests]   | _________________ TestEndpoint.test_addversion_and_delversion __________________\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   | >               socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:204: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 56945), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   |                 sock.connect(sa)\n[Tests/tests]   |                 # Break explicitly a reference cycle\n[Tests/tests]   |                 err = None\n[Tests/tests]   |                 return sock\n[Tests/tests]   |     \n[Tests/tests]   |             except OSError as _:\n[Tests/tests]   |                 err = _\n[Tests/tests]   |                 if sock is not None:\n[Tests/tests]   |                     sock.close()\n[Tests/tests]   |     \n[Tests/tests]   |         if err is not None:\n[Tests/tests]   |             try:\n[Tests/tests]   | >               raise err\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:85: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 56945), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   | >               sock.connect(sa)\n[Tests/tests]   | E               ConnectionRefusedError: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:73: ConnectionRefusedError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0ba64fd0>\n[Tests/tests]   | method = 'POST', url = '/addversion.json'\n[Tests/tests]   | body = b'--525ac43aac6049be724cc7dead5d1c18\\r\\nContent-Disposition: form-data; name=\"project\"\\r\\n\\r\\nquotesbot\\r\\n--525ac43aa...5\\x06\\x00\\x00\\x00\\x00\\x14\\x00\\x14\\x00(\\x06\\x00\\x00\\x15\\x18\\x00\\x00\\x00\\x00\\r\\n--525ac43aac6049be724cc7dead5d1c18--\\r\\n'\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '8100', 'Content-Type': 'multipart/form-data; boundary=525ac43aac6049be724cc7dead5d1c18'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/addversion.json', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:802: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0ba64fd0>\n[Tests/tests]   | conn = <urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>\n[Tests/tests]   | method = 'POST', url = '/addversion.json'\n[Tests/tests]   | body = b'--525ac43aac6049be724cc7dead5d1c18\\r\\nContent-Disposition: form-data; name=\"project\"\\r\\n\\r\\nquotesbot\\r\\n--525ac43aa...5\\x06\\x00\\x00\\x00\\x00\\x14\\x00\\x14\\x00(\\x06\\x00\\x00\\x15\\x18\\x00\\x00\\x00\\x00\\r\\n--525ac43aac6049be724cc7dead5d1c18--\\r\\n'\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '8100', 'Content-Type': 'multipart/form-data; boundary=525ac43aac6049be724cc7dead5d1c18'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), chunked = False\n[Tests/tests]   | response_conn = <urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>\n[Tests/tests]   | preload_content = False, decode_content = False, enforce_content_length = True\n[Tests/tests]   | \n[Tests/tests]   |     def _make_request(\n[Tests/tests]   |         self,\n[Tests/tests]   |         conn: BaseHTTPConnection,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | None = None,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         response_conn: BaseHTTPConnection | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Perform a request on a given urllib connection object taken from our\n[Tests/tests]   |         pool.\n[Tests/tests]   |     \n[Tests/tests]   |         :param conn:\n[Tests/tests]   |             a connection from one of our connection pools\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response_conn:\n[Tests/tests]   |             Set this to ``None`` if you will handle releasing the connection or\n[Tests/tests]   |             set the connection to have the response release it.\n[Tests/tests]   |     \n[Tests/tests]   |         :param preload_content:\n[Tests/tests]   |           If True, the response's body will be preloaded during construction.\n[Tests/tests]   |     \n[Tests/tests]   |         :param decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param enforce_content_length:\n[Tests/tests]   |             Enforce content length checking. Body returned by server must match\n[Tests/tests]   |             value of Content-Length header, if present. Otherwise, raise error.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self.num_requests += 1\n[Tests/tests]   |     \n[Tests/tests]   |         timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |         timeout_obj.start_connect()\n[Tests/tests]   |         conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Trigger any extra validation we need to do.\n[Tests/tests]   |             try:\n[Tests/tests]   |                 self._validate_conn(conn)\n[Tests/tests]   |             except (SocketTimeout, BaseSSLError) as e:\n[Tests/tests]   |                 self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n[Tests/tests]   |                 raise\n[Tests/tests]   |     \n[Tests/tests]   |         # _validate_conn() starts the connection to an HTTPS proxy\n[Tests/tests]   |         # so we need to wrap errors with 'ProxyError' here too.\n[Tests/tests]   |         except (\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             NewConnectionError,\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             # If the connection didn't successfully connect to it's proxy\n[Tests/tests]   |             # then there\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e, (OSError, NewConnectionError, TimeoutError, SSLError)\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             raise new_e\n[Tests/tests]   |     \n[Tests/tests]   |         # conn.request() calls http.client.*.request, not the method in\n[Tests/tests]   |         # urllib3.request. It also calls makefile (recv) on the socket.\n[Tests/tests]   |         try:\n[Tests/tests]   |             conn.request(\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               enforce_content_length=enforce_content_length,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:504: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>\n[Tests/tests]   | method = 'POST', url = '/addversion.json'\n[Tests/tests]   | body = b'--525ac43aac6049be724cc7dead5d1c18\\r\\nContent-Disposition: form-data; name=\"project\"\\r\\n\\r\\nquotesbot\\r\\n--525ac43aa...5\\x06\\x00\\x00\\x00\\x00\\x14\\x00\\x14\\x00(\\x06\\x00\\x00\\x15\\x18\\x00\\x00\\x00\\x00\\r\\n--525ac43aac6049be724cc7dead5d1c18--\\r\\n'\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '8100', 'Content-Type': 'multipart/form-data; boundary=525ac43aac6049be724cc7dead5d1c18'}\n[Tests/tests]   | \n[Tests/tests]   |     def request(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         *,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> None:\n[Tests/tests]   |         # Update the inner socket's timeout value to send the request.\n[Tests/tests]   |         # This only triggers if the connection is re-used.\n[Tests/tests]   |         if self.sock is not None:\n[Tests/tests]   |             self.sock.settimeout(self.timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         # Store these values to be fed into the HTTPResponse\n[Tests/tests]   |         # object later. TODO: Remove this in favor of a real\n[Tests/tests]   |         # HTTP lifecycle mechanism.\n[Tests/tests]   |     \n[Tests/tests]   |         # We have to store these before we call .request()\n[Tests/tests]   |         # because sometimes we can still salvage a response\n[Tests/tests]   |         # off the wire even if we aren't able to completely\n[Tests/tests]   |         # send the request body.\n[Tests/tests]   |         self._response_options = _ResponseOptions(\n[Tests/tests]   |             request_method=method,\n[Tests/tests]   |             request_url=url,\n[Tests/tests]   |             preload_content=preload_content,\n[Tests/tests]   |             decode_content=decode_content,\n[Tests/tests]   |             enforce_content_length=enforce_content_length,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = {}\n[Tests/tests]   |         header_keys = frozenset(to_str(k.lower()) for k in headers)\n[Tests/tests]   |         skip_accept_encoding = \"accept-encoding\" in header_keys\n[Tests/tests]   |         skip_host = \"host\" in header_keys\n[Tests/tests]   |         self.putrequest(\n[Tests/tests]   |             method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Transform the body into an iterable of sendall()-able chunks\n[Tests/tests]   |         # and detect if an explicit Content-Length is doable.\n[Tests/tests]   |         chunks_and_cl = body_to_chunks(body, method=method, blocksize=self.blocksize)\n[Tests/tests]   |         chunks = chunks_and_cl.chunks\n[Tests/tests]   |         content_length = chunks_and_cl.content_length\n[Tests/tests]   |     \n[Tests/tests]   |         # When chunked is explicit set to 'True' we respect that.\n[Tests/tests]   |         if chunked:\n[Tests/tests]   |             if \"transfer-encoding\" not in header_keys:\n[Tests/tests]   |                 self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |         else:\n[Tests/tests]   |             # Detect whether a framing mechanism is already in use. If so\n[Tests/tests]   |             # we respect that value, otherwise we pick chunked vs content-length\n[Tests/tests]   |             # depending on the type of 'body'.\n[Tests/tests]   |             if \"content-length\" in header_keys:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |             elif \"transfer-encoding\" in header_keys:\n[Tests/tests]   |                 chunked = True\n[Tests/tests]   |     \n[Tests/tests]   |             # Otherwise we go off the recommendation of 'body_to_chunks()'.\n[Tests/tests]   |             else:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |                 if content_length is None:\n[Tests/tests]   |                     if chunks is not None:\n[Tests/tests]   |                         chunked = True\n[Tests/tests]   |                         self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |                 else:\n[Tests/tests]   |                     self.putheader(\"Content-Length\", str(content_length))\n[Tests/tests]   |     \n[Tests/tests]   |         # Now that framing headers are out of the way we send all the other headers.\n[Tests/tests]   |         if \"user-agent\" not in header_keys:\n[Tests/tests]   |             self.putheader(\"User-Agent\", _get_default_user_agent())\n[Tests/tests]   |         for header, value in headers.items():\n[Tests/tests]   |             self.putheader(header, value)\n[Tests/tests]   | >       self.endheaders()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:388: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>\n[Tests/tests]   | message_body = None\n[Tests/tests]   | \n[Tests/tests]   |     def endheaders(self, message_body=None, *, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Indicate that the last header line has been sent to the server.\n[Tests/tests]   |     \n[Tests/tests]   |         This method sends the request to the server.  The optional message_body\n[Tests/tests]   |         argument can be used to pass a message body associated with the\n[Tests/tests]   |         request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.__state == _CS_REQ_STARTED:\n[Tests/tests]   |             self.__state = _CS_REQ_SENT\n[Tests/tests]   |         else:\n[Tests/tests]   |             raise CannotSendHeader()\n[Tests/tests]   | >       self._send_output(message_body, encode_chunked=encode_chunked)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1276: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>\n[Tests/tests]   | message_body = None, encode_chunked = False\n[Tests/tests]   | \n[Tests/tests]   |     def _send_output(self, message_body=None, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Send the currently buffered request and clear the buffer.\n[Tests/tests]   |     \n[Tests/tests]   |         Appends an extra \\\\r\\\\n to the buffer.\n[Tests/tests]   |         A message_body may be specified, to be appended to the request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self._buffer.extend((b\"\", b\"\"))\n[Tests/tests]   |         msg = b\"\\r\\n\".join(self._buffer)\n[Tests/tests]   |         del self._buffer[:]\n[Tests/tests]   | >       self.send(msg)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1036: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>\n[Tests/tests]   | data = b'POST /addversion.json HTTP/1.1\\r\\nHost: 127.0.0.1:56945\\r\\nUser-Agent: python-requests/2.31.0\\r\\nAccept-Encoding: gz...-alive\\r\\nContent-Length: 8100\\r\\nContent-Type: multipart/form-data; boundary=525ac43aac6049be724cc7dead5d1c18\\r\\n\\r\\n'\n[Tests/tests]   | \n[Tests/tests]   |     def send(self, data):\n[Tests/tests]   |         \"\"\"Send `data' to the server.\n[Tests/tests]   |         ``data`` can be a string object, a bytes object, an array object, a\n[Tests/tests]   |         file-like object that supports a .read() method, or an iterable object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         if self.sock is None:\n[Tests/tests]   |             if self.auto_open:\n[Tests/tests]   | >               self.connect()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:976: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>\n[Tests/tests]   | \n[Tests/tests]   |     def connect(self) -> None:\n[Tests/tests]   | >       self.sock = self._new_conn()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:236: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   |                 socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   |         except socket.gaierror as e:\n[Tests/tests]   |             raise NameResolutionError(self.host, self, e) from e\n[Tests/tests]   |         except SocketTimeout as e:\n[Tests/tests]   |             raise ConnectTimeoutError(\n[Tests/tests]   |                 self,\n[Tests/tests]   |                 f\"Connection to {self.host} timed out. (connect timeout={self.timeout})\",\n[Tests/tests]   |             ) from e\n[Tests/tests]   |     \n[Tests/tests]   |         except OSError as e:\n[Tests/tests]   |             raise NewConnectionError(\n[Tests/tests]   |                 self, f\"Failed to establish a new connection: {e}\"\n[Tests/tests]   | >           ) from e\n[Tests/tests]   | E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>: Failed to establish a new connection: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:217: NewConnectionError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0ba64950>\n[Tests/tests]   | request = <PreparedRequest [POST]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   | >               chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:497: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0ba64fd0>\n[Tests/tests]   | method = 'POST', url = '/addversion.json'\n[Tests/tests]   | body = b'--525ac43aac6049be724cc7dead5d1c18\\r\\nContent-Disposition: form-data; name=\"project\"\\r\\n\\r\\nquotesbot\\r\\n--525ac43aa...5\\x06\\x00\\x00\\x00\\x00\\x14\\x00\\x14\\x00(\\x06\\x00\\x00\\x15\\x18\\x00\\x00\\x00\\x00\\r\\n--525ac43aac6049be724cc7dead5d1c18--\\r\\n'\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '8100', 'Content-Type': 'multipart/form-data; boundary=525ac43aac6049be724cc7dead5d1c18'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/addversion.json', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   |                 **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |             # Everything went great!\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |     \n[Tests/tests]   |         except EmptyPoolError:\n[Tests/tests]   |             # Didn't get a connection from the pool, no need to clean up\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |             release_this_conn = False\n[Tests/tests]   |             raise\n[Tests/tests]   |     \n[Tests/tests]   |         except (\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             HTTPException,\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             ProtocolError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             ProxyError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             # Discard the connection for these exceptions. It will be\n[Tests/tests]   |             # replaced during the next _get_conn() call.\n[Tests/tests]   |             clean_exit = False\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e,\n[Tests/tests]   |                 (\n[Tests/tests]   |                     OSError,\n[Tests/tests]   |                     NewConnectionError,\n[Tests/tests]   |                     TimeoutError,\n[Tests/tests]   |                     SSLError,\n[Tests/tests]   |                     HTTPException,\n[Tests/tests]   |                 ),\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             elif isinstance(new_e, (OSError, HTTPException)):\n[Tests/tests]   |                 new_e = ProtocolError(\"Connection aborted.\", new_e)\n[Tests/tests]   |     \n[Tests/tests]   |             retries = retries.increment(\n[Tests/tests]   | >               method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:845: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | method = 'POST', url = '/addversion.json', response = None\n[Tests/tests]   | error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>: Failed to establish a new connection: [Errno 111] Connection refused')\n[Tests/tests]   | _pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0ba64fd0>\n[Tests/tests]   | _stacktrace = <traceback object at 0x7fdc0ba33d70>\n[Tests/tests]   | \n[Tests/tests]   |     def increment(\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str | None = None,\n[Tests/tests]   |         url: str | None = None,\n[Tests/tests]   |         response: BaseHTTPResponse | None = None,\n[Tests/tests]   |         error: Exception | None = None,\n[Tests/tests]   |         _pool: ConnectionPool | None = None,\n[Tests/tests]   |         _stacktrace: TracebackType | None = None,\n[Tests/tests]   |     ) -> Retry:\n[Tests/tests]   |         \"\"\"Return a new Retry object with incremented retry counters.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response: A response object, or None, if the server did not\n[Tests/tests]   |             return a response.\n[Tests/tests]   |         :type response: :class:`~urllib3.response.BaseHTTPResponse`\n[Tests/tests]   |         :param Exception error: An error encountered during the request, or\n[Tests/tests]   |             None if the response was received successfully.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: A new ``Retry`` object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.total is False and error:\n[Tests/tests]   |             # Disabled, indicate to re-raise the error.\n[Tests/tests]   |             raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |     \n[Tests/tests]   |         total = self.total\n[Tests/tests]   |         if total is not None:\n[Tests/tests]   |             total -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         connect = self.connect\n[Tests/tests]   |         read = self.read\n[Tests/tests]   |         redirect = self.redirect\n[Tests/tests]   |         status_count = self.status\n[Tests/tests]   |         other = self.other\n[Tests/tests]   |         cause = \"unknown\"\n[Tests/tests]   |         status = None\n[Tests/tests]   |         redirect_location = None\n[Tests/tests]   |     \n[Tests/tests]   |         if error and self._is_connection_error(error):\n[Tests/tests]   |             # Connect retry?\n[Tests/tests]   |             if connect is False:\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif connect is not None:\n[Tests/tests]   |                 connect -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error and self._is_read_error(error):\n[Tests/tests]   |             # Read retry?\n[Tests/tests]   |             if read is False or method is None or not self._is_method_retryable(method):\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif read is not None:\n[Tests/tests]   |                 read -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error:\n[Tests/tests]   |             # Other retry?\n[Tests/tests]   |             if other is not None:\n[Tests/tests]   |                 other -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif response and response.get_redirect_location():\n[Tests/tests]   |             # Redirect retry?\n[Tests/tests]   |             if redirect is not None:\n[Tests/tests]   |                 redirect -= 1\n[Tests/tests]   |             cause = \"too many redirects\"\n[Tests/tests]   |             response_redirect_location = response.get_redirect_location()\n[Tests/tests]   |             if response_redirect_location:\n[Tests/tests]   |                 redirect_location = response_redirect_location\n[Tests/tests]   |             status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         else:\n[Tests/tests]   |             # Incrementing because of a server error like a 500 in\n[Tests/tests]   |             # status_forcelist and the given method is in the allowed_methods\n[Tests/tests]   |             cause = ResponseError.GENERIC_ERROR\n[Tests/tests]   |             if response and response.status:\n[Tests/tests]   |                 if status_count is not None:\n[Tests/tests]   |                     status_count -= 1\n[Tests/tests]   |                 cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n[Tests/tests]   |                 status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         history = self.history + (\n[Tests/tests]   |             RequestHistory(method, url, error, status, redirect_location),\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         new_retry = self.new(\n[Tests/tests]   |             total=total,\n[Tests/tests]   |             connect=connect,\n[Tests/tests]   |             read=read,\n[Tests/tests]   |             redirect=redirect,\n[Tests/tests]   |             status=status_count,\n[Tests/tests]   |             other=other,\n[Tests/tests]   |             history=history,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if new_retry.is_exhausted():\n[Tests/tests]   |             reason = error or ResponseError(cause)\n[Tests/tests]   | >           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n[Tests/tests]   | E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=56945): Max retries exceeded with url: /addversion.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/retry.py:515: MaxRetryError\n[Tests/tests]   | \n[Tests/tests]   | During handling of the above exception, another exception occurred:\n[Tests/tests]   | \n[Tests/tests]   | self = <scrapyd.tests.test_endpoints.TestEndpoint object at 0x7fdc0c28b890>\n[Tests/tests]   | mock_scrapyd = <scrapyd.tests.mockserver.MockScrapyDServer object at 0x7fdc0ba64590>\n[Tests/tests]   | quotesbot_egg = <_io.BufferedReader name='/tmp/de65f406-fe28-11ed-a890-af2cc187fc11/scrapy-scrapyd/scrapyd/tests/quotesbot.egg'>\n[Tests/tests]   | \n[Tests/tests]   |     def test_addversion_and_delversion(self, mock_scrapyd, quotesbot_egg):\n[Tests/tests]   | >       resp = self._deploy(mock_scrapyd, quotesbot_egg)\n[Tests/tests]   | \n[Tests/tests]   | scrapyd/tests/test_endpoints.py:84: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | scrapyd/tests/test_endpoints.py:108: in _deploy\n[Tests/tests]   |     resp = requests.post(url, data=data, files=files)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:115: in post\n[Tests/tests]   |     return request(\"post\", url, data=data, json=json, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:59: in request\n[Tests/tests]   |     return session.request(method=method, url=url, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:589: in request\n[Tests/tests]   |     resp = self.send(prep, **send_kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:703: in send\n[Tests/tests]   |     r = adapter.send(request, **kwargs)\n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0ba64950>\n[Tests/tests]   | request = <PreparedRequest [POST]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |         except (ProtocolError, OSError) as err:\n[Tests/tests]   |             raise ConnectionError(err, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         except MaxRetryError as e:\n[Tests/tests]   |             if isinstance(e.reason, ConnectTimeoutError):\n[Tests/tests]   |                 # TODO: Remove this in 3.0.0: see #2811\n[Tests/tests]   |                 if not isinstance(e.reason, NewConnectionError):\n[Tests/tests]   |                     raise ConnectTimeout(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, ResponseError):\n[Tests/tests]   |                 raise RetryError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _ProxyError):\n[Tests/tests]   |                 raise ProxyError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _SSLError):\n[Tests/tests]   |                 # This branch is for urllib3 v1.22 and later.\n[Tests/tests]   |                 raise SSLError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   | >           raise ConnectionError(e, request=request)\n[Tests/tests]   | E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=56945): Max retries exceeded with url: /addversion.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:519: ConnectionError\n[Tests/tests]   | ______________________ TestEndpoint.test_failed_settings _______________________\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   | >               socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:204: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 40453), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   |                 sock.connect(sa)\n[Tests/tests]   |                 # Break explicitly a reference cycle\n[Tests/tests]   |                 err = None\n[Tests/tests]   |                 return sock\n[Tests/tests]   |     \n[Tests/tests]   |             except OSError as _:\n[Tests/tests]   |                 err = _\n[Tests/tests]   |                 if sock is not None:\n[Tests/tests]   |                     sock.close()\n[Tests/tests]   |     \n[Tests/tests]   |         if err is not None:\n[Tests/tests]   |             try:\n[Tests/tests]   | >               raise err\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:85: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | address = ('127.0.0.1', 40453), timeout = None, source_address = None\n[Tests/tests]   | socket_options = [(6, 1, 1)]\n[Tests/tests]   | \n[Tests/tests]   |     def create_connection(\n[Tests/tests]   |         address: tuple[str, int],\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         source_address: tuple[str, int] | None = None,\n[Tests/tests]   |         socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n[Tests/tests]   |     ) -> socket.socket:\n[Tests/tests]   |         \"\"\"Connect to *address* and return the socket object.\n[Tests/tests]   |     \n[Tests/tests]   |         Convenience function.  Connect to *address* (a 2-tuple ``(host,\n[Tests/tests]   |         port)``) and return the socket object.  Passing the optional\n[Tests/tests]   |         *timeout* parameter will set the timeout on the socket instance\n[Tests/tests]   |         before attempting to connect.  If no *timeout* is supplied, the\n[Tests/tests]   |         global default timeout setting returned by :func:`socket.getdefaulttimeout`\n[Tests/tests]   |         is used.  If *source_address* is set it must be a tuple of (host, port)\n[Tests/tests]   |         for the socket to bind as a source address before making the connection.\n[Tests/tests]   |         An host of '' or port 0 tells the OS to use the default.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         host, port = address\n[Tests/tests]   |         if host.startswith(\"[\"):\n[Tests/tests]   |             host = host.strip(\"[]\")\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n[Tests/tests]   |         # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n[Tests/tests]   |         # The original create_connection function always returns all records.\n[Tests/tests]   |         family = allowed_gai_family()\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             host.encode(\"idna\")\n[Tests/tests]   |         except UnicodeError:\n[Tests/tests]   |             raise LocationParseError(f\"'{host}', label empty or too long\") from None\n[Tests/tests]   |     \n[Tests/tests]   |         for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n[Tests/tests]   |             af, socktype, proto, canonname, sa = res\n[Tests/tests]   |             sock = None\n[Tests/tests]   |             try:\n[Tests/tests]   |                 sock = socket.socket(af, socktype, proto)\n[Tests/tests]   |     \n[Tests/tests]   |                 # If provided, set socket level options before connecting.\n[Tests/tests]   |                 _set_socket_options(sock, socket_options)\n[Tests/tests]   |     \n[Tests/tests]   |                 if timeout is not _DEFAULT_TIMEOUT:\n[Tests/tests]   |                     sock.settimeout(timeout)\n[Tests/tests]   |                 if source_address:\n[Tests/tests]   |                     sock.bind(source_address)\n[Tests/tests]   | >               sock.connect(sa)\n[Tests/tests]   | E               ConnectionRefusedError: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/connection.py:73: ConnectionRefusedError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bb3ae50>\n[Tests/tests]   | method = 'POST', url = '/addversion.json'\n[Tests/tests]   | body = b'--7958ef39ec15d9f6b407ce00987354cf\\r\\nContent-Disposition: form-data; name=\"project\"\\r\\n\\r\\nquotesbot\\r\\n--7958ef39e...5\\x06\\x00\\x00\\x00\\x00\\x14\\x00\\x14\\x00(\\x06\\x00\\x00\\x89\\x18\\x00\\x00\\x00\\x00\\r\\n--7958ef39ec15d9f6b407ce00987354cf--\\r\\n'\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '8224', 'Content-Type': 'multipart/form-data; boundary=7958ef39ec15d9f6b407ce00987354cf'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/addversion.json', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:802: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bb3ae50>\n[Tests/tests]   | conn = <urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>\n[Tests/tests]   | method = 'POST', url = '/addversion.json'\n[Tests/tests]   | body = b'--7958ef39ec15d9f6b407ce00987354cf\\r\\nContent-Disposition: form-data; name=\"project\"\\r\\n\\r\\nquotesbot\\r\\n--7958ef39e...5\\x06\\x00\\x00\\x00\\x00\\x14\\x00\\x14\\x00(\\x06\\x00\\x00\\x89\\x18\\x00\\x00\\x00\\x00\\r\\n--7958ef39ec15d9f6b407ce00987354cf--\\r\\n'\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '8224', 'Content-Type': 'multipart/form-data; boundary=7958ef39ec15d9f6b407ce00987354cf'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), chunked = False\n[Tests/tests]   | response_conn = <urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>\n[Tests/tests]   | preload_content = False, decode_content = False, enforce_content_length = True\n[Tests/tests]   | \n[Tests/tests]   |     def _make_request(\n[Tests/tests]   |         self,\n[Tests/tests]   |         conn: BaseHTTPConnection,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | None = None,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         response_conn: BaseHTTPConnection | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Perform a request on a given urllib connection object taken from our\n[Tests/tests]   |         pool.\n[Tests/tests]   |     \n[Tests/tests]   |         :param conn:\n[Tests/tests]   |             a connection from one of our connection pools\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response_conn:\n[Tests/tests]   |             Set this to ``None`` if you will handle releasing the connection or\n[Tests/tests]   |             set the connection to have the response release it.\n[Tests/tests]   |     \n[Tests/tests]   |         :param preload_content:\n[Tests/tests]   |           If True, the response's body will be preloaded during construction.\n[Tests/tests]   |     \n[Tests/tests]   |         :param decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param enforce_content_length:\n[Tests/tests]   |             Enforce content length checking. Body returned by server must match\n[Tests/tests]   |             value of Content-Length header, if present. Otherwise, raise error.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self.num_requests += 1\n[Tests/tests]   |     \n[Tests/tests]   |         timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |         timeout_obj.start_connect()\n[Tests/tests]   |         conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Trigger any extra validation we need to do.\n[Tests/tests]   |             try:\n[Tests/tests]   |                 self._validate_conn(conn)\n[Tests/tests]   |             except (SocketTimeout, BaseSSLError) as e:\n[Tests/tests]   |                 self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n[Tests/tests]   |                 raise\n[Tests/tests]   |     \n[Tests/tests]   |         # _validate_conn() starts the connection to an HTTPS proxy\n[Tests/tests]   |         # so we need to wrap errors with 'ProxyError' here too.\n[Tests/tests]   |         except (\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             NewConnectionError,\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             # If the connection didn't successfully connect to it's proxy\n[Tests/tests]   |             # then there\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e, (OSError, NewConnectionError, TimeoutError, SSLError)\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             raise new_e\n[Tests/tests]   |     \n[Tests/tests]   |         # conn.request() calls http.client.*.request, not the method in\n[Tests/tests]   |         # urllib3.request. It also calls makefile (recv) on the socket.\n[Tests/tests]   |         try:\n[Tests/tests]   |             conn.request(\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   | >               enforce_content_length=enforce_content_length,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:504: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>\n[Tests/tests]   | method = 'POST', url = '/addversion.json'\n[Tests/tests]   | body = b'--7958ef39ec15d9f6b407ce00987354cf\\r\\nContent-Disposition: form-data; name=\"project\"\\r\\n\\r\\nquotesbot\\r\\n--7958ef39e...5\\x06\\x00\\x00\\x00\\x00\\x14\\x00\\x14\\x00(\\x06\\x00\\x00\\x89\\x18\\x00\\x00\\x00\\x00\\r\\n--7958ef39ec15d9f6b407ce00987354cf--\\r\\n'\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '8224', 'Content-Type': 'multipart/form-data; boundary=7958ef39ec15d9f6b407ce00987354cf'}\n[Tests/tests]   | \n[Tests/tests]   |     def request(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         *,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         enforce_content_length: bool = True,\n[Tests/tests]   |     ) -> None:\n[Tests/tests]   |         # Update the inner socket's timeout value to send the request.\n[Tests/tests]   |         # This only triggers if the connection is re-used.\n[Tests/tests]   |         if self.sock is not None:\n[Tests/tests]   |             self.sock.settimeout(self.timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         # Store these values to be fed into the HTTPResponse\n[Tests/tests]   |         # object later. TODO: Remove this in favor of a real\n[Tests/tests]   |         # HTTP lifecycle mechanism.\n[Tests/tests]   |     \n[Tests/tests]   |         # We have to store these before we call .request()\n[Tests/tests]   |         # because sometimes we can still salvage a response\n[Tests/tests]   |         # off the wire even if we aren't able to completely\n[Tests/tests]   |         # send the request body.\n[Tests/tests]   |         self._response_options = _ResponseOptions(\n[Tests/tests]   |             request_method=method,\n[Tests/tests]   |             request_url=url,\n[Tests/tests]   |             preload_content=preload_content,\n[Tests/tests]   |             decode_content=decode_content,\n[Tests/tests]   |             enforce_content_length=enforce_content_length,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = {}\n[Tests/tests]   |         header_keys = frozenset(to_str(k.lower()) for k in headers)\n[Tests/tests]   |         skip_accept_encoding = \"accept-encoding\" in header_keys\n[Tests/tests]   |         skip_host = \"host\" in header_keys\n[Tests/tests]   |         self.putrequest(\n[Tests/tests]   |             method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Transform the body into an iterable of sendall()-able chunks\n[Tests/tests]   |         # and detect if an explicit Content-Length is doable.\n[Tests/tests]   |         chunks_and_cl = body_to_chunks(body, method=method, blocksize=self.blocksize)\n[Tests/tests]   |         chunks = chunks_and_cl.chunks\n[Tests/tests]   |         content_length = chunks_and_cl.content_length\n[Tests/tests]   |     \n[Tests/tests]   |         # When chunked is explicit set to 'True' we respect that.\n[Tests/tests]   |         if chunked:\n[Tests/tests]   |             if \"transfer-encoding\" not in header_keys:\n[Tests/tests]   |                 self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |         else:\n[Tests/tests]   |             # Detect whether a framing mechanism is already in use. If so\n[Tests/tests]   |             # we respect that value, otherwise we pick chunked vs content-length\n[Tests/tests]   |             # depending on the type of 'body'.\n[Tests/tests]   |             if \"content-length\" in header_keys:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |             elif \"transfer-encoding\" in header_keys:\n[Tests/tests]   |                 chunked = True\n[Tests/tests]   |     \n[Tests/tests]   |             # Otherwise we go off the recommendation of 'body_to_chunks()'.\n[Tests/tests]   |             else:\n[Tests/tests]   |                 chunked = False\n[Tests/tests]   |                 if content_length is None:\n[Tests/tests]   |                     if chunks is not None:\n[Tests/tests]   |                         chunked = True\n[Tests/tests]   |                         self.putheader(\"Transfer-Encoding\", \"chunked\")\n[Tests/tests]   |                 else:\n[Tests/tests]   |                     self.putheader(\"Content-Length\", str(content_length))\n[Tests/tests]   |     \n[Tests/tests]   |         # Now that framing headers are out of the way we send all the other headers.\n[Tests/tests]   |         if \"user-agent\" not in header_keys:\n[Tests/tests]   |             self.putheader(\"User-Agent\", _get_default_user_agent())\n[Tests/tests]   |         for header, value in headers.items():\n[Tests/tests]   |             self.putheader(header, value)\n[Tests/tests]   | >       self.endheaders()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:388: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>\n[Tests/tests]   | message_body = None\n[Tests/tests]   | \n[Tests/tests]   |     def endheaders(self, message_body=None, *, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Indicate that the last header line has been sent to the server.\n[Tests/tests]   |     \n[Tests/tests]   |         This method sends the request to the server.  The optional message_body\n[Tests/tests]   |         argument can be used to pass a message body associated with the\n[Tests/tests]   |         request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.__state == _CS_REQ_STARTED:\n[Tests/tests]   |             self.__state = _CS_REQ_SENT\n[Tests/tests]   |         else:\n[Tests/tests]   |             raise CannotSendHeader()\n[Tests/tests]   | >       self._send_output(message_body, encode_chunked=encode_chunked)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1276: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>\n[Tests/tests]   | message_body = None, encode_chunked = False\n[Tests/tests]   | \n[Tests/tests]   |     def _send_output(self, message_body=None, encode_chunked=False):\n[Tests/tests]   |         \"\"\"Send the currently buffered request and clear the buffer.\n[Tests/tests]   |     \n[Tests/tests]   |         Appends an extra \\\\r\\\\n to the buffer.\n[Tests/tests]   |         A message_body may be specified, to be appended to the request.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         self._buffer.extend((b\"\", b\"\"))\n[Tests/tests]   |         msg = b\"\\r\\n\".join(self._buffer)\n[Tests/tests]   |         del self._buffer[:]\n[Tests/tests]   | >       self.send(msg)\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:1036: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>\n[Tests/tests]   | data = b'POST /addversion.json HTTP/1.1\\r\\nHost: 127.0.0.1:40453\\r\\nUser-Agent: python-requests/2.31.0\\r\\nAccept-Encoding: gz...-alive\\r\\nContent-Length: 8224\\r\\nContent-Type: multipart/form-data; boundary=7958ef39ec15d9f6b407ce00987354cf\\r\\n\\r\\n'\n[Tests/tests]   | \n[Tests/tests]   |     def send(self, data):\n[Tests/tests]   |         \"\"\"Send `data' to the server.\n[Tests/tests]   |         ``data`` can be a string object, a bytes object, an array object, a\n[Tests/tests]   |         file-like object that supports a .read() method, or an iterable object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         if self.sock is None:\n[Tests/tests]   |             if self.auto_open:\n[Tests/tests]   | >               self.connect()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py:976: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>\n[Tests/tests]   | \n[Tests/tests]   |     def connect(self) -> None:\n[Tests/tests]   | >       self.sock = self._new_conn()\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:236: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>\n[Tests/tests]   | \n[Tests/tests]   |     def _new_conn(self) -> socket.socket:\n[Tests/tests]   |         \"\"\"Establish a socket connection and set nodelay settings on it.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: New socket connection.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         try:\n[Tests/tests]   |             sock = connection.create_connection(\n[Tests/tests]   |                 (self._dns_host, self.port),\n[Tests/tests]   |                 self.timeout,\n[Tests/tests]   |                 source_address=self.source_address,\n[Tests/tests]   |                 socket_options=self.socket_options,\n[Tests/tests]   |             )\n[Tests/tests]   |         except socket.gaierror as e:\n[Tests/tests]   |             raise NameResolutionError(self.host, self, e) from e\n[Tests/tests]   |         except SocketTimeout as e:\n[Tests/tests]   |             raise ConnectTimeoutError(\n[Tests/tests]   |                 self,\n[Tests/tests]   |                 f\"Connection to {self.host} timed out. (connect timeout={self.timeout})\",\n[Tests/tests]   |             ) from e\n[Tests/tests]   |     \n[Tests/tests]   |         except OSError as e:\n[Tests/tests]   |             raise NewConnectionError(\n[Tests/tests]   |                 self, f\"Failed to establish a new connection: {e}\"\n[Tests/tests]   | >           ) from e\n[Tests/tests]   | E           urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>: Failed to establish a new connection: [Errno 111] Connection refused\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connection.py:217: NewConnectionError\n[Tests/tests]   | \n[Tests/tests]   | The above exception was the direct cause of the following exception:\n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0bb3a810>\n[Tests/tests]   | request = <PreparedRequest [POST]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   | >               chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:497: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bb3ae50>\n[Tests/tests]   | method = 'POST', url = '/addversion.json'\n[Tests/tests]   | body = b'--7958ef39ec15d9f6b407ce00987354cf\\r\\nContent-Disposition: form-data; name=\"project\"\\r\\n\\r\\nquotesbot\\r\\n--7958ef39e...5\\x06\\x00\\x00\\x00\\x00\\x14\\x00\\x14\\x00(\\x06\\x00\\x00\\x89\\x18\\x00\\x00\\x00\\x00\\r\\n--7958ef39ec15d9f6b407ce00987354cf--\\r\\n'\n[Tests/tests]   | headers = {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '8224', 'Content-Type': 'multipart/form-data; boundary=7958ef39ec15d9f6b407ce00987354cf'}\n[Tests/tests]   | retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | redirect = False, assert_same_host = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\n[Tests/tests]   | release_conn = False, chunked = False, body_pos = None, preload_content = False\n[Tests/tests]   | decode_content = False, response_kw = {}\n[Tests/tests]   | parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/addversion.json', query=None, fragment=None)\n[Tests/tests]   | destination_scheme = None, conn = None, release_this_conn = True\n[Tests/tests]   | http_tunnel_required = False, err = None, clean_exit = False\n[Tests/tests]   | \n[Tests/tests]   |     def urlopen(  # type: ignore[override]\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str,\n[Tests/tests]   |         url: str,\n[Tests/tests]   |         body: _TYPE_BODY | None = None,\n[Tests/tests]   |         headers: typing.Mapping[str, str] | None = None,\n[Tests/tests]   |         retries: Retry | bool | int | None = None,\n[Tests/tests]   |         redirect: bool = True,\n[Tests/tests]   |         assert_same_host: bool = True,\n[Tests/tests]   |         timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n[Tests/tests]   |         pool_timeout: int | None = None,\n[Tests/tests]   |         release_conn: bool | None = None,\n[Tests/tests]   |         chunked: bool = False,\n[Tests/tests]   |         body_pos: _TYPE_BODY_POSITION | None = None,\n[Tests/tests]   |         preload_content: bool = True,\n[Tests/tests]   |         decode_content: bool = True,\n[Tests/tests]   |         **response_kw: typing.Any,\n[Tests/tests]   |     ) -> BaseHTTPResponse:\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         Get a connection from the pool and perform an HTTP request. This is the\n[Tests/tests]   |         lowest level call for making a request, so you'll need to specify all\n[Tests/tests]   |         the raw details.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            More commonly, it's appropriate to use a convenience method\n[Tests/tests]   |            such as :meth:`request`.\n[Tests/tests]   |     \n[Tests/tests]   |         .. note::\n[Tests/tests]   |     \n[Tests/tests]   |            `release_conn` will only behave as expected if\n[Tests/tests]   |            `preload_content=False` because we want to make\n[Tests/tests]   |            `preload_content=False` the default behaviour someday soon without\n[Tests/tests]   |            breaking backwards compatibility.\n[Tests/tests]   |     \n[Tests/tests]   |         :param method:\n[Tests/tests]   |             HTTP request method (such as GET, POST, PUT, etc.)\n[Tests/tests]   |     \n[Tests/tests]   |         :param url:\n[Tests/tests]   |             The URL to perform the request on.\n[Tests/tests]   |     \n[Tests/tests]   |         :param body:\n[Tests/tests]   |             Data to send in the request body, either :class:`str`, :class:`bytes`,\n[Tests/tests]   |             an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param headers:\n[Tests/tests]   |             Dictionary of custom headers to send, such as User-Agent,\n[Tests/tests]   |             If-None-Match, etc. If None, pool headers are used. If provided,\n[Tests/tests]   |             these headers completely replace any pool-specific headers.\n[Tests/tests]   |     \n[Tests/tests]   |         :param retries:\n[Tests/tests]   |             Configure the number of retries to allow before raising a\n[Tests/tests]   |             :class:`~urllib3.exceptions.MaxRetryError` exception.\n[Tests/tests]   |     \n[Tests/tests]   |             Pass ``None`` to retry until you receive a response. Pass a\n[Tests/tests]   |             :class:`~urllib3.util.retry.Retry` object for fine-grained control\n[Tests/tests]   |             over different types of retries.\n[Tests/tests]   |             Pass an integer number to retry connection errors that many times,\n[Tests/tests]   |             but no other types of errors. Pass zero to never retry.\n[Tests/tests]   |     \n[Tests/tests]   |             If ``False``, then retries are disabled and any exception is raised\n[Tests/tests]   |             immediately. Also, instead of raising a MaxRetryError on redirects,\n[Tests/tests]   |             the redirect response will be returned.\n[Tests/tests]   |     \n[Tests/tests]   |         :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n[Tests/tests]   |     \n[Tests/tests]   |         :param redirect:\n[Tests/tests]   |             If True, automatically handle redirects (status codes 301, 302,\n[Tests/tests]   |             303, 307, 308). Each redirect counts as a retry. Disabling retries\n[Tests/tests]   |             will disable redirect, too.\n[Tests/tests]   |     \n[Tests/tests]   |         :param assert_same_host:\n[Tests/tests]   |             If ``True``, will make sure that the host of the pool requests is\n[Tests/tests]   |             consistent else will raise HostChangedError. When ``False``, you can\n[Tests/tests]   |             use the pool on an HTTP proxy and request foreign hosts.\n[Tests/tests]   |     \n[Tests/tests]   |         :param timeout:\n[Tests/tests]   |             If specified, overrides the default timeout for this one\n[Tests/tests]   |             request. It may be a float (in seconds) or an instance of\n[Tests/tests]   |             :class:`urllib3.util.Timeout`.\n[Tests/tests]   |     \n[Tests/tests]   |         :param pool_timeout:\n[Tests/tests]   |             If set and the pool is set to block=True, then this method will\n[Tests/tests]   |             block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n[Tests/tests]   |             connection is available within the time period.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool preload_content:\n[Tests/tests]   |             If True, the response's body will be preloaded into memory.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool decode_content:\n[Tests/tests]   |             If True, will attempt to decode the body based on the\n[Tests/tests]   |             'content-encoding' header.\n[Tests/tests]   |     \n[Tests/tests]   |         :param release_conn:\n[Tests/tests]   |             If False, then the urlopen call will not release the connection\n[Tests/tests]   |             back into the pool once a response is received (but will release if\n[Tests/tests]   |             you read the entire contents of the response such as when\n[Tests/tests]   |             `preload_content=True`). This is useful if you're not preloading\n[Tests/tests]   |             the response's content immediately. You will need to call\n[Tests/tests]   |             ``r.release_conn()`` on the response ``r`` to return the connection\n[Tests/tests]   |             back into the pool. If None, it takes the value of ``preload_content``\n[Tests/tests]   |             which defaults to ``True``.\n[Tests/tests]   |     \n[Tests/tests]   |         :param bool chunked:\n[Tests/tests]   |             If True, urllib3 will send the body using chunked transfer\n[Tests/tests]   |             encoding. Otherwise, urllib3 will send the body using the standard\n[Tests/tests]   |             content-length form. Defaults to False.\n[Tests/tests]   |     \n[Tests/tests]   |         :param int body_pos:\n[Tests/tests]   |             Position to seek to in file-like body in the event of a retry or\n[Tests/tests]   |             redirect. Typically this won't need to be set because urllib3 will\n[Tests/tests]   |             auto-populate the value when needed.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         parsed_url = parse_url(url)\n[Tests/tests]   |         destination_scheme = parsed_url.scheme\n[Tests/tests]   |     \n[Tests/tests]   |         if headers is None:\n[Tests/tests]   |             headers = self.headers\n[Tests/tests]   |     \n[Tests/tests]   |         if not isinstance(retries, Retry):\n[Tests/tests]   |             retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n[Tests/tests]   |     \n[Tests/tests]   |         if release_conn is None:\n[Tests/tests]   |             release_conn = preload_content\n[Tests/tests]   |     \n[Tests/tests]   |         # Check host\n[Tests/tests]   |         if assert_same_host and not self.is_same_host(url):\n[Tests/tests]   |             raise HostChangedError(self, url, retries)\n[Tests/tests]   |     \n[Tests/tests]   |         # Ensure that the URL we're connecting to is properly encoded\n[Tests/tests]   |         if url.startswith(\"/\"):\n[Tests/tests]   |             url = to_str(_encode_target(url))\n[Tests/tests]   |         else:\n[Tests/tests]   |             url = to_str(parsed_url.url)\n[Tests/tests]   |     \n[Tests/tests]   |         conn = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Track whether `conn` needs to be released before\n[Tests/tests]   |         # returning/raising/recursing. Update this variable if necessary, and\n[Tests/tests]   |         # leave `release_conn` constant throughout the function. That way, if\n[Tests/tests]   |         # the function recurses, the original value of `release_conn` will be\n[Tests/tests]   |         # passed down into the recursive call, and its value will be respected.\n[Tests/tests]   |         #\n[Tests/tests]   |         # See issue #651 [1] for details.\n[Tests/tests]   |         #\n[Tests/tests]   |         # [1] <https://github.com/urllib3/urllib3/issues/651>\n[Tests/tests]   |         release_this_conn = release_conn\n[Tests/tests]   |     \n[Tests/tests]   |         http_tunnel_required = connection_requires_http_tunnel(\n[Tests/tests]   |             self.proxy, self.proxy_config, destination_scheme\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n[Tests/tests]   |         # have to copy the headers dict so we can safely change it without those\n[Tests/tests]   |         # changes being reflected in anyone else's copy.\n[Tests/tests]   |         if not http_tunnel_required:\n[Tests/tests]   |             headers = headers.copy()  # type: ignore[attr-defined]\n[Tests/tests]   |             headers.update(self.proxy_headers)  # type: ignore[union-attr]\n[Tests/tests]   |     \n[Tests/tests]   |         # Must keep the exception bound to a separate variable or else Python 3\n[Tests/tests]   |         # complains about UnboundLocalError.\n[Tests/tests]   |         err = None\n[Tests/tests]   |     \n[Tests/tests]   |         # Keep track of whether we cleanly exited the except block. This\n[Tests/tests]   |         # ensures we do proper cleanup in finally.\n[Tests/tests]   |         clean_exit = False\n[Tests/tests]   |     \n[Tests/tests]   |         # Rewind body position, if needed. Record current position\n[Tests/tests]   |         # for future rewinds in the event of a redirect/retry.\n[Tests/tests]   |         body_pos = set_file_position(body, body_pos)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             # Request a connection from the queue.\n[Tests/tests]   |             timeout_obj = self._get_timeout(timeout)\n[Tests/tests]   |             conn = self._get_conn(timeout=pool_timeout)\n[Tests/tests]   |     \n[Tests/tests]   |             conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n[Tests/tests]   |     \n[Tests/tests]   |             # Is this a closed/new connection that requires CONNECT tunnelling?\n[Tests/tests]   |             if self.proxy is not None and http_tunnel_required and conn.is_closed:\n[Tests/tests]   |                 try:\n[Tests/tests]   |                     self._prepare_proxy(conn)\n[Tests/tests]   |                 except (BaseSSLError, OSError, SocketTimeout) as e:\n[Tests/tests]   |                     self._raise_timeout(\n[Tests/tests]   |                         err=e, url=self.proxy.url, timeout_value=conn.timeout\n[Tests/tests]   |                     )\n[Tests/tests]   |                     raise\n[Tests/tests]   |     \n[Tests/tests]   |             # If we're going to release the connection in ``finally:``, then\n[Tests/tests]   |             # the response doesn't need to know about the connection. Otherwise\n[Tests/tests]   |             # it will also try to release it and we'll have a double-release\n[Tests/tests]   |             # mess.\n[Tests/tests]   |             response_conn = conn if not release_conn else None\n[Tests/tests]   |     \n[Tests/tests]   |             # Make the request on the HTTPConnection object\n[Tests/tests]   |             response = self._make_request(\n[Tests/tests]   |                 conn,\n[Tests/tests]   |                 method,\n[Tests/tests]   |                 url,\n[Tests/tests]   |                 timeout=timeout_obj,\n[Tests/tests]   |                 body=body,\n[Tests/tests]   |                 headers=headers,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |                 retries=retries,\n[Tests/tests]   |                 response_conn=response_conn,\n[Tests/tests]   |                 preload_content=preload_content,\n[Tests/tests]   |                 decode_content=decode_content,\n[Tests/tests]   |                 **response_kw,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |             # Everything went great!\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |     \n[Tests/tests]   |         except EmptyPoolError:\n[Tests/tests]   |             # Didn't get a connection from the pool, no need to clean up\n[Tests/tests]   |             clean_exit = True\n[Tests/tests]   |             release_this_conn = False\n[Tests/tests]   |             raise\n[Tests/tests]   |     \n[Tests/tests]   |         except (\n[Tests/tests]   |             TimeoutError,\n[Tests/tests]   |             HTTPException,\n[Tests/tests]   |             OSError,\n[Tests/tests]   |             ProtocolError,\n[Tests/tests]   |             BaseSSLError,\n[Tests/tests]   |             SSLError,\n[Tests/tests]   |             CertificateError,\n[Tests/tests]   |             ProxyError,\n[Tests/tests]   |         ) as e:\n[Tests/tests]   |             # Discard the connection for these exceptions. It will be\n[Tests/tests]   |             # replaced during the next _get_conn() call.\n[Tests/tests]   |             clean_exit = False\n[Tests/tests]   |             new_e: Exception = e\n[Tests/tests]   |             if isinstance(e, (BaseSSLError, CertificateError)):\n[Tests/tests]   |                 new_e = SSLError(e)\n[Tests/tests]   |             if isinstance(\n[Tests/tests]   |                 new_e,\n[Tests/tests]   |                 (\n[Tests/tests]   |                     OSError,\n[Tests/tests]   |                     NewConnectionError,\n[Tests/tests]   |                     TimeoutError,\n[Tests/tests]   |                     SSLError,\n[Tests/tests]   |                     HTTPException,\n[Tests/tests]   |                 ),\n[Tests/tests]   |             ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n[Tests/tests]   |                 new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n[Tests/tests]   |             elif isinstance(new_e, (OSError, HTTPException)):\n[Tests/tests]   |                 new_e = ProtocolError(\"Connection aborted.\", new_e)\n[Tests/tests]   |     \n[Tests/tests]   |             retries = retries.increment(\n[Tests/tests]   | >               method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n[Tests/tests]   |             )\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/connectionpool.py:845: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = Retry(total=0, connect=None, read=False, redirect=None, status=None)\n[Tests/tests]   | method = 'POST', url = '/addversion.json', response = None\n[Tests/tests]   | error = NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>: Failed to establish a new connection: [Errno 111] Connection refused')\n[Tests/tests]   | _pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7fdc0bb3ae50>\n[Tests/tests]   | _stacktrace = <traceback object at 0x7fdc0bef7c30>\n[Tests/tests]   | \n[Tests/tests]   |     def increment(\n[Tests/tests]   |         self,\n[Tests/tests]   |         method: str | None = None,\n[Tests/tests]   |         url: str | None = None,\n[Tests/tests]   |         response: BaseHTTPResponse | None = None,\n[Tests/tests]   |         error: Exception | None = None,\n[Tests/tests]   |         _pool: ConnectionPool | None = None,\n[Tests/tests]   |         _stacktrace: TracebackType | None = None,\n[Tests/tests]   |     ) -> Retry:\n[Tests/tests]   |         \"\"\"Return a new Retry object with incremented retry counters.\n[Tests/tests]   |     \n[Tests/tests]   |         :param response: A response object, or None, if the server did not\n[Tests/tests]   |             return a response.\n[Tests/tests]   |         :type response: :class:`~urllib3.response.BaseHTTPResponse`\n[Tests/tests]   |         :param Exception error: An error encountered during the request, or\n[Tests/tests]   |             None if the response was received successfully.\n[Tests/tests]   |     \n[Tests/tests]   |         :return: A new ``Retry`` object.\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |         if self.total is False and error:\n[Tests/tests]   |             # Disabled, indicate to re-raise the error.\n[Tests/tests]   |             raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |     \n[Tests/tests]   |         total = self.total\n[Tests/tests]   |         if total is not None:\n[Tests/tests]   |             total -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         connect = self.connect\n[Tests/tests]   |         read = self.read\n[Tests/tests]   |         redirect = self.redirect\n[Tests/tests]   |         status_count = self.status\n[Tests/tests]   |         other = self.other\n[Tests/tests]   |         cause = \"unknown\"\n[Tests/tests]   |         status = None\n[Tests/tests]   |         redirect_location = None\n[Tests/tests]   |     \n[Tests/tests]   |         if error and self._is_connection_error(error):\n[Tests/tests]   |             # Connect retry?\n[Tests/tests]   |             if connect is False:\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif connect is not None:\n[Tests/tests]   |                 connect -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error and self._is_read_error(error):\n[Tests/tests]   |             # Read retry?\n[Tests/tests]   |             if read is False or method is None or not self._is_method_retryable(method):\n[Tests/tests]   |                 raise reraise(type(error), error, _stacktrace)\n[Tests/tests]   |             elif read is not None:\n[Tests/tests]   |                 read -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif error:\n[Tests/tests]   |             # Other retry?\n[Tests/tests]   |             if other is not None:\n[Tests/tests]   |                 other -= 1\n[Tests/tests]   |     \n[Tests/tests]   |         elif response and response.get_redirect_location():\n[Tests/tests]   |             # Redirect retry?\n[Tests/tests]   |             if redirect is not None:\n[Tests/tests]   |                 redirect -= 1\n[Tests/tests]   |             cause = \"too many redirects\"\n[Tests/tests]   |             response_redirect_location = response.get_redirect_location()\n[Tests/tests]   |             if response_redirect_location:\n[Tests/tests]   |                 redirect_location = response_redirect_location\n[Tests/tests]   |             status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         else:\n[Tests/tests]   |             # Incrementing because of a server error like a 500 in\n[Tests/tests]   |             # status_forcelist and the given method is in the allowed_methods\n[Tests/tests]   |             cause = ResponseError.GENERIC_ERROR\n[Tests/tests]   |             if response and response.status:\n[Tests/tests]   |                 if status_count is not None:\n[Tests/tests]   |                     status_count -= 1\n[Tests/tests]   |                 cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n[Tests/tests]   |                 status = response.status\n[Tests/tests]   |     \n[Tests/tests]   |         history = self.history + (\n[Tests/tests]   |             RequestHistory(method, url, error, status, redirect_location),\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         new_retry = self.new(\n[Tests/tests]   |             total=total,\n[Tests/tests]   |             connect=connect,\n[Tests/tests]   |             read=read,\n[Tests/tests]   |             redirect=redirect,\n[Tests/tests]   |             status=status_count,\n[Tests/tests]   |             other=other,\n[Tests/tests]   |             history=history,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         if new_retry.is_exhausted():\n[Tests/tests]   |             reason = error or ResponseError(cause)\n[Tests/tests]   | >           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n[Tests/tests]   | E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=40453): Max retries exceeded with url: /addversion.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/urllib3/util/retry.py:515: MaxRetryError\n[Tests/tests]   | \n[Tests/tests]   | During handling of the above exception, another exception occurred:\n[Tests/tests]   | \n[Tests/tests]   | self = <scrapyd.tests.test_endpoints.TestEndpoint object at 0x7fdc0c28ba50>\n[Tests/tests]   | mock_scrapyd = <scrapyd.tests.mockserver.MockScrapyDServer object at 0x7fdc0bb3a150>\n[Tests/tests]   | quotesbot_egg_asyncio = <_io.BufferedReader name='/tmp/de65f406-fe28-11ed-a890-af2cc187fc11/scrapy-scrapyd/scrapyd/tests/quotesbot_asyncio.egg'>\n[Tests/tests]   | \n[Tests/tests]   |     def test_failed_settings(self, mock_scrapyd, quotesbot_egg_asyncio):\n[Tests/tests]   | >       response = self._deploy(mock_scrapyd, quotesbot_egg_asyncio)\n[Tests/tests]   | \n[Tests/tests]   | scrapyd/tests/test_endpoints.py:112: \n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | scrapyd/tests/test_endpoints.py:108: in _deploy\n[Tests/tests]   |     resp = requests.post(url, data=data, files=files)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:115: in post\n[Tests/tests]   |     return request(\"post\", url, data=data, json=json, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/api.py:59: in request\n[Tests/tests]   |     return session.request(method=method, url=url, **kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:589: in request\n[Tests/tests]   |     resp = self.send(prep, **send_kwargs)\n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/sessions.py:703: in send\n[Tests/tests]   |     r = adapter.send(request, **kwargs)\n[Tests/tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[Tests/tests]   | \n[Tests/tests]   | self = <requests.adapters.HTTPAdapter object at 0x7fdc0bb3a810>\n[Tests/tests]   | request = <PreparedRequest [POST]>, stream = False\n[Tests/tests]   | timeout = Timeout(connect=None, read=None, total=None), verify = True\n[Tests/tests]   | cert = None, proxies = OrderedDict()\n[Tests/tests]   | \n[Tests/tests]   |     def send(\n[Tests/tests]   |         self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n[Tests/tests]   |     ):\n[Tests/tests]   |         \"\"\"Sends PreparedRequest object. Returns Response object.\n[Tests/tests]   |     \n[Tests/tests]   |         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n[Tests/tests]   |         :param stream: (optional) Whether to stream the request content.\n[Tests/tests]   |         :param timeout: (optional) How long to wait for the server to send\n[Tests/tests]   |             data before giving up, as a float, or a :ref:`(connect timeout,\n[Tests/tests]   |             read timeout) <timeouts>` tuple.\n[Tests/tests]   |         :type timeout: float or tuple or urllib3 Timeout object\n[Tests/tests]   |         :param verify: (optional) Either a boolean, in which case it controls whether\n[Tests/tests]   |             we verify the server's TLS certificate, or a string, in which case it\n[Tests/tests]   |             must be a path to a CA bundle to use\n[Tests/tests]   |         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n[Tests/tests]   |         :param proxies: (optional) The proxies dictionary to apply to the request.\n[Tests/tests]   |         :rtype: requests.Response\n[Tests/tests]   |         \"\"\"\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             conn = self.get_connection(request.url, proxies)\n[Tests/tests]   |         except LocationValueError as e:\n[Tests/tests]   |             raise InvalidURL(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         self.cert_verify(conn, request.url, verify, cert)\n[Tests/tests]   |         url = self.request_url(request, proxies)\n[Tests/tests]   |         self.add_headers(\n[Tests/tests]   |             request,\n[Tests/tests]   |             stream=stream,\n[Tests/tests]   |             timeout=timeout,\n[Tests/tests]   |             verify=verify,\n[Tests/tests]   |             cert=cert,\n[Tests/tests]   |             proxies=proxies,\n[Tests/tests]   |         )\n[Tests/tests]   |     \n[Tests/tests]   |         chunked = not (request.body is None or \"Content-Length\" in request.headers)\n[Tests/tests]   |     \n[Tests/tests]   |         if isinstance(timeout, tuple):\n[Tests/tests]   |             try:\n[Tests/tests]   |                 connect, read = timeout\n[Tests/tests]   |                 timeout = TimeoutSauce(connect=connect, read=read)\n[Tests/tests]   |             except ValueError:\n[Tests/tests]   |                 raise ValueError(\n[Tests/tests]   |                     f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n[Tests/tests]   |                     f\"or a single float to set both timeouts to the same value.\"\n[Tests/tests]   |                 )\n[Tests/tests]   |         elif isinstance(timeout, TimeoutSauce):\n[Tests/tests]   |             pass\n[Tests/tests]   |         else:\n[Tests/tests]   |             timeout = TimeoutSauce(connect=timeout, read=timeout)\n[Tests/tests]   |     \n[Tests/tests]   |         try:\n[Tests/tests]   |             resp = conn.urlopen(\n[Tests/tests]   |                 method=request.method,\n[Tests/tests]   |                 url=url,\n[Tests/tests]   |                 body=request.body,\n[Tests/tests]   |                 headers=request.headers,\n[Tests/tests]   |                 redirect=False,\n[Tests/tests]   |                 assert_same_host=False,\n[Tests/tests]   |                 preload_content=False,\n[Tests/tests]   |                 decode_content=False,\n[Tests/tests]   |                 retries=self.max_retries,\n[Tests/tests]   |                 timeout=timeout,\n[Tests/tests]   |                 chunked=chunked,\n[Tests/tests]   |             )\n[Tests/tests]   |     \n[Tests/tests]   |         except (ProtocolError, OSError) as err:\n[Tests/tests]   |             raise ConnectionError(err, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |         except MaxRetryError as e:\n[Tests/tests]   |             if isinstance(e.reason, ConnectTimeoutError):\n[Tests/tests]   |                 # TODO: Remove this in 3.0.0: see #2811\n[Tests/tests]   |                 if not isinstance(e.reason, NewConnectionError):\n[Tests/tests]   |                     raise ConnectTimeout(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, ResponseError):\n[Tests/tests]   |                 raise RetryError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _ProxyError):\n[Tests/tests]   |                 raise ProxyError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   |             if isinstance(e.reason, _SSLError):\n[Tests/tests]   |                 # This branch is for urllib3 v1.22 and later.\n[Tests/tests]   |                 raise SSLError(e, request=request)\n[Tests/tests]   |     \n[Tests/tests]   | >           raise ConnectionError(e, request=request)\n[Tests/tests]   | E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=40453): Max retries exceeded with url: /addversion.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | \n[Tests/tests]   | /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/requests/adapters.py:519: ConnectionError\n[Tests/tests]   | =============================== warnings summary ===============================\n[Tests/tests]   | ../../../opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/coverage/inorout.py:460\n[Tests/tests]   |   /opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/coverage/inorout.py:460: CoverageWarning: --include is ignored because --source is set (include-ignored)\n[Tests/tests]   |     self.warn(\"--include is ignored because --source is set\", slug=\"include-ignored\")\n[Tests/tests]   | \n[Tests/tests]   | -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n[Tests/tests]   | \n[Tests/tests]   | ---------- coverage: platform linux, python 3.7.11-final-0 -----------\n[Tests/tests]   | Coverage XML written to file coverage.xml\n[Tests/tests]   | \n[Tests/tests]   | =========================== short test summary info ============================\n[Tests/tests]   | FAILED scrapyd/tests/test_endpoints.py::TestEndpoint::test_root - requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=52469): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0b896450>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | FAILED scrapyd/tests/test_endpoints.py::TestEndpoint::test_auth - requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=47429): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bdf63d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | FAILED scrapyd/tests/test_endpoints.py::TestEndpoint::test_launch_spider_get - requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=39563): Max retries exceeded with url: /schedule.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bf15550>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | FAILED scrapyd/tests/test_endpoints.py::TestEndpoint::test_spider_list_project_no_egg - requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=41915): Max retries exceeded with url: /listprojects.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bdd56d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | FAILED scrapyd/tests/test_endpoints.py::TestEndpoint::test_addversion_and_delversion - requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=56945): Max retries exceeded with url: /addversion.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0bb70f10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | FAILED scrapyd/tests/test_endpoints.py::TestEndpoint::test_failed_settings - requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=40453): Max retries exceeded with url: /addversion.json (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fdc0ba66110>: Failed to establish a new connection: [Errno 111] Connection refused'))\n[Tests/tests]   | =================== 6 failed, 76 passed, 1 warning in 15.41s ===================\n[Tests/tests]   \u274c  Failure - Main Run unit tests\n[Tests/tests] exitcode '1': failure\n[Tests/tests] \ud83c\udfc1  Job failed\n",
    "actions_stderr": "Error: Job 'tests' failed\n"
}