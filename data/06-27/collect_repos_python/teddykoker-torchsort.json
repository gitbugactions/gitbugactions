{
    "repository": "teddykoker/torchsort",
    "stars": 679,
    "language": "python",
    "size": 554,
    "clone_url": "https://github.com/teddykoker/torchsort.git",
    "timestamp": "2023-06-28T16:43:20.812417Z",
    "clone_success": true,
    "number_of_actions": 1,
    "number_of_test_actions": 1,
    "actions_successful": true,
    "actions_build_tools": [
        "pytest"
    ],
    "actions_test_build_tools": [
        "pytest"
    ],
    "actions_run": {
        "failed": false,
        "tests": [
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-0.1-l2-soft_rank]",
                "time": 0.098,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-0.1-l2-soft_sort]",
                "time": 0.073,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-0.1-kl-soft_rank]",
                "time": 0.077,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-0.1-kl-soft_sort]",
                "time": 0.063,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-1.0-l2-soft_rank]",
                "time": 0.065,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-1.0-l2-soft_sort]",
                "time": 0.069,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-1.0-kl-soft_rank]",
                "time": 0.066,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-1.0-kl-soft_sort]",
                "time": 0.062,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-10.0-l2-soft_rank]",
                "time": 0.068,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-10.0-l2-soft_sort]",
                "time": 0.061,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-10.0-kl-soft_rank]",
                "time": 0.067,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_gradcheck[device0-10.0-kl-soft_sort]",
                "time": 0.049,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-0.1-l2-funcs0]",
                "time": 1.178,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-0.1-l2-funcs1]",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-0.1-kl-funcs0]",
                "time": 0.369,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-0.1-kl-funcs1]",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-1.0-l2-funcs0]",
                "time": 0.001,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-1.0-l2-funcs1]",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-1.0-kl-funcs0]",
                "time": 0.001,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-1.0-kl-funcs1]",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-10.0-l2-funcs0]",
                "time": 0.001,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-10.0-l2-funcs1]",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-10.0-kl-funcs0]",
                "time": 0.001,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_vs_original[device0-10.0-kl-funcs1]",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-0.1-l2-soft_rank]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-0.1-l2-soft_sort]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-0.1-kl-soft_rank]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-0.1-kl-soft_sort]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-1.0-l2-soft_rank]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-1.0-l2-soft_sort]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-1.0-kl-soft_rank]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-1.0-kl-soft_sort]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-10.0-l2-soft_rank]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-10.0-l2-soft_sort]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-10.0-kl-soft_rank]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_ops",
                "name": "test_half[device0-10.0-kl-soft_sort]",
                "time": 0.0,
                "results": [
                    {
                        "result": "Skipped",
                        "message": "requires CUDA to test fp16",
                        "type": "pytest.skip"
                    }
                ],
                "stdout": null,
                "stderr": null
            }
        ],
        "stdout": "[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests] \ud83d\ude80  Start image=crawlergpt:latest\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udc33  docker pull image=crawlergpt:latest platform= username= forcePull=false\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udc33  docker create image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udc33  docker run image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/teddykoker-torchsort] user=0 workdir=\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \u2601  git clone 'https://github.com/actions/setup-python' # ref=v2\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests] \ud83e\uddea  Matrix: map[python-version:3.8]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests] \u2b50 Run Main Checkout Code\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \u2705  Success - Main Checkout Code\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests] \u2b50 Run Main Set up Python 3.8\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udc33  docker cp src=/tmp/act-cache/a232a26c-302b-4caa-8893-53e993e2e2e4/act/actions-setup-python@v2/ dst=/var/run/act/actions/actions-setup-python@v2/\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /var/run/act/actions/actions-setup-python@v2/] user=0 workdir=\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udc33  docker exec cmd=[node /var/run/act/actions/actions-setup-python@v2/dist/setup/index.js] user= workdir=\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::Semantic version spec of 3.8 is 3.8\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::isExplicit: \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::explicit? false\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::isExplicit: 2.7.18\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::explicit? true\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::isExplicit: 3.5.10\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::explicit? true\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::isExplicit: 3.6.14\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::explicit? true\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::isExplicit: 3.7.11\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::explicit? true\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::isExplicit: 3.8.11\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::explicit? true\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::isExplicit: 3.9.6\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::explicit? true\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::evaluating 6 versions\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::matched: 3.8.11\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::checking cache: /opt/hostedtoolcache/Python/3.8.11/x64\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udcac  ::debug::Found tool in cache Python 3.8.11 x64\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Successfully setup CPython (3.8.11)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \u2753 add-matcher /run/act/actions/actions-setup-python@v2/.github/python.json\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \u2705  Success - Main Set up Python 3.8\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \u2699  ::set-env:: pythonLocation=/opt/hostedtoolcache/Python/3.8.11/x64\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \u2699  ::set-env:: LD_LIBRARY_PATH=/opt/hostedtoolcache/Python/3.8.11/x64/lib\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \u2699  ::set-output:: python-version=3.8.11\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.8.11/x64\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.8.11/x64/bin\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests] \u2b50 Run Main Install Dependencies\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/2] user= workdir=\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting torch\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting nvidia-cusolver-cu11==11.4.0.1\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting networkx\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting typing-extensions\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading typing_extensions-4.6.3-py3-none-any.whl (31 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting nvidia-cuda-runtime-cu11==11.7.99\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting nvidia-cudnn-cu11==8.5.0.96\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting nvidia-cublas-cu11==11.10.3.66\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting nvidia-cufft-cu11==10.9.0.58\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting filelock\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting triton==2.0.0\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting nvidia-curand-cu11==10.2.10.91\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting nvidia-cuda-cupti-cu11==11.7.101\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting sympy\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting nvidia-cusparse-cu11==11.7.4.91\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting nvidia-nccl-cu11==2.14.3\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting nvidia-nvtx-cu11==11.7.91\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting jinja2\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting wheel\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (56.0.0)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting cmake\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading cmake-3.26.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting lit\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading lit-16.0.6.tar.gz (153 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Installing build dependencies: started\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Installing build dependencies: finished with status 'done'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Getting requirements to build wheel: started\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Getting requirements to build wheel: finished with status 'done'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Installing backend dependencies: started\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Installing backend dependencies: finished with status 'done'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     Preparing wheel metadata: started\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     Preparing wheel metadata: finished with status 'done'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting MarkupSafe>=2.0\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting mpmath>=0.19\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Building wheels for collected packages: lit\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Building wheel for lit (PEP 517): started\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Building wheel for lit (PEP 517): finished with status 'done'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93582 sha256=09819b0d060c499d7481f9e961668ca70ae9970a60e5cdc92bbf22b7a4d64be3\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Stored in directory: /home/runneradmin/.cache/pip/wheels/05/ab/f1/0102fea49a41c753f0e79a1a4012417d5d7ef0f93224694472\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Successfully built lit\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Installing collected packages: wheel, nvidia-cublas-cu11, mpmath, MarkupSafe, lit, filelock, cmake, typing-extensions, triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-cusolver-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, networkx, jinja2, torch\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Successfully installed MarkupSafe-2.1.3 cmake-3.26.4 filelock-3.12.2 jinja2-3.1.2 lit-16.0.6 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 triton-2.0.0 typing-extensions-4.6.3 wheel-0.40.0\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | WARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | You should consider upgrading via the '/opt/hostedtoolcache/Python/3.8.11/x64/bin/python -m pip install --upgrade pip' command.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Obtaining file:///tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/teddykoker-torchsort\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting fast_soft_sort@ git+https://github.com/google-research/fast-soft-sort.git@c3110360d7c94c42027865c71b23e46fa22151e2\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Cloning https://github.com/google-research/fast-soft-sort.git (to revision c3110360d7c94c42027865c71b23e46fa22151e2) to /tmp/pip-install-g3satdi8/fast-soft-sort_4bd6d8fe07944b9399d143bee678c229\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Running command git clone -q https://github.com/google-research/fast-soft-sort.git /tmp/pip-install-g3satdi8/fast-soft-sort_4bd6d8fe07944b9399d143bee678c229\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Running command git rev-parse -q --verify 'sha^c3110360d7c94c42027865c71b23e46fa22151e2'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Running command git fetch -q https://github.com/google-research/fast-soft-sort.git c3110360d7c94c42027865c71b23e46fa22151e2\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Running command git checkout -q c3110360d7c94c42027865c71b23e46fa22151e2\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Resolved https://github.com/google-research/fast-soft-sort.git to commit c3110360d7c94c42027865c71b23e46fa22151e2\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: torch in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torchsort==0.1.9) (2.0.1)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting pytest\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading pytest-7.4.0-py3-none-any.whl (323 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting numba\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading numba-0.57.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting numpy\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting scipy>=1.2.0\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting llvmlite<0.41,>=0.40.0dev0\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading llvmlite-0.40.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting importlib-metadata\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting zipp>=0.5\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting iniconfig\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting exceptiongroup>=1.0.0rc8\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting packaging\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading packaging-23.1-py3-none-any.whl (48 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting tomli>=1.0.0\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Collecting pluggy<2.0,>=0.12\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Downloading pluggy-1.2.0-py3-none-any.whl (17 kB)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: filelock in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (3.12.2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (11.7.4.91)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (10.2.10.91)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (11.7.99)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: jinja2 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (3.1.2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (10.9.0.58)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (8.5.0.96)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: typing-extensions in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (4.6.3)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (11.4.0.1)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (2.14.3)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (11.7.91)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: triton==2.0.0 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (2.0.0)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (11.10.3.66)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: networkx in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (3.1)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (11.7.99)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: sympy in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (1.12)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from torch->torchsort==0.1.9) (11.7.101)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: wheel in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchsort==0.1.9) (0.40.0)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->torchsort==0.1.9) (56.0.0)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: cmake in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from triton==2.0.0->torch->torchsort==0.1.9) (3.26.4)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: lit in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from triton==2.0.0->torch->torchsort==0.1.9) (16.0.6)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: MarkupSafe>=2.0 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from jinja2->torch->torchsort==0.1.9) (2.1.3)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Requirement already satisfied: mpmath>=0.19 in /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages (from sympy->torch->torchsort==0.1.9) (1.3.0)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Building wheels for collected packages: fast-soft-sort\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Building wheel for fast-soft-sort (setup.py): started\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Building wheel for fast-soft-sort (setup.py): finished with status 'done'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Created wheel for fast-soft-sort: filename=fast_soft_sort-0.1-py3-none-any.whl size=15442 sha256=96ede9f5aa50708ac004d40a368242af442cd4bedf496a0409f3e450db7eb7c5\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Stored in directory: /home/runneradmin/.cache/pip/wheels/bd/54/ac/c6e15935e4703aa8ee190652a542312717f1587c38cc9818ae\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Successfully built fast-soft-sort\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Installing collected packages: zipp, numpy, llvmlite, importlib-metadata, tomli, scipy, pluggy, packaging, numba, iniconfig, exceptiongroup, torchsort, pytest, fast-soft-sort\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |   Running setup.py develop for torchsort\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | Successfully installed exceptiongroup-1.1.1 fast-soft-sort-0.1 importlib-metadata-6.7.0 iniconfig-2.0.0 llvmlite-0.40.1 numba-0.57.1 numpy-1.24.4 packaging-23.1 pluggy-1.2.0 pytest-7.4.0 scipy-1.10.1 tomli-2.0.1 torchsort-0.1.9 zipp-3.15.0\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | WARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | You should consider upgrading via the '/opt/hostedtoolcache/Python/3.8.11/x64/bin/python -m pip install --upgrade pip' command.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \u2705  Success - Main Install Dependencies\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests] \u2b50 Run Main Run Pytest\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/3] user= workdir=\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | ============================= test session starts ==============================\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | platform linux -- Python 3.8.11, pytest-7.4.0, pluggy-1.2.0 -- /opt/hostedtoolcache/Python/3.8.11/x64/bin/python\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | cachedir: .pytest_cache\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | rootdir: /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/teddykoker-torchsort\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | collecting ... collected 36 items\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-0.1-l2-soft_rank] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-0.1-l2-soft_sort] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-0.1-kl-soft_rank] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-0.1-kl-soft_sort] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-1.0-l2-soft_rank] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-1.0-l2-soft_sort] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-1.0-kl-soft_rank] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-1.0-kl-soft_sort] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-10.0-l2-soft_rank] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-10.0-l2-soft_sort] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-10.0-kl-soft_rank] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_gradcheck[device0-10.0-kl-soft_sort] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-0.1-l2-funcs0] FAILED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-0.1-l2-funcs1] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-0.1-kl-funcs0] FAILED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-0.1-kl-funcs1] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-1.0-l2-funcs0] FAILED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-1.0-l2-funcs1] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-1.0-kl-funcs0] FAILED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-1.0-kl-funcs1] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-10.0-l2-funcs0] FAILED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-10.0-l2-funcs1] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-10.0-kl-funcs0] FAILED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_vs_original[device0-10.0-kl-funcs1] PASSED\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-0.1-l2-soft_rank] SKIPPED (requ...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-0.1-l2-soft_sort] SKIPPED (requ...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-0.1-kl-soft_rank] SKIPPED (requ...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-0.1-kl-soft_sort] SKIPPED (requ...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-1.0-l2-soft_rank] SKIPPED (requ...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-1.0-l2-soft_sort] SKIPPED (requ...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-1.0-kl-soft_rank] SKIPPED (requ...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-1.0-kl-soft_sort] SKIPPED (requ...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-10.0-l2-soft_rank] SKIPPED (req...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-10.0-l2-soft_sort] SKIPPED (req...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-10.0-kl-soft_rank] SKIPPED (req...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py::test_half[device0-10.0-kl-soft_sort] SKIPPED (req...)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | =================================== FAILURES ===================================\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | ___________________ test_vs_original[device0-0.1-l2-funcs0] ____________________\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | funcs = (<function soft_rank at 0x7fbe7980b790>, <function soft_rank at 0x7fbe7980b3a0>)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | regularization = 'l2', regularization_strength = 0.1\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | device = device(type='cpu')\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         \"funcs\",\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         [(soft_rank, fss.soft_rank), (soft_sort, fss.soft_sort)],\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization\", REGULARIZATION)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization_strength\", REGULARIZATION_STRENGTH)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"device\", DEVICES)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def test_vs_original(funcs, regularization, regularization_strength, device):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # test that torchsort outputs are consistent with the outputs of the code provided\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # from the original paper\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         x = torch.randn(BATCH_SIZE, SEQ_LEN, dtype=torch.float64, requires_grad=True).to(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             device\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         kwargs = {\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization\": regularization,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization_strength\": regularization_strength,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         }\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >       assert torch.allclose(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[0](x, **kwargs).cpu(),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[1](x.cpu(), **kwargs),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py:59: \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:74: in soft_rank\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return map_tensor(wrapped_fn.apply, values)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in map_tensor\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in <listcomp>\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/torch/autograd/function.py:506: in apply\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return super().apply(*args, **kwargs)  # type: ignore[misc]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:36: in forward\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.from_numpy(obj.compute())\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:260: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return self.projection_.compute()\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:204: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     self.inv_permutation = _inv_permutation(self.permutation)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:171: in _inv_permutation\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     inv_permutation = np.zeros(len(permutation), dtype=np.int)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | attr = 'int'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def __getattr__(attr):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Warn for expired attributes, and return a dummy function\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # that always raises an exception.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         import warnings\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             msg = __expired_functions__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             def _expired(*args, **kwds):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 raise RuntimeError(msg)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return _expired\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Emit warnings for deprecated attributes\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             val, msg = __deprecated_attrs__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return val\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __future_scalars__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # And future warnings for those that will change, but also give\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # the AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 f\"In the future `np.{attr}` will be defined as the \"\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __former_attrs__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >           raise AttributeError(__former_attrs__[attr])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/numpy/__init__.py:305: AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | ___________________ test_vs_original[device0-0.1-kl-funcs0] ____________________\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | funcs = (<function soft_rank at 0x7fbe7980b790>, <function soft_rank at 0x7fbe7980b3a0>)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | regularization = 'kl', regularization_strength = 0.1\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | device = device(type='cpu')\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         \"funcs\",\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         [(soft_rank, fss.soft_rank), (soft_sort, fss.soft_sort)],\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization\", REGULARIZATION)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization_strength\", REGULARIZATION_STRENGTH)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"device\", DEVICES)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def test_vs_original(funcs, regularization, regularization_strength, device):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # test that torchsort outputs are consistent with the outputs of the code provided\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # from the original paper\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         x = torch.randn(BATCH_SIZE, SEQ_LEN, dtype=torch.float64, requires_grad=True).to(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             device\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         kwargs = {\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization\": regularization,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization_strength\": regularization_strength,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         }\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >       assert torch.allclose(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[0](x, **kwargs).cpu(),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[1](x.cpu(), **kwargs),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py:59: \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:74: in soft_rank\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return map_tensor(wrapped_fn.apply, values)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in map_tensor\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in <listcomp>\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/torch/autograd/function.py:506: in apply\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return super().apply(*args, **kwargs)  # type: ignore[misc]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:36: in forward\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.from_numpy(obj.compute())\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:253: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     self.factor = np.exp(self.projection_.compute())\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:204: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     self.inv_permutation = _inv_permutation(self.permutation)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:171: in _inv_permutation\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     inv_permutation = np.zeros(len(permutation), dtype=np.int)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | attr = 'int'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def __getattr__(attr):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Warn for expired attributes, and return a dummy function\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # that always raises an exception.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         import warnings\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             msg = __expired_functions__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             def _expired(*args, **kwds):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 raise RuntimeError(msg)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return _expired\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Emit warnings for deprecated attributes\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             val, msg = __deprecated_attrs__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return val\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __future_scalars__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # And future warnings for those that will change, but also give\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # the AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 f\"In the future `np.{attr}` will be defined as the \"\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __former_attrs__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >           raise AttributeError(__former_attrs__[attr])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/numpy/__init__.py:305: AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | ___________________ test_vs_original[device0-1.0-l2-funcs0] ____________________\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | funcs = (<function soft_rank at 0x7fbe7980b790>, <function soft_rank at 0x7fbe7980b3a0>)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | regularization = 'l2', regularization_strength = 1.0\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | device = device(type='cpu')\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         \"funcs\",\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         [(soft_rank, fss.soft_rank), (soft_sort, fss.soft_sort)],\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization\", REGULARIZATION)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization_strength\", REGULARIZATION_STRENGTH)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"device\", DEVICES)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def test_vs_original(funcs, regularization, regularization_strength, device):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # test that torchsort outputs are consistent with the outputs of the code provided\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # from the original paper\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         x = torch.randn(BATCH_SIZE, SEQ_LEN, dtype=torch.float64, requires_grad=True).to(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             device\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         kwargs = {\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization\": regularization,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization_strength\": regularization_strength,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         }\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >       assert torch.allclose(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[0](x, **kwargs).cpu(),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[1](x.cpu(), **kwargs),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py:59: \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:74: in soft_rank\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return map_tensor(wrapped_fn.apply, values)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in map_tensor\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in <listcomp>\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/torch/autograd/function.py:506: in apply\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return super().apply(*args, **kwargs)  # type: ignore[misc]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:36: in forward\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.from_numpy(obj.compute())\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:260: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return self.projection_.compute()\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:204: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     self.inv_permutation = _inv_permutation(self.permutation)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:171: in _inv_permutation\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     inv_permutation = np.zeros(len(permutation), dtype=np.int)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | attr = 'int'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def __getattr__(attr):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Warn for expired attributes, and return a dummy function\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # that always raises an exception.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         import warnings\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             msg = __expired_functions__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             def _expired(*args, **kwds):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 raise RuntimeError(msg)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return _expired\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Emit warnings for deprecated attributes\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             val, msg = __deprecated_attrs__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return val\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __future_scalars__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # And future warnings for those that will change, but also give\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # the AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 f\"In the future `np.{attr}` will be defined as the \"\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __former_attrs__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >           raise AttributeError(__former_attrs__[attr])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/numpy/__init__.py:305: AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | ___________________ test_vs_original[device0-1.0-kl-funcs0] ____________________\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | funcs = (<function soft_rank at 0x7fbe7980b790>, <function soft_rank at 0x7fbe7980b3a0>)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | regularization = 'kl', regularization_strength = 1.0\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | device = device(type='cpu')\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         \"funcs\",\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         [(soft_rank, fss.soft_rank), (soft_sort, fss.soft_sort)],\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization\", REGULARIZATION)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization_strength\", REGULARIZATION_STRENGTH)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"device\", DEVICES)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def test_vs_original(funcs, regularization, regularization_strength, device):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # test that torchsort outputs are consistent with the outputs of the code provided\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # from the original paper\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         x = torch.randn(BATCH_SIZE, SEQ_LEN, dtype=torch.float64, requires_grad=True).to(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             device\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         kwargs = {\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization\": regularization,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization_strength\": regularization_strength,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         }\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >       assert torch.allclose(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[0](x, **kwargs).cpu(),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[1](x.cpu(), **kwargs),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py:59: \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:74: in soft_rank\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return map_tensor(wrapped_fn.apply, values)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in map_tensor\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in <listcomp>\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/torch/autograd/function.py:506: in apply\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return super().apply(*args, **kwargs)  # type: ignore[misc]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:36: in forward\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.from_numpy(obj.compute())\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:253: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     self.factor = np.exp(self.projection_.compute())\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:204: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     self.inv_permutation = _inv_permutation(self.permutation)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:171: in _inv_permutation\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     inv_permutation = np.zeros(len(permutation), dtype=np.int)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | attr = 'int'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def __getattr__(attr):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Warn for expired attributes, and return a dummy function\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # that always raises an exception.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         import warnings\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             msg = __expired_functions__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             def _expired(*args, **kwds):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 raise RuntimeError(msg)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return _expired\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Emit warnings for deprecated attributes\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             val, msg = __deprecated_attrs__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return val\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __future_scalars__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # And future warnings for those that will change, but also give\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # the AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 f\"In the future `np.{attr}` will be defined as the \"\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __former_attrs__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >           raise AttributeError(__former_attrs__[attr])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/numpy/__init__.py:305: AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | ___________________ test_vs_original[device0-10.0-l2-funcs0] ___________________\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | funcs = (<function soft_rank at 0x7fbe7980b790>, <function soft_rank at 0x7fbe7980b3a0>)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | regularization = 'l2', regularization_strength = 10.0\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | device = device(type='cpu')\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         \"funcs\",\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         [(soft_rank, fss.soft_rank), (soft_sort, fss.soft_sort)],\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization\", REGULARIZATION)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization_strength\", REGULARIZATION_STRENGTH)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"device\", DEVICES)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def test_vs_original(funcs, regularization, regularization_strength, device):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # test that torchsort outputs are consistent with the outputs of the code provided\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # from the original paper\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         x = torch.randn(BATCH_SIZE, SEQ_LEN, dtype=torch.float64, requires_grad=True).to(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             device\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         kwargs = {\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization\": regularization,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization_strength\": regularization_strength,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         }\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >       assert torch.allclose(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[0](x, **kwargs).cpu(),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[1](x.cpu(), **kwargs),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py:59: \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:74: in soft_rank\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return map_tensor(wrapped_fn.apply, values)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in map_tensor\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in <listcomp>\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/torch/autograd/function.py:506: in apply\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return super().apply(*args, **kwargs)  # type: ignore[misc]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:36: in forward\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.from_numpy(obj.compute())\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:260: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return self.projection_.compute()\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:204: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     self.inv_permutation = _inv_permutation(self.permutation)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:171: in _inv_permutation\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     inv_permutation = np.zeros(len(permutation), dtype=np.int)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | attr = 'int'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def __getattr__(attr):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Warn for expired attributes, and return a dummy function\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # that always raises an exception.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         import warnings\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             msg = __expired_functions__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             def _expired(*args, **kwds):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 raise RuntimeError(msg)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return _expired\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Emit warnings for deprecated attributes\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             val, msg = __deprecated_attrs__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return val\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __future_scalars__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # And future warnings for those that will change, but also give\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # the AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 f\"In the future `np.{attr}` will be defined as the \"\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __former_attrs__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >           raise AttributeError(__former_attrs__[attr])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/numpy/__init__.py:305: AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | ___________________ test_vs_original[device0-10.0-kl-funcs0] ___________________\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | funcs = (<function soft_rank at 0x7fbe7980b790>, <function soft_rank at 0x7fbe7980b3a0>)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | regularization = 'kl', regularization_strength = 10.0\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | device = device(type='cpu')\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         \"funcs\",\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         [(soft_rank, fss.soft_rank), (soft_sort, fss.soft_sort)],\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization\", REGULARIZATION)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"regularization_strength\", REGULARIZATION_STRENGTH)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     @pytest.mark.parametrize(\"device\", DEVICES)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def test_vs_original(funcs, regularization, regularization_strength, device):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # test that torchsort outputs are consistent with the outputs of the code provided\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # from the original paper\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         x = torch.randn(BATCH_SIZE, SEQ_LEN, dtype=torch.float64, requires_grad=True).to(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             device\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         kwargs = {\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization\": regularization,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             \"regularization_strength\": regularization_strength,\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         }\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >       assert torch.allclose(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[0](x, **kwargs).cpu(),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             funcs[1](x.cpu(), **kwargs),\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         )\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | tests/test_ops.py:59: \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:74: in soft_rank\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return map_tensor(wrapped_fn.apply, values)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in map_tensor\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:46: in <listcomp>\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.stack([map_fn(tensor_i) for tensor_i in torch.unbind(tensor)])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/torch/autograd/function.py:506: in apply\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return super().apply(*args, **kwargs)  # type: ignore[misc]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/pytorch_ops.py:36: in forward\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     return torch.from_numpy(obj.compute())\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:253: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     self.factor = np.exp(self.projection_.compute())\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:204: in compute\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     self.inv_permutation = _inv_permutation(self.permutation)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/fast_soft_sort/numpy_ops.py:171: in _inv_permutation\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     inv_permutation = np.zeros(len(permutation), dtype=np.int)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | attr = 'int'\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     def __getattr__(attr):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Warn for expired attributes, and return a dummy function\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # that always raises an exception.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         import warnings\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             msg = __expired_functions__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             def _expired(*args, **kwds):\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 raise RuntimeError(msg)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return _expired\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         # Emit warnings for deprecated attributes\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         try:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             val, msg = __deprecated_attrs__[attr]\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         except KeyError:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             pass\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         else:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(msg, DeprecationWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             return val\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __future_scalars__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # And future warnings for those that will change, but also give\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             # the AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |             warnings.warn(\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 f\"In the future `np.{attr}` will be defined as the \"\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |                 \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |         if attr in __former_attrs__:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | >           raise AttributeError(__former_attrs__[attr])\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E           The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | E               https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | \n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | /opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/numpy/__init__.py:305: AttributeError\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | - generated xml file: /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/teddykoker-torchsort/report.xml -\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | =========================== short test summary info ============================\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | FAILED tests/test_ops.py::test_vs_original[device0-0.1-l2-funcs0] - AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | FAILED tests/test_ops.py::test_vs_original[device0-0.1-kl-funcs0] - AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | FAILED tests/test_ops.py::test_vs_original[device0-1.0-l2-funcs0] - AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | FAILED tests/test_ops.py::test_vs_original[device0-1.0-kl-funcs0] - AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | FAILED tests/test_ops.py::test_vs_original[device0-10.0-l2-funcs0] - AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | FAILED tests/test_ops.py::test_vs_original[device0-10.0-kl-funcs0] - AttributeError: module 'numpy' has no attribute 'int'.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   |     https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   | =================== 6 failed, 18 passed, 12 skipped in 4.77s ===================\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests]   \u274c  Failure - Main Run Pytest\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests] exitcode '1': failure\n[92aae73d-a1b2-4c6e-bed0-6910aaad97e4/Tests] \ud83c\udfc1  Job failed\n",
        "stderr": "Error: Job 'Tests' failed\n",
        "workflow": "/tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/teddykoker-torchsort/.github/workflows/test-crawler.yml",
        "build_tool": "pytest",
        "elapsed_time": 565.8117587566376
    }
}