{
    "repository": "scrapinghub/scrapyrt",
    "stars": 775,
    "language": "python",
    "size": 307,
    "clone_url": "https://github.com/scrapinghub/scrapyrt.git",
    "timestamp": "2023-07-01T10:13:35.301753Z",
    "clone_success": true,
    "number_of_actions": 2,
    "number_of_test_actions": 1,
    "actions_successful": true,
    "actions_build_tools": [
        "unknown",
        "pytest"
    ],
    "actions_test_build_tools": [
        "pytest"
    ],
    "actions_run": {
        "failed": false,
        "tests": [
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_find_scrapy_project",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_find_scrapy_project_invalid_conf",
                "time": 0.008,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_get_application",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_execute",
                "time": 0.081,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_reactor_launched[twisted.internet.asyncioreactor.AsyncioSelectorReactor-AsyncioSelectorReactor]",
                "time": 1.044,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AssertionError: assert 'Running with reactor: AsyncioSelectorReactor' in ''\n +  where '' = <built-in method decode of bytes object at 0x56164f37ef70>()\n +    where <built-in method decode of bytes object at 0x56164f37ef70> = b''.decode",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_reactor_launched[None-EPollReactor]",
                "time": 1.045,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AssertionError: assert 'Running with reactor: EPollReactor' in ''\n +  where '' = <built-in method decode of bytes object at 0x56164f38b700>()\n +    where <built-in method decode of bytes object at 0x56164f38b700> = b''.decode",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCrawl",
                "name": "test_crawl",
                "time": 0.039,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCrawl",
                "name": "test_no_spider",
                "time": 0.026,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCrawl",
                "name": "test_spider_arguments_are_passed",
                "time": 0.014,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCrawl",
                "name": "test_spider_exists",
                "time": 0.016,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestGetProjectSettings",
                "name": "test_get_project_settings",
                "time": 0.007,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_modify_realtime_request",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_modify_realtime_request_is_not_callable",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_pass_good_spider_errback",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_pass_wrong_spider_errback",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_raise_error_if_not_callable",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_spider_opened",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestHandleScheduling",
                "name": "test_handle_scheduling",
                "time": 0.01,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestHandleScheduling",
                "name": "test_handle_scheduling_another_spider",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestLimitRuntime",
                "name": "test_limit_runtime",
                "time": 1.011,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestLimitRuntime",
                "name": "test_string_number_timeout_value",
                "time": 1.011,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestLimitRuntime",
                "name": "test_wrong_timeout_value",
                "time": 0.008,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestHandleSpiderError",
                "name": "test_handle_spider_error_another_spider",
                "time": 0.074,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestHandleSpiderError",
                "name": "test_handle_spider_error_debug_false",
                "time": 0.03,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestHandleSpiderError",
                "name": "test_handle_spider_error_debug_true",
                "time": 0.026,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestLimitRequests",
                "name": "test_max_requests_not_set",
                "time": 0.008,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestLimitRequests",
                "name": "test_max_requests_set",
                "time": 0.008,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestGetItem",
                "name": "test_get_item",
                "time": 0.007,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestGetItem",
                "name": "test_get_item_another_spider",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCollectDropped",
                "name": "test_collect_dropped",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCollectDropped",
                "name": "test_collect_dropped_another_spider",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestReturnItems",
                "name": "test_return_items",
                "time": 0.033,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestReturnItems",
                "name": "test_return_items_without_debug",
                "time": 0.009,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCreateSpiderRequest",
                "name": "test_invalid_arguments",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCreateSpiderRequest",
                "name": "test_invalid_url",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCreateSpiderRequest",
                "name": "test_valid_arguments",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestStartRequests",
                "name": "test_start_requests_false",
                "time": 0.207,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestStartRequests",
                "name": "test_start_requests_true",
                "time": 0.04,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCreateProperLogFile",
                "name": "test_filename",
                "time": 0.013,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawler.TestCrawler",
                "name": "test_crawl_start_requests_default",
                "time": 0.927,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawler.TestCrawler",
                "name": "test_crawl_start_requests_disabled",
                "time": 0.83,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawler.TestCrawler",
                "name": "test_crawl_start_requests_enabled",
                "time": 0.774,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawler_process.CralwerProcessTestCase",
                "name": "test_signals",
                "time": 0.037,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_decorators.TestDecorators",
                "name": "test_deprecated",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_log_observer.TestLogObserver",
                "name": "test_emit_called",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_log_observer.TestLogObserver",
                "name": "test_log_start_messages_filtering",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_log_observer.TestLogObserver",
                "name": "test_scrapy_filtering",
                "time": 0.004,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_log_observer.TestLogObserver",
                "name": "test_unicode_message",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_is_leaf",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_render_GET",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_render_POST",
                "time": 0.007,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_render_POST_invalid_json",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_render_POST_invalid_options",
                "time": 0.007,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_validate_options[scrapy_args0-api_args0-False]",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_validate_options[scrapy_args1-api_args1-True]",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_prepare_response",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceGetRequiredArgument",
                "name": "test_empty_argument",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceGetRequiredArgument",
                "name": "test_get_argument",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceGetRequiredArgument",
                "name": "test_raise_error",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_parameters[perform_get]",
                "time": 1.925,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_parameters[perform_post]",
                "time": 1.925,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_url_no_start_requests[perform_get]",
                "time": 1.813,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_url_no_start_requests[perform_post]",
                "time": 1.816,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_url_but_start_requests_present[perform_get]",
                "time": 2.004,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_url_but_start_requests_present[perform_post]",
                "time": 2.174,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_request_but_start_requests_present",
                "time": 2.034,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_request_in_POST_handler",
                "time": 1.906,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_url_and_start_requests_present[perform_get]",
                "time": 2.15,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_url_and_start_requests_present[perform_post]",
                "time": 2.031,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_spider_name[perform_get]",
                "time": 1.939,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_spider_name[perform_post]",
                "time": 2.049,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_invalid_scrapy_request_detected_in_api",
                "time": 2.017,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_invalid_scrapy_request_detected_by_scrapy[perform_get]",
                "time": 1.926,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_invalid_scrapy_request_detected_by_scrapy[perform_post]",
                "time": 1.917,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl[perform_get]",
                "time": 1.913,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AssertionError: assert 'error' == 'ok'\n  - ok\n  + error",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl[perform_post]",
                "time": 2.042,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AssertionError: assert 'error' == 'ok'\n  - ok\n  + error",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_invalid_json_in_post",
                "time": 1.834,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_passing_errback[perform_get]",
                "time": 2.0,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: 'NoneType' object has no attribute 'get'",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_passing_errback[perform_post]",
                "time": 2.015,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: 'NoneType' object has no attribute 'get'",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_bytes_in_item[perform_get]",
                "time": 1.969,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_bytes_in_item[perform_post]",
                "time": 2.165,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl_with_argument_get",
                "time": 2.047,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AssertionError: assert 'error' == 'ok'\n  - ok\n  + error",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl_with_argument_post",
                "time": 2.015,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl_with_argument_invalid_json",
                "time": 1.931,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl_with_argument_invalid_name",
                "time": 2.075,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl_with_argument_attribute_collision",
                "time": 1.909,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AssertionError: assert 'error' == 'ok'\n  - ok\n  + error",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_realtimeapi.TestRealtimeApi",
                "name": "test_realtimeapi_with_custom_settings",
                "time": 0.007,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_realtimeapi.TestRealtimeApi",
                "name": "test_realtimeapi_with_default_settings",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_root.TestRootResourceIntegration",
                "name": "test_root",
                "time": 1.84,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRender",
                "name": "test_render_deferred_fail",
                "time": 0.01,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRender",
                "name": "test_render_deferred_succeed",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRender",
                "name": "test_render_exception",
                "time": 0.026,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRender",
                "name": "test_render_ok",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestHandleErrors",
                "name": "test_error_400",
                "time": 0.044,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestHandleErrors",
                "name": "test_error_403",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestHandleErrors",
                "name": "test_error_not_supported_method",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestHandleErrors",
                "name": "test_exception",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestHandleErrors",
                "name": "test_failure",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestFormatErrorResponse",
                "name": "test_format_error_response",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRenderObject",
                "name": "test_access_control_allow_methods_header_get",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRenderObject",
                "name": "test_access_control_allow_methods_header_get_post",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRenderObject",
                "name": "test_render_object",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_utils.TestUtils",
                "name": "test_get_scrapy_request_args",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_utils.TestUtils",
                "name": "test_get_scrapy_request_args_error",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            }
        ],
        "stdout": "[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build] \ud83d\ude80  Start image=crawlergpt:latest\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udc33  docker pull image=crawlergpt:latest platform= username= forcePull=false\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udc33  docker create image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udc33  docker run image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt] user=0 workdir=\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \u2601  git clone 'https://github.com/actions/setup-python' # ref=v2\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build] \ud83e\uddea  Matrix: map[python-version:3.6 scrapy-version:2.5.1]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build] \u2b50 Run Main actions/checkout@v2\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \u2705  Success - Main actions/checkout@v2\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build] \u2b50 Run Main Set up Python 3.6\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udc33  docker cp src=/tmp/act-cache/07ed7b42-09bf-43f5-b1e6-cb43cefd406a/act/actions-setup-python@v2/ dst=/var/run/act/actions/actions-setup-python@v2/\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /var/run/act/actions/actions-setup-python@v2/] user=0 workdir=\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udc33  docker exec cmd=[node /var/run/act/actions/actions-setup-python@v2/dist/setup/index.js] user= workdir=\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::Semantic version spec of 3.6 is 3.6\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::isExplicit: \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::explicit? false\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::isExplicit: 2.7.18\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::explicit? true\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::isExplicit: 3.5.10\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::explicit? true\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::isExplicit: 3.6.14\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::explicit? true\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::isExplicit: 3.7.11\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::explicit? true\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::isExplicit: 3.8.11\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::explicit? true\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::isExplicit: 3.9.6\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::explicit? true\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::evaluating 6 versions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::matched: 3.6.14\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::checking cache: /opt/hostedtoolcache/Python/3.6.14/x64\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udcac  ::debug::Found tool in cache Python 3.6.14 x64\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Successfully setup CPython (3.6.14)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \u2753 add-matcher /run/act/actions/actions-setup-python@v2/.github/python.json\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \u2705  Success - Main Set up Python 3.6\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \u2699  ::set-env:: pythonLocation=/opt/hostedtoolcache/Python/3.6.14/x64\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \u2699  ::set-env:: LD_LIBRARY_PATH=/opt/hostedtoolcache/Python/3.6.14/x64/lib\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \u2699  ::set-output:: python-version=3.6.14\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.6.14/x64\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.6.14/x64/bin\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build] \u2b50 Run Main Install dependencies\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/2] user= workdir=\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Requirement already satisfied: pip in /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages (21.2.4)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting pip\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Installing collected packages: pip\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Attempting uninstall: pip\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     Found existing installation: pip 21.2.4\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     Uninstalling pip-21.2.4:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |       Successfully uninstalled pip-21.2.4\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Successfully installed pip-21.3.1\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting scrapy==2.5.1\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading Scrapy-2.5.1-py2.py3-none-any.whl (254 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting queuelib>=1.4.2\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting w3lib>=1.17.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting itemadapter>=0.1.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting parsel>=1.5.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting service-identity>=16.0.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting protego>=0.1.15\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting Twisted[http2]>=17.9.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading Twisted-22.4.0-py3-none-any.whl (3.1 MB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting PyDispatcher>=2.0.5\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting lxml>=3.5.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading lxml-4.9.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.6 MB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting zope.interface>=4.1.3\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading zope.interface-5.5.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (253 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting h2<4.0,>=3.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting itemloaders>=1.0.1\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting pyOpenSSL>=16.2.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading pyOpenSSL-23.2.0-py3-none-any.whl (59 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting cryptography>=2.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading cryptography-40.0.2-cp36-abi3-manylinux_2_28_x86_64.whl (3.7 MB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting cssselect>=0.9.1\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting cffi>=1.12\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting hyperframe<6,>=5.2.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting hpack<4,>=3.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting jmespath>=0.9.5\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting six>=1.6.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting pyasn1\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting attrs>=19.1.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting pyasn1-modules\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting Automat>=0.8.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting hyperlink>=17.1.1\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting typing-extensions>=3.6.5\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting incremental>=21.3.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting constantly>=15.1\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting priority<2.0,>=1.1.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading priority-1.3.0-py2.py3-none-any.whl (11 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages (from zope.interface>=4.1.3->scrapy==2.5.1) (40.6.2)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting pycparser\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting idna>=2.5\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading idna-3.4-py3-none-any.whl (61 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Installing collected packages: six, pycparser, idna, attrs, zope.interface, w3lib, typing-extensions, pyasn1, lxml, incremental, hyperlink, hyperframe, hpack, cssselect, constantly, cffi, Automat, Twisted, pyasn1-modules, priority, parsel, jmespath, itemadapter, h2, cryptography, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, scrapy\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Successfully installed Automat-22.10.0 PyDispatcher-2.0.7 Twisted-22.4.0 attrs-22.2.0 cffi-1.15.1 constantly-15.1.0 cryptography-40.0.2 cssselect-1.1.0 h2-3.2.0 hpack-3.0.0 hyperframe-5.2.0 hyperlink-21.0.0 idna-3.4 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-0.10.0 lxml-4.9.2 parsel-1.6.0 priority-1.3.0 protego-0.2.1 pyOpenSSL-23.2.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycparser-2.21 queuelib-1.6.2 scrapy-2.5.1 service-identity-21.1.0 six-1.16.0 typing-extensions-4.1.1 w3lib-2.0.1 zope.interface-5.5.2\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting mock\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading mock-5.0.2-py3-none-any.whl (30 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting port-for\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading port_for-0.5.0-py2.py3-none-any.whl (18 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting Flask\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting pytest\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading pytest-7.0.1-py3-none-any.whl (296 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting requests\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting bumpversion\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading bumpversion-0.6.0-py2.py3-none-any.whl (8.4 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting flake8\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading flake8-5.0.4-py2.py3-none-any.whl (61 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting Werkzeug>=2.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting click>=7.1.2\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading click-8.0.4-py3-none-any.whl (97 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting Jinja2>=3.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting itsdangerous>=2.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting py>=1.8.2\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting iniconfig\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting packaging\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting importlib-metadata>=0.12\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Requirement already satisfied: attrs>=19.2.0 in /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages (from pytest->-r requirements-dev.txt (line 4)) (22.2.0)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting pluggy<2.0,>=0.12\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting tomli>=1.0.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading tomli-1.2.3-py3-none-any.whl (12 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Requirement already satisfied: idna<4,>=2.5 in /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages (from requests->-r requirements-dev.txt (line 5)) (3.4)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting urllib3<1.27,>=1.21.1\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting certifi>=2017.4.17\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting charset-normalizer~=2.0.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting bump2version\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading bump2version-1.0.1-py2.py3-none-any.whl (22 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting pyflakes<2.6.0,>=2.5.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading pyflakes-2.5.0-py2.py3-none-any.whl (66 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting pycodestyle<2.10.0,>=2.9.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading pycodestyle-2.9.1-py2.py3-none-any.whl (41 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting mccabe<0.8.0,>=0.7.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting importlib-metadata>=0.12\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting zipp>=0.5\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Requirement already satisfied: typing-extensions>=3.6.4 in /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest->-r requirements-dev.txt (line 4)) (4.1.1)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting MarkupSafe>=2.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting dataclasses\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Collecting pyparsing!=3.0.5,>=2.0.2\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   Downloading pyparsing-3.1.0-py3-none-any.whl (102 kB)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Installing collected packages: zipp, pyparsing, MarkupSafe, importlib-metadata, dataclasses, Werkzeug, urllib3, tomli, pyflakes, pycodestyle, py, pluggy, packaging, mccabe, Jinja2, itsdangerous, iniconfig, click, charset-normalizer, certifi, bump2version, requests, pytest, port-for, mock, Flask, flake8, bumpversion\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Successfully installed Flask-2.0.3 Jinja2-3.0.3 MarkupSafe-2.0.1 Werkzeug-2.0.3 bump2version-1.0.1 bumpversion-0.6.0 certifi-2023.5.7 charset-normalizer-2.0.12 click-8.0.4 dataclasses-0.8 flake8-5.0.4 importlib-metadata-4.2.0 iniconfig-1.1.1 itsdangerous-2.0.1 mccabe-0.7.0 mock-5.0.2 packaging-21.3 pluggy-1.0.0 port-for-0.5.0 py-1.11.0 pycodestyle-2.9.1 pyflakes-2.5.0 pyparsing-3.1.0 pytest-7.0.1 requests-2.27.1 tomli-1.2.3 urllib3-1.26.16 zipp-3.6.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \u2705  Success - Main Install dependencies\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build] \u2b50 Run Main Test with pytest\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/3] user= workdir=\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ============================= test session starts ==============================\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | platform linux -- Python 3.6.14, pytest-7.0.1, pluggy-1.0.0\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | rootdir: /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | collected 104 items\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | tests/test_cmdline.py ....FF                                             [  5%]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | tests/test_crawl_manager.py .................................            [ 37%]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | tests/test_crawler.py FFF                                                [ 40%]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | tests/test_crawler_process.py .                                          [ 41%]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | tests/test_decorators.py .                                               [ 42%]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | tests/test_log_observer.py ..F.                                          [ 46%]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | tests/test_resource_crawl.py ...............FFF.FF.....FF.FFFFFF..F      [ 82%]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | tests/test_resource_realtimeapi.py ..                                    [ 84%]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | tests/test_resource_root.py .                                            [ 85%]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | tests/test_resource_serviceresource.py .............                     [ 98%]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | tests/test_utils.py ..                                                   [100%]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | =================================== FAILURES ===================================\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ TestCmdLine.test_reactor_launched[twisted.internet.asyncioreactor.AsyncioSelectorReactor-AsyncioSelectorReactor] _\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_cmdline.TestCmdLine object at 0x7f2c3eef9080>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | reactor = 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | expected = 'AsyncioSelectorReactor'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize('reactor,expected', [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         (\"twisted.internet.asyncioreactor.AsyncioSelectorReactor\",\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |          \"AsyncioSelectorReactor\"),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         (None, 'EPollReactor')\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_reactor_launched(self, reactor, expected):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         port = port_for.select_random()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         tmp_dir = tempfile.mkdtemp()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         cwd = os.path.join(tmp_dir, 'testproject')\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         generate_project(cwd)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         cmd = [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             sys.executable, '-m', 'scrapyrt.cmdline', '-p', str(port),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         ]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         if reactor is not None:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             cmd.extend(['-s', f'TWISTED_REACTOR={reactor}'])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         process = subprocess.Popen(cmd, cwd=cwd, stdout=subprocess.PIPE,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                                    stderr=subprocess.PIPE,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                                    env=get_testenv())\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         try:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             _, logs = process.communicate(timeout=1)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         except subprocess.TimeoutExpired:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             process.kill()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             _, logs = process.communicate()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert f\"Running with reactor: {expected}\" in logs.decode()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       AssertionError: assert 'Running with reactor: AsyncioSelectorReactor' in ''\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +  where '' = <built-in method decode of bytes object at 0x56164f37ef70>()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +    where <built-in method decode of bytes object at 0x56164f37ef70> = b''.decode\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_cmdline.py:95: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _____________ TestCmdLine.test_reactor_launched[None-EPollReactor] _____________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_cmdline.TestCmdLine object at 0x7f2c3eef9240>, reactor = None\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | expected = 'EPollReactor'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize('reactor,expected', [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         (\"twisted.internet.asyncioreactor.AsyncioSelectorReactor\",\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |          \"AsyncioSelectorReactor\"),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         (None, 'EPollReactor')\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_reactor_launched(self, reactor, expected):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         port = port_for.select_random()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         tmp_dir = tempfile.mkdtemp()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         cwd = os.path.join(tmp_dir, 'testproject')\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         generate_project(cwd)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         cmd = [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             sys.executable, '-m', 'scrapyrt.cmdline', '-p', str(port),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         ]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         if reactor is not None:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             cmd.extend(['-s', f'TWISTED_REACTOR={reactor}'])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         process = subprocess.Popen(cmd, cwd=cwd, stdout=subprocess.PIPE,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                                    stderr=subprocess.PIPE,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                                    env=get_testenv())\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         try:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             _, logs = process.communicate(timeout=1)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         except subprocess.TimeoutExpired:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             process.kill()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             _, logs = process.communicate()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert f\"Running with reactor: {expected}\" in logs.decode()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       AssertionError: assert 'Running with reactor: EPollReactor' in ''\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +  where '' = <built-in method decode of bytes object at 0x56164f38b700>()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +    where <built-in method decode of bytes object at 0x56164f38b700> = b''.decode\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_cmdline.py:95: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ________________ TestCrawler.test_crawl_start_requests_default _________________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | result = None, gen = <generator object crawl at 0x7f2c3eaa3fc0>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | status = _CancellationStatus(deferred=<Deferred at 0x7f2c3e9547b8 current result: None>, waitingOn=None)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @_extraneous\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def _inlineCallbacks(\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         result: object,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         gen: Union[\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             Generator[Deferred[_T], object, None],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             Coroutine[Deferred[_T], object, None],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         ],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         status: _CancellationStatus,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ) -> None:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         Carry out the work of L{inlineCallbacks}.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         Iterate the generator produced by an C{@}L{inlineCallbacks}-decorated\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         function, C{gen}, C{send()}ing it the results of each value C{yield}ed by\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         that generator, until a L{Deferred} is yielded, at which point a callback\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         is added to that L{Deferred} to call this function again.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param result: The last result seen by this generator.  Note that this is\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             never a L{Deferred} - by the time this function is invoked, the\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             L{Deferred} has been called back and this will be a particular result\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             at a point in its callback chain.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param gen: a generator object returned by calling a function or method\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             decorated with C{@}L{inlineCallbacks}\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param status: a L{_CancellationStatus} tracking the current status of C{gen}\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # This function is complicated by the need to prevent unbounded recursion\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # arising from repeatedly yielding immediately ready deferreds.  This while\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # loop and the waiting variable solve that by manually unfolding the\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # recursion.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # waiting for result?  # result\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         waiting: List[Any] = [True, None]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # Get the current contextvars Context object.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         current_context = _copy_context()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         while 1:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             try:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 # Send the last result back as the result of the yield expression.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 isFailure = isinstance(result, Failure)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 if isFailure:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                     result = current_context.run(\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                         cast(Failure, result).throwExceptionIntoGenerator, gen\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                     )\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 else:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >                   result = current_context.run(gen.send, result)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:1660: \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:62: in run\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return f(*args, **kwargs)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/scrapyrt/core.py:42: in crawl\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.engine = self._create_engine()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/crawler.py:101: in _create_engine\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return ExecutionEngine(self, lambda _: self.stop())\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/engine.py:69: in __init__\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.downloader = downloader_cls(crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py:83: in __init__\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:53: in from_crawler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return cls.from_settings(crawler.settings, crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:34: in from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mwcls = load_object(clspath)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py:61: in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py:126: in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py:27: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import TunnelError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py:23: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py:11: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     import logging\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from OpenSSL import SSL\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from service_identity.exceptions import CertificateError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from twisted.internet._sslverify import ClientTLSOptions, verifyHostname, VerificationError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from twisted.internet.ssl import AcceptableCiphers\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.utils.ssl import x509name_to_string, get_temp_key_info\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     logger = logging.getLogger(__name__)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3 = 'SSLv3'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLS = 'TLS'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv10 = 'TLSv1.0'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv11 = 'TLSv1.1'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv12 = 'TLSv1.2'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     openssl_methods = {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLS: SSL.SSLv23_METHOD,                      # protocol negotiation (recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv10: SSL.TLSv1_METHOD,                    # TLS 1.0 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv11: getattr(SSL, 'TLSv1_1_METHOD', 5),   # TLS 1.1 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv12: getattr(SSL, 'TLSv1_2_METHOD', 6),   # TLS 1.2 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     }\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E   AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py:23: AttributeError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ----------------------------- Captured stdout call -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ------------------------------ Captured log call -------------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"http\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Traceback (most recent call last):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     dhcls = load_object(path)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"https\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Traceback (most recent call last):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     dhcls = load_object(path)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.s3.S3DownloadHandler\" for scheme \"s3\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Traceback (most recent call last):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     dhcls = load_object(path)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/s3.py\", line 3, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http import HTTPDownloadHandler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ________________ TestCrawler.test_crawl_start_requests_disabled ________________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | result = None, gen = <generator object crawl at 0x7f2c3e9df5c8>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | status = _CancellationStatus(deferred=<Deferred at 0x7f2c3e70b9b0 current result: None>, waitingOn=None)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @_extraneous\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def _inlineCallbacks(\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         result: object,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         gen: Union[\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             Generator[Deferred[_T], object, None],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             Coroutine[Deferred[_T], object, None],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         ],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         status: _CancellationStatus,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ) -> None:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         Carry out the work of L{inlineCallbacks}.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         Iterate the generator produced by an C{@}L{inlineCallbacks}-decorated\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         function, C{gen}, C{send()}ing it the results of each value C{yield}ed by\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         that generator, until a L{Deferred} is yielded, at which point a callback\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         is added to that L{Deferred} to call this function again.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param result: The last result seen by this generator.  Note that this is\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             never a L{Deferred} - by the time this function is invoked, the\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             L{Deferred} has been called back and this will be a particular result\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             at a point in its callback chain.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param gen: a generator object returned by calling a function or method\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             decorated with C{@}L{inlineCallbacks}\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param status: a L{_CancellationStatus} tracking the current status of C{gen}\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # This function is complicated by the need to prevent unbounded recursion\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # arising from repeatedly yielding immediately ready deferreds.  This while\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # loop and the waiting variable solve that by manually unfolding the\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # recursion.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # waiting for result?  # result\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         waiting: List[Any] = [True, None]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # Get the current contextvars Context object.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         current_context = _copy_context()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         while 1:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             try:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 # Send the last result back as the result of the yield expression.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 isFailure = isinstance(result, Failure)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 if isFailure:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                     result = current_context.run(\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                         cast(Failure, result).throwExceptionIntoGenerator, gen\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                     )\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 else:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >                   result = current_context.run(gen.send, result)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:1660: \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:62: in run\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return f(*args, **kwargs)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/scrapyrt/core.py:42: in crawl\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.engine = self._create_engine()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/crawler.py:101: in _create_engine\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return ExecutionEngine(self, lambda _: self.stop())\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/engine.py:69: in __init__\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.downloader = downloader_cls(crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py:83: in __init__\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:53: in from_crawler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return cls.from_settings(crawler.settings, crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:34: in from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mwcls = load_object(clspath)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py:61: in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py:126: in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py:27: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import TunnelError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py:23: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py:11: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     import logging\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from OpenSSL import SSL\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from service_identity.exceptions import CertificateError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from twisted.internet._sslverify import ClientTLSOptions, verifyHostname, VerificationError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from twisted.internet.ssl import AcceptableCiphers\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.utils.ssl import x509name_to_string, get_temp_key_info\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     logger = logging.getLogger(__name__)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3 = 'SSLv3'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLS = 'TLS'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv10 = 'TLSv1.0'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv11 = 'TLSv1.1'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv12 = 'TLSv1.2'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     openssl_methods = {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLS: SSL.SSLv23_METHOD,                      # protocol negotiation (recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv10: SSL.TLSv1_METHOD,                    # TLS 1.0 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv11: getattr(SSL, 'TLSv1_1_METHOD', 5),   # TLS 1.1 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv12: getattr(SSL, 'TLSv1_2_METHOD', 6),   # TLS 1.2 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     }\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E   AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py:23: AttributeError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ----------------------------- Captured stdout call -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ------------------------------ Captured log call -------------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"http\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Traceback (most recent call last):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     dhcls = load_object(path)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"https\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Traceback (most recent call last):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     dhcls = load_object(path)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.s3.S3DownloadHandler\" for scheme \"s3\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Traceback (most recent call last):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     dhcls = load_object(path)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/s3.py\", line 3, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http import HTTPDownloadHandler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ________________ TestCrawler.test_crawl_start_requests_enabled _________________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | result = None, gen = <generator object crawl at 0x7f2c3e79ca40>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | status = _CancellationStatus(deferred=<Deferred at 0x7f2c3e6f54e0 current result: None>, waitingOn=None)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @_extraneous\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def _inlineCallbacks(\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         result: object,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         gen: Union[\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             Generator[Deferred[_T], object, None],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             Coroutine[Deferred[_T], object, None],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         ],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         status: _CancellationStatus,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ) -> None:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         Carry out the work of L{inlineCallbacks}.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         Iterate the generator produced by an C{@}L{inlineCallbacks}-decorated\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         function, C{gen}, C{send()}ing it the results of each value C{yield}ed by\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         that generator, until a L{Deferred} is yielded, at which point a callback\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         is added to that L{Deferred} to call this function again.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param result: The last result seen by this generator.  Note that this is\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             never a L{Deferred} - by the time this function is invoked, the\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             L{Deferred} has been called back and this will be a particular result\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             at a point in its callback chain.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param gen: a generator object returned by calling a function or method\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             decorated with C{@}L{inlineCallbacks}\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param status: a L{_CancellationStatus} tracking the current status of C{gen}\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # This function is complicated by the need to prevent unbounded recursion\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # arising from repeatedly yielding immediately ready deferreds.  This while\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # loop and the waiting variable solve that by manually unfolding the\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # recursion.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # waiting for result?  # result\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         waiting: List[Any] = [True, None]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # Get the current contextvars Context object.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         current_context = _copy_context()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         while 1:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             try:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 # Send the last result back as the result of the yield expression.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 isFailure = isinstance(result, Failure)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 if isFailure:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                     result = current_context.run(\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                         cast(Failure, result).throwExceptionIntoGenerator, gen\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                     )\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 else:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >                   result = current_context.run(gen.send, result)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:1660: \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:62: in run\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return f(*args, **kwargs)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/scrapyrt/core.py:42: in crawl\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.engine = self._create_engine()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/crawler.py:101: in _create_engine\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return ExecutionEngine(self, lambda _: self.stop())\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/engine.py:69: in __init__\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.downloader = downloader_cls(crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py:83: in __init__\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:53: in from_crawler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return cls.from_settings(crawler.settings, crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:34: in from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mwcls = load_object(clspath)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py:61: in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py:126: in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py:27: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import TunnelError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py:23: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py:11: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     import logging\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from OpenSSL import SSL\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from service_identity.exceptions import CertificateError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from twisted.internet._sslverify import ClientTLSOptions, verifyHostname, VerificationError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from twisted.internet.ssl import AcceptableCiphers\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.utils.ssl import x509name_to_string, get_temp_key_info\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     logger = logging.getLogger(__name__)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3 = 'SSLv3'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLS = 'TLS'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv10 = 'TLSv1.0'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv11 = 'TLSv1.1'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv12 = 'TLSv1.2'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     openssl_methods = {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLS: SSL.SSLv23_METHOD,                      # protocol negotiation (recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv10: SSL.TLSv1_METHOD,                    # TLS 1.0 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv11: getattr(SSL, 'TLSv1_1_METHOD', 5),   # TLS 1.1 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv12: getattr(SSL, 'TLSv1_2_METHOD', 6),   # TLS 1.2 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     }\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E   AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py:23: AttributeError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ----------------------------- Captured stdout call -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ------------------------------ Captured log call -------------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"http\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Traceback (most recent call last):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     dhcls = load_object(path)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"https\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Traceback (most recent call last):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     dhcls = load_object(path)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.s3.S3DownloadHandler\" for scheme \"s3\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | Traceback (most recent call last):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     dhcls = load_object(path)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/s3.py\", line 3, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http import HTTPDownloadHandler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ____________________ TestLogObserver.test_scrapy_filtering _____________________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | result = None, gen = <generator object crawl at 0x7f2c3e79ceb8>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | status = _CancellationStatus(deferred=<Deferred at 0x7f2c3e43d160 current result: <twisted.python.failure.Failure builtins.AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'>>, waitingOn=None)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @_extraneous\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def _inlineCallbacks(\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         result: object,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         gen: Union[\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             Generator[Deferred[_T], object, None],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             Coroutine[Deferred[_T], object, None],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         ],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         status: _CancellationStatus,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ) -> None:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         Carry out the work of L{inlineCallbacks}.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         Iterate the generator produced by an C{@}L{inlineCallbacks}-decorated\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         function, C{gen}, C{send()}ing it the results of each value C{yield}ed by\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         that generator, until a L{Deferred} is yielded, at which point a callback\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         is added to that L{Deferred} to call this function again.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param result: The last result seen by this generator.  Note that this is\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             never a L{Deferred} - by the time this function is invoked, the\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             L{Deferred} has been called back and this will be a particular result\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             at a point in its callback chain.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param gen: a generator object returned by calling a function or method\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             decorated with C{@}L{inlineCallbacks}\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         @param status: a L{_CancellationStatus} tracking the current status of C{gen}\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # This function is complicated by the need to prevent unbounded recursion\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # arising from repeatedly yielding immediately ready deferreds.  This while\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # loop and the waiting variable solve that by manually unfolding the\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # recursion.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # waiting for result?  # result\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         waiting: List[Any] = [True, None]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         # Get the current contextvars Context object.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         current_context = _copy_context()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         while 1:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             try:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 # Send the last result back as the result of the yield expression.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 isFailure = isinstance(result, Failure)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 if isFailure:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                     result = current_context.run(\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                         cast(Failure, result).throwExceptionIntoGenerator, gen\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                     )\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                 else:\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >                   result = current_context.run(gen.send, result)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:1660: \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:62: in run\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return f(*args, **kwargs)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/scrapyrt/core.py:42: in crawl\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.engine = self._create_engine()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/crawler.py:101: in _create_engine\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return ExecutionEngine(self, lambda _: self.stop())\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/engine.py:69: in __init__\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.downloader = downloader_cls(crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py:83: in __init__\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:53: in from_crawler\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return cls.from_settings(crawler.settings, crawler)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:34: in from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mwcls = load_object(clspath)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py:61: in load_object\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     mod = import_module(module)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py:126: in import_module\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py:27: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.handlers.http11 import TunnelError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py:23: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py:11: in <module>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     import logging\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from OpenSSL import SSL\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from service_identity.exceptions import CertificateError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from twisted.internet._sslverify import ClientTLSOptions, verifyHostname, VerificationError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from twisted.internet.ssl import AcceptableCiphers\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from scrapy.utils.ssl import x509name_to_string, get_temp_key_info\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     logger = logging.getLogger(__name__)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_SSLv3 = 'SSLv3'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLS = 'TLS'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv10 = 'TLSv1.0'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv11 = 'TLSv1.1'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     METHOD_TLSv12 = 'TLSv1.2'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     openssl_methods = {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLS: SSL.SSLv23_METHOD,                      # protocol negotiation (recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv10: SSL.TLSv1_METHOD,                    # TLS 1.0 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv11: getattr(SSL, 'TLSv1_1_METHOD', 5),   # TLS 1.1 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         METHOD_TLSv12: getattr(SSL, 'TLSv1_2_METHOD', 6),   # TLS 1.2 only\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     }\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E   AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py:23: AttributeError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ TestCrawlResourceIntegration.test_no_url_but_start_requests_present[perform_get] _\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed2bf28>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3e5b4320>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | method = <function perform_get at 0x7f2c3ec0d400>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize(\"method\", [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         perform_get, perform_post\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_no_url_but_start_requests_present(self, server, method):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = method(server.url(\"crawl.json\"), {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             'spider_name': \"test_with_sr\",\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"start_requests\": True\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }, {})\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res.status_code == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       assert 500 == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +  where 500 = <Response [500]>.status_code\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:223: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:16:57+0000 [-] Log opened.\\n2023-07-01 10:16:57+0000 [-] Site starting on 31396\\n2023-07-01 10:16:57+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f5ed8f92c18>\\n2023-07-01 10:16:57+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ TestCrawlResourceIntegration.test_no_url_but_start_requests_present[perform_post] _\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed2bf98>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3e51bcf8>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | method = <function perform_post at 0x7f2c3ec0da60>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize(\"method\", [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         perform_get, perform_post\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_no_url_but_start_requests_present(self, server, method):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = method(server.url(\"crawl.json\"), {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             'spider_name': \"test_with_sr\",\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"start_requests\": True\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }, {})\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res.status_code == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       assert 500 == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +  where 500 = <Response [500]>.status_code\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:223: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:16:59+0000 [-] Log opened.\\n2023-07-01 10:16:59+0000 [-] Site starting on 14605\\n2023-07-01 10:16:59+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f1250ecfc50>\\n2023-07-01 10:16:59+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ___ TestCrawlResourceIntegration.test_no_request_but_start_requests_present ____\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed02080>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3e3a7da0>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_no_request_but_start_requests_present(self, server):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"Test for POST handler checking if everything works fine\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         if there is no 'request' argument, but 'start_requests' are\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         present. Not checked above because of the way default test fixtures\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         are written.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         post_data = {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"no_request\": {},\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"start_requests\": True,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"spider_name\": \"test_with_sr\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         post_data.update(post_data)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = requests.post(server.url(\"crawl.json\"),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                             json=post_data)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res.status_code == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       assert 500 == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +  where 500 = <Response [500]>.status_code\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:255: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:02+0000 [-] Log opened.\\n2023-07-01 10:17:02+0000 [-] Site starting on 32026\\n2023-07-01 10:17:02+0000 [-] Starting factory <twisted.web.server.Site object at 0x7fc31bd2fcc0>\\n2023-07-01 10:17:02+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ TestCrawlResourceIntegration.test_url_and_start_requests_present[perform_get] _\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed022e8>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3e588a58>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | method = <function perform_get at 0x7f2c3ec0d400>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize(\"method\", [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         perform_get, perform_post\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_url_and_start_requests_present(self, server, method):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         spider_data = {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"url\": server.target_site.url(\"page3.html\")\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         api_params = {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"spider_name\": \"test_with_sr\",\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"start_requests\": True,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = method(server.url(\"crawl.json\"), api_params,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      spider_data)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res.status_code == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       assert 500 == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +  where 500 = <Response [500]>.status_code\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:291: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:06+0000 [-] Log opened.\\n2023-07-01 10:17:06+0000 [-] Site starting on 22606\\n2023-07-01 10:17:06+0000 [-] Starting factory <twisted.web.server.Site object at 0x7fb3809250b8>\\n2023-07-01 10:17:06+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ TestCrawlResourceIntegration.test_url_and_start_requests_present[perform_post] _\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed02358>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3e4fa518>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | method = <function perform_post at 0x7f2c3ec0da60>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize(\"method\", [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         perform_get, perform_post\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_url_and_start_requests_present(self, server, method):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         spider_data = {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"url\": server.target_site.url(\"page3.html\")\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         api_params = {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"spider_name\": \"test_with_sr\",\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"start_requests\": True,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = method(server.url(\"crawl.json\"), api_params,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      spider_data)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res.status_code == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       assert 500 == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +  where 500 = <Response [500]>.status_code\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:291: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:08+0000 [-] Log opened.\\n2023-07-01 10:17:08+0000 [-] Site starting on 12238\\n2023-07-01 10:17:08+0000 [-] Starting factory <twisted.web.server.Site object at 0x7effc3270cc0>\\n2023-07-01 10:17:08+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _____________ TestCrawlResourceIntegration.test_crawl[perform_get] _____________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed02278>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3e588ef0>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | method = <function perform_get at 0x7f2c3ec0d400>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize(\"method\", [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         perform_get, perform_post\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_crawl(self, server, method):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         url = server.url(\"crawl.json\")\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = method(url,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"spider_name\": \"test\"},\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"url\": server.target_site.url(\"page1.html\")})\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         expected_items = [{\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             u'name': ['Page 1'],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res_json = res.json()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res_json[\"status\"] == \"ok\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       AssertionError: assert 'error' == 'ok'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E         - ok\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E         + error\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:365: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:20+0000 [-] Log opened.\\n2023-07-01 10:17:20+0000 [-] Site starting on 17898\\n2023-07-01 10:17:20+0000 [-] Starting factory <twisted.web.server.Site object at 0x7ff214d34cc0>\\n2023-07-01 10:17:20+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ____________ TestCrawlResourceIntegration.test_crawl[perform_post] _____________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed02048>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3ed2bda0>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | method = <function perform_post at 0x7f2c3ec0da60>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize(\"method\", [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         perform_get, perform_post\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_crawl(self, server, method):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         url = server.url(\"crawl.json\")\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = method(url,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"spider_name\": \"test\"},\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"url\": server.target_site.url(\"page1.html\")})\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         expected_items = [{\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             u'name': ['Page 1'],\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res_json = res.json()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res_json[\"status\"] == \"ok\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       AssertionError: assert 'error' == 'ok'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E         - ok\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E         + error\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:365: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:22+0000 [-] Log opened.\\n2023-07-01 10:17:22+0000 [-] Site starting on 24899\\n2023-07-01 10:17:22+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f5e627fdcf8>\\n2023-07-01 10:17:22+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ________ TestCrawlResourceIntegration.test_passing_errback[perform_get] ________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed029b0>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3e4296d8>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | method = <function perform_get at 0x7f2c3ec0d400>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize(\"method\", [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         perform_get, perform_post\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_passing_errback(self, server, method):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         url = server.url(\"crawl.json\")\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = method(url,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"spider_name\": \"test\"},\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"url\": server.target_site.url(\"err/503\"),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                       'errback': 'some_errback'})\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res_json = res.json()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res_json.get('stats').get('log_count/ERROR') == 2\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       AttributeError: 'NoneType' object has no attribute 'get'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:395: AttributeError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:25+0000 [-] Log opened.\\n2023-07-01 10:17:26+0000 [-] Site starting on 6277\\n2023-07-01 10:17:26+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f45eb3d8c50>\\n2023-07-01 10:17:26+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _______ TestCrawlResourceIntegration.test_passing_errback[perform_post] ________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed02a20>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3e64fac8>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | method = <function perform_post at 0x7f2c3ec0da60>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize(\"method\", [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         perform_get, perform_post\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_passing_errback(self, server, method):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         url = server.url(\"crawl.json\")\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = method(url,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"spider_name\": \"test\"},\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"url\": server.target_site.url(\"err/503\"),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                       'errback': 'some_errback'})\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res_json = res.json()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res_json.get('stats').get('log_count/ERROR') == 2\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       AttributeError: 'NoneType' object has no attribute 'get'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:395: AttributeError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:28+0000 [-] Log opened.\\n2023-07-01 10:17:28+0000 [-] Site starting on 22621\\n2023-07-01 10:17:28+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f26c8b87c50>\\n2023-07-01 10:17:28+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _________ TestCrawlResourceIntegration.test_bytes_in_item[perform_get] _________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed02b70>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3e5f2be0>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | method = <function perform_get at 0x7f2c3ec0d400>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize(\"method\", [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         perform_get, perform_post\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_bytes_in_item(self, server, method):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         url = server.url(\"crawl.json\")\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = method(url,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"spider_name\": \"test\"},\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"url\": server.target_site.url(\"page1.html\"),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                       'callback': 'return_bytes'})\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res.status_code == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       assert 500 == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +  where 500 = <Response [500]>.status_code\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:414: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:29+0000 [-] Log opened.\\n2023-07-01 10:17:29+0000 [-] Site starting on 11946\\n2023-07-01 10:17:29+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f2fc952a780>\\n2023-07-01 10:17:29+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ________ TestCrawlResourceIntegration.test_bytes_in_item[perform_post] _________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed02be0>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3e707e10>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | method = <function perform_post at 0x7f2c3ec0da60>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     @pytest.mark.parametrize(\"method\", [\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         perform_get, perform_post\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     ])\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_bytes_in_item(self, server, method):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         url = server.url(\"crawl.json\")\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = method(url,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"spider_name\": \"test\"},\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                      {\"url\": server.target_site.url(\"page1.html\"),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |                       'callback': 'return_bytes'})\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res.status_code == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       assert 500 == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +  where 500 = <Response [500]>.status_code\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:414: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:32+0000 [-] Log opened.\\n2023-07-01 10:17:32+0000 [-] Site starting on 30650\\n2023-07-01 10:17:32+0000 [-] Starting factory <twisted.web.server.Site object at 0x7ff0dd9b7d30>\\n2023-07-01 10:17:32+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | __________ TestCrawlResourceIntegration.test_crawl_with_argument_get ___________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed02c88>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3e427a90>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_crawl_with_argument_get(self, server):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         url = server.url(\"crawl.json\")\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         postcode = \"43-300\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         argument = json.dumps({\"postcode\": postcode})\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         argument = quote(argument)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = perform_get(url, {\"spider_name\": \"test\"}, {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"url\": server.target_site.url(\"page1.html\"),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"crawl_args\": argument,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"callback\": 'return_argument'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         })\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         expected_items = [{\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             u'name': postcode,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res_json = res.json()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res_json[\"status\"] == \"ok\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       AssertionError: assert 'error' == 'ok'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E         - ok\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E         + error\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:431: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:34+0000 [-] Log opened.\\n2023-07-01 10:17:34+0000 [-] Site starting on 31066\\n2023-07-01 10:17:34+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f8e49c70cc0>\\n2023-07-01 10:17:34+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | __________ TestCrawlResourceIntegration.test_crawl_with_argument_post __________\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ed02d68>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c3ea5ef98>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_crawl_with_argument_post(self, server):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         url = server.url(\"crawl.json\")\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         postcode = \"43-300\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         argument = {\"postcode\": postcode}\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = perform_post(url, {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"spider_name\": \"test\",\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"crawl_args\": argument\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }, {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"url\": server.target_site.url(\"page1.html\"),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"callback\": 'return_argument'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         })\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         expected_items = [{\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             u'name': postcode,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         }]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res_json = res.json()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res.status_code == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       assert 500 == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E        +  where 500 = <Response [500]>.status_code\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:452: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:36+0000 [-] Log opened.\\n2023-07-01 10:17:36+0000 [-] Site starting on 25628\\n2023-07-01 10:17:36+0000 [-] Starting factory <twisted.web.server.Site object at 0x7fbdd32f4cc0>\\n2023-07-01 10:17:36+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | __ TestCrawlResourceIntegration.test_crawl_with_argument_attribute_collision ___\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7f2c3ee220b8>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7f2c41204048>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def test_crawl_with_argument_attribute_collision(self, server):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"If there is attribute collision and some argument to spider\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |          passed via API, and this argument collides with spider attribute,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |          argument from request overrides spider attribute.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         \"\"\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         url = server.url(\"crawl.json\")\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         argument = quote(json.dumps({\"some_attribute\": \"string\"}))\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res = perform_get(url, {\"spider_name\": \"test\"}, {\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"url\": server.target_site.url(\"page1.html\"),\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             \"crawl_args\": argument,\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         })\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         def check_res(res):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             res_json = res.json()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             assert res_json[\"status\"] == \"ok\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             assert res.status_code == 200\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             assert res_json['items']\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |             assert len(res_json['items']) == 1\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       check_res(res)\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:525: \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | res = <Response [500]>\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     def check_res(res):\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |         res_json = res.json()\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | >       assert res_json[\"status\"] == \"ok\"\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E       AssertionError: assert 'error' == 'ok'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E         - ok\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | E         + error\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:520: AssertionError\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ---------------------------- Captured stdout setup -----------------------------\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-07-01 10:17:42+0000 [-] Log opened.\\n2023-07-01 10:17:42+0000 [-] Site starting on 13135\\n2023-07-01 10:17:42+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f6f8a27dcc0>\\n2023-07-01 10:17:42+0000 [-] Running with reactor: EPollReactor. \\n'\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | =============================== warnings summary ===============================\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ../../../opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |   /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   |     from cryptography.hazmat.bindings.openssl.binding import Binding\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | \n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | - generated xml file: /tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/report.xml -\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | =========================== short test summary info ============================\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_cmdline.py::TestCmdLine::test_reactor_launched[twisted.internet.asyncioreactor.AsyncioSelectorReactor-AsyncioSelectorReactor]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_cmdline.py::TestCmdLine::test_reactor_launched[None-EPollReactor]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_crawler.py::TestCrawler::test_crawl_start_requests_default\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_crawler.py::TestCrawler::test_crawl_start_requests_disabled\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_crawler.py::TestCrawler::test_crawl_start_requests_enabled\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_log_observer.py::TestLogObserver::test_scrapy_filtering - A...\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_no_url_but_start_requests_present[perform_get]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_no_url_but_start_requests_present[perform_post]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_no_request_but_start_requests_present\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_url_and_start_requests_present[perform_get]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_url_and_start_requests_present[perform_post]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_crawl[perform_get]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_crawl[perform_post]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_passing_errback[perform_get]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_passing_errback[perform_post]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_bytes_in_item[perform_get]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_bytes_in_item[perform_post]\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_crawl_with_argument_get\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_crawl_with_argument_post\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_crawl_with_argument_attribute_collision\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   | ============= 20 failed, 84 passed, 1 warning in 65.78s (0:01:05) ==============\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build]   \u274c  Failure - Main Test with pytest\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build] exitcode '1': failure\n[849e3892-a4f4-4ef5-b528-3cef86b1c6ea/build] \ud83c\udfc1  Job failed\n",
        "stderr": "Error: Job 'build' failed\n",
        "workflow": {
            "path": "/tmp/558156d8-17ed-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/.github/workflows/main-crawler.yml",
            "type": "pytest"
        },
        "workflow_name": "849e3892-a4f4-4ef5-b528-3cef86b1c6ea",
        "build_tool": "pytest",
        "elapsed_time": 288.369019985199
    }
}