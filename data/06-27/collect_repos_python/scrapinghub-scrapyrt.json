{
    "repository": "scrapinghub/scrapyrt",
    "stars": 775,
    "language": "python",
    "size": 307,
    "clone_url": "https://github.com/scrapinghub/scrapyrt.git",
    "timestamp": "2023-06-28T10:44:46.923521Z",
    "clone_success": true,
    "number_of_actions": 2,
    "number_of_test_actions": 1,
    "actions_successful": true,
    "actions_build_tools": [
        "unknown",
        "pytest"
    ],
    "actions_test_build_tools": [
        "pytest"
    ],
    "actions_run": {
        "failed": false,
        "tests": [
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_find_scrapy_project",
                "time": 0.023,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_find_scrapy_project_invalid_conf",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_get_application",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_execute",
                "time": 0.008,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_reactor_launched[twisted.internet.asyncioreactor.AsyncioSelectorReactor-AsyncioSelectorReactor]",
                "time": 1.046,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_cmdline.TestCmdLine",
                "name": "test_reactor_launched[None-EPollReactor]",
                "time": 1.044,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCrawl",
                "name": "test_crawl",
                "time": 0.023,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCrawl",
                "name": "test_no_spider",
                "time": 0.009,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCrawl",
                "name": "test_spider_arguments_are_passed",
                "time": 0.011,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCrawl",
                "name": "test_spider_exists",
                "time": 0.011,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestGetProjectSettings",
                "name": "test_get_project_settings",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_modify_realtime_request",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_modify_realtime_request_is_not_callable",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_pass_good_spider_errback",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_pass_wrong_spider_errback",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_raise_error_if_not_callable",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestSpiderIdle",
                "name": "test_spider_opened",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestHandleScheduling",
                "name": "test_handle_scheduling",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestHandleScheduling",
                "name": "test_handle_scheduling_another_spider",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestLimitRuntime",
                "name": "test_limit_runtime",
                "time": 1.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestLimitRuntime",
                "name": "test_string_number_timeout_value",
                "time": 1.008,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestLimitRuntime",
                "name": "test_wrong_timeout_value",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestHandleSpiderError",
                "name": "test_handle_spider_error_another_spider",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestHandleSpiderError",
                "name": "test_handle_spider_error_debug_false",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestHandleSpiderError",
                "name": "test_handle_spider_error_debug_true",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestLimitRequests",
                "name": "test_max_requests_not_set",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestLimitRequests",
                "name": "test_max_requests_set",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestGetItem",
                "name": "test_get_item",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestGetItem",
                "name": "test_get_item_another_spider",
                "time": 0.007,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCollectDropped",
                "name": "test_collect_dropped",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCollectDropped",
                "name": "test_collect_dropped_another_spider",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestReturnItems",
                "name": "test_return_items",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestReturnItems",
                "name": "test_return_items_without_debug",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCreateSpiderRequest",
                "name": "test_invalid_arguments",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCreateSpiderRequest",
                "name": "test_invalid_url",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCreateSpiderRequest",
                "name": "test_valid_arguments",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestStartRequests",
                "name": "test_start_requests_false",
                "time": 0.141,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestStartRequests",
                "name": "test_start_requests_true",
                "time": 0.102,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawl_manager.TestCreateProperLogFile",
                "name": "test_filename",
                "time": 0.009,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawler.TestCrawler",
                "name": "test_crawl_start_requests_default",
                "time": 0.705,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawler.TestCrawler",
                "name": "test_crawl_start_requests_disabled",
                "time": 0.657,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawler.TestCrawler",
                "name": "test_crawl_start_requests_enabled",
                "time": 0.572,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_crawler_process.CralwerProcessTestCase",
                "name": "test_signals",
                "time": 0.033,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_decorators.TestDecorators",
                "name": "test_deprecated",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_log_observer.TestLogObserver",
                "name": "test_emit_called",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_log_observer.TestLogObserver",
                "name": "test_log_start_messages_filtering",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_log_observer.TestLogObserver",
                "name": "test_scrapy_filtering",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_log_observer.TestLogObserver",
                "name": "test_unicode_message",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_is_leaf",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_render_GET",
                "time": 0.007,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_render_POST",
                "time": 0.009,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_render_POST_invalid_json",
                "time": 0.026,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_render_POST_invalid_options",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_validate_options[scrapy_args0-api_args0-False]",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_validate_options[scrapy_args1-api_args1-True]",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResource",
                "name": "test_prepare_response",
                "time": 0.013,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceGetRequiredArgument",
                "name": "test_empty_argument",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceGetRequiredArgument",
                "name": "test_get_argument",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceGetRequiredArgument",
                "name": "test_raise_error",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_parameters[perform_get]",
                "time": 1.507,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_parameters[perform_post]",
                "time": 1.513,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_url_no_start_requests[perform_get]",
                "time": 1.401,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_url_no_start_requests[perform_post]",
                "time": 1.698,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_url_but_start_requests_present[perform_get]",
                "time": 1.611,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_url_but_start_requests_present[perform_post]",
                "time": 1.569,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_request_but_start_requests_present",
                "time": 1.659,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_request_in_POST_handler",
                "time": 1.592,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_url_and_start_requests_present[perform_get]",
                "time": 1.544,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_url_and_start_requests_present[perform_post]",
                "time": 2.005,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_spider_name[perform_get]",
                "time": 1.92,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_no_spider_name[perform_post]",
                "time": 1.808,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_invalid_scrapy_request_detected_in_api",
                "time": 1.913,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_invalid_scrapy_request_detected_by_scrapy[perform_get]",
                "time": 1.863,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_invalid_scrapy_request_detected_by_scrapy[perform_post]",
                "time": 1.814,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl[perform_get]",
                "time": 2.216,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AssertionError: assert 'error' == 'ok'\n  - ok\n  + error",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl[perform_post]",
                "time": 2.4,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AssertionError: assert 'error' == 'ok'\n  - ok\n  + error",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_invalid_json_in_post",
                "time": 2.108,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_passing_errback[perform_get]",
                "time": 1.605,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: 'NoneType' object has no attribute 'get'",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_passing_errback[perform_post]",
                "time": 1.83,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AttributeError: 'NoneType' object has no attribute 'get'",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_bytes_in_item[perform_get]",
                "time": 1.712,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_bytes_in_item[perform_post]",
                "time": 1.68,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl_with_argument_get",
                "time": 1.489,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AssertionError: assert 'error' == 'ok'\n  - ok\n  + error",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl_with_argument_post",
                "time": 1.709,
                "results": [
                    {
                        "result": "Failure",
                        "message": "assert 500 == 200\n +  where 500 = <Response [500]>.status_code",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl_with_argument_invalid_json",
                "time": 1.494,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl_with_argument_invalid_name",
                "time": 1.533,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_crawl.TestCrawlResourceIntegration",
                "name": "test_crawl_with_argument_attribute_collision",
                "time": 1.461,
                "results": [
                    {
                        "result": "Failure",
                        "message": "AssertionError: assert 'error' == 'ok'\n  - ok\n  + error",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_realtimeapi.TestRealtimeApi",
                "name": "test_realtimeapi_with_custom_settings",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_realtimeapi.TestRealtimeApi",
                "name": "test_realtimeapi_with_default_settings",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_root.TestRootResourceIntegration",
                "name": "test_root",
                "time": 1.491,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRender",
                "name": "test_render_deferred_fail",
                "time": 0.009,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRender",
                "name": "test_render_deferred_succeed",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRender",
                "name": "test_render_exception",
                "time": 0.006,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRender",
                "name": "test_render_ok",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestHandleErrors",
                "name": "test_error_400",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestHandleErrors",
                "name": "test_error_403",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestHandleErrors",
                "name": "test_error_not_supported_method",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestHandleErrors",
                "name": "test_exception",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestHandleErrors",
                "name": "test_failure",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestFormatErrorResponse",
                "name": "test_format_error_response",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRenderObject",
                "name": "test_access_control_allow_methods_header_get",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRenderObject",
                "name": "test_access_control_allow_methods_header_get_post",
                "time": 0.008,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_resource_serviceresource.TestRenderObject",
                "name": "test_render_object",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_utils.TestUtils",
                "name": "test_get_scrapy_request_args",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "tests.test_utils.TestUtils",
                "name": "test_get_scrapy_request_args_error",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            }
        ],
        "stdout": "[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build] \ud83d\ude80  Start image=crawlergpt:latest\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udc33  docker pull image=crawlergpt:latest platform= username= forcePull=false\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udc33  docker create image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udc33  docker run image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt] user=0 workdir=\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \u2601  git clone 'https://github.com/actions/setup-python' # ref=v2\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build] \ud83e\uddea  Matrix: map[python-version:3.6 scrapy-version:2.5.1]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build] \u2b50 Run Main actions/checkout@v2\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \u2705  Success - Main actions/checkout@v2\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build] \u2b50 Run Main Set up Python 3.6\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udc33  docker cp src=/tmp/act-cache/6e919d8e-cf1c-4227-8421-66f0b945423c/act/actions-setup-python@v2/ dst=/var/run/act/actions/actions-setup-python@v2/\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /var/run/act/actions/actions-setup-python@v2/] user=0 workdir=\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udc33  docker exec cmd=[node /var/run/act/actions/actions-setup-python@v2/dist/setup/index.js] user= workdir=\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::Semantic version spec of 3.6 is 3.6\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::isExplicit: \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::explicit? false\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::isExplicit: 2.7.18\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::explicit? true\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::isExplicit: 3.5.10\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::explicit? true\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::isExplicit: 3.6.14\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::explicit? true\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::isExplicit: 3.7.11\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::explicit? true\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::isExplicit: 3.8.11\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::explicit? true\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::isExplicit: 3.9.6\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::explicit? true\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::evaluating 6 versions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::matched: 3.6.14\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::checking cache: /opt/hostedtoolcache/Python/3.6.14/x64\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udcac  ::debug::Found tool in cache Python 3.6.14 x64\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Successfully setup CPython (3.6.14)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \u2753 add-matcher /run/act/actions/actions-setup-python@v2/.github/python.json\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \u2705  Success - Main Set up Python 3.6\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \u2699  ::set-env:: pythonLocation=/opt/hostedtoolcache/Python/3.6.14/x64\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \u2699  ::set-env:: LD_LIBRARY_PATH=/opt/hostedtoolcache/Python/3.6.14/x64/lib\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \u2699  ::set-output:: python-version=3.6.14\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.6.14/x64\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.6.14/x64/bin\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build] \u2b50 Run Main Install dependencies\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/2] user= workdir=\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Requirement already satisfied: pip in /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages (21.2.4)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting pip\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Installing collected packages: pip\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Attempting uninstall: pip\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     Found existing installation: pip 21.2.4\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     Uninstalling pip-21.2.4:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |       Successfully uninstalled pip-21.2.4\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Successfully installed pip-21.3.1\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting scrapy==2.5.1\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading Scrapy-2.5.1-py2.py3-none-any.whl (254 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting itemadapter>=0.1.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting queuelib>=1.4.2\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting service-identity>=16.0.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting h2<4.0,>=3.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting PyDispatcher>=2.0.5\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting zope.interface>=4.1.3\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading zope.interface-5.5.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (253 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting lxml>=3.5.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading lxml-4.9.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.6 MB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting itemloaders>=1.0.1\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting protego>=0.1.15\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting parsel>=1.5.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting w3lib>=1.17.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting pyOpenSSL>=16.2.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading pyOpenSSL-23.2.0-py3-none-any.whl (59 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting Twisted[http2]>=17.9.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading Twisted-22.4.0-py3-none-any.whl (3.1 MB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting cssselect>=0.9.1\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting cryptography>=2.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading cryptography-40.0.2-cp36-abi3-manylinux_2_28_x86_64.whl (3.7 MB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting cffi>=1.12\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading cffi-1.15.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (402 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting hyperframe<6,>=5.2.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting hpack<4,>=3.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting jmespath>=0.9.5\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting six>=1.6.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting attrs>=19.1.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting pyasn1-modules\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting pyasn1\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting Automat>=0.8.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting incremental>=21.3.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting typing-extensions>=3.6.5\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting hyperlink>=17.1.1\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting constantly>=15.1\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting priority<2.0,>=1.1.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading priority-1.3.0-py2.py3-none-any.whl (11 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages (from zope.interface>=4.1.3->scrapy==2.5.1) (40.6.2)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting pycparser\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting idna>=2.5\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading idna-3.4-py3-none-any.whl (61 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Installing collected packages: six, pycparser, idna, attrs, zope.interface, w3lib, typing-extensions, pyasn1, lxml, incremental, hyperlink, hyperframe, hpack, cssselect, constantly, cffi, Automat, Twisted, pyasn1-modules, priority, parsel, jmespath, itemadapter, h2, cryptography, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, scrapy\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Successfully installed Automat-22.10.0 PyDispatcher-2.0.7 Twisted-22.4.0 attrs-22.2.0 cffi-1.15.1 constantly-15.1.0 cryptography-40.0.2 cssselect-1.1.0 h2-3.2.0 hpack-3.0.0 hyperframe-5.2.0 hyperlink-21.0.0 idna-3.4 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-0.10.0 lxml-4.9.2 parsel-1.6.0 priority-1.3.0 protego-0.2.1 pyOpenSSL-23.2.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycparser-2.21 queuelib-1.6.2 scrapy-2.5.1 service-identity-21.1.0 six-1.16.0 typing-extensions-4.1.1 w3lib-2.0.1 zope.interface-5.5.2\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting mock\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading mock-5.0.2-py3-none-any.whl (30 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting port-for\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading port_for-0.5.0-py2.py3-none-any.whl (18 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting Flask\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting pytest\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading pytest-7.0.1-py3-none-any.whl (296 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting requests\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting bumpversion\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading bumpversion-0.6.0-py2.py3-none-any.whl (8.4 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting flake8\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading flake8-5.0.4-py2.py3-none-any.whl (61 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting itsdangerous>=2.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting Werkzeug>=2.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting Jinja2>=3.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting click>=7.1.2\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading click-8.0.4-py3-none-any.whl (97 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting importlib-metadata>=0.12\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Requirement already satisfied: attrs>=19.2.0 in /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages (from pytest->-r requirements-dev.txt (line 4)) (22.2.0)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting packaging\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading packaging-21.3-py3-none-any.whl (40 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting py>=1.8.2\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting tomli>=1.0.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading tomli-1.2.3-py3-none-any.whl (12 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting pluggy<2.0,>=0.12\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting iniconfig\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting urllib3<1.27,>=1.21.1\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Requirement already satisfied: idna<4,>=2.5 in /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages (from requests->-r requirements-dev.txt (line 5)) (3.4)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting certifi>=2017.4.17\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting charset-normalizer~=2.0.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting bump2version\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading bump2version-1.0.1-py2.py3-none-any.whl (22 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting pyflakes<2.6.0,>=2.5.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading pyflakes-2.5.0-py2.py3-none-any.whl (66 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting mccabe<0.8.0,>=0.7.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting importlib-metadata>=0.12\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting pycodestyle<2.10.0,>=2.9.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading pycodestyle-2.9.1-py2.py3-none-any.whl (41 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Requirement already satisfied: typing-extensions>=3.6.4 in /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest->-r requirements-dev.txt (line 4)) (4.1.1)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting zipp>=0.5\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting MarkupSafe>=2.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting dataclasses\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Collecting pyparsing!=3.0.5,>=2.0.2\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   Downloading pyparsing-3.1.0-py3-none-any.whl (102 kB)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Installing collected packages: zipp, pyparsing, MarkupSafe, importlib-metadata, dataclasses, Werkzeug, urllib3, tomli, pyflakes, pycodestyle, py, pluggy, packaging, mccabe, Jinja2, itsdangerous, iniconfig, click, charset-normalizer, certifi, bump2version, requests, pytest, port-for, mock, Flask, flake8, bumpversion\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Successfully installed Flask-2.0.3 Jinja2-3.0.3 MarkupSafe-2.0.1 Werkzeug-2.0.3 bump2version-1.0.1 bumpversion-0.6.0 certifi-2023.5.7 charset-normalizer-2.0.12 click-8.0.4 dataclasses-0.8 flake8-5.0.4 importlib-metadata-4.2.0 iniconfig-1.1.1 itsdangerous-2.0.1 mccabe-0.7.0 mock-5.0.2 packaging-21.3 pluggy-1.0.0 port-for-0.5.0 py-1.11.0 pycodestyle-2.9.1 pyflakes-2.5.0 pyparsing-3.1.0 pytest-7.0.1 requests-2.27.1 tomli-1.2.3 urllib3-1.26.16 zipp-3.6.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \u2705  Success - Main Install dependencies\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build] \u2b50 Run Main Test with pytest\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/3] user= workdir=\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ============================= test session starts ==============================\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | platform linux -- Python 3.6.14, pytest-7.0.1, pluggy-1.0.0\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | rootdir: /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | collected 104 items\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | tests/test_cmdline.py ......                                             [  5%]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | tests/test_crawl_manager.py .................................            [ 37%]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | tests/test_crawler.py FFF                                                [ 40%]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | tests/test_crawler_process.py .                                          [ 41%]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | tests/test_decorators.py .                                               [ 42%]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | tests/test_log_observer.py ....                                          [ 46%]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | tests/test_resource_crawl.py ...............FFF.FF.....FF.FFFFFF..F      [ 82%]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | tests/test_resource_realtimeapi.py ..                                    [ 84%]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | tests/test_resource_root.py .                                            [ 85%]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | tests/test_resource_serviceresource.py .............                     [ 98%]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | tests/test_utils.py ..                                                   [100%]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | =================================== FAILURES ===================================\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ________________ TestCrawler.test_crawl_start_requests_default _________________\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | result = None, gen = <generator object crawl at 0x7fc15f48b780>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | status = _CancellationStatus(deferred=<Deferred at 0x7fc15f4d6978 current result: None>, waitingOn=None)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @_extraneous\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def _inlineCallbacks(\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         result: object,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         gen: Union[\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             Generator[Deferred[_T], object, None],\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             Coroutine[Deferred[_T], object, None],\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         ],\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         status: _CancellationStatus,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ) -> None:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         \"\"\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         Carry out the work of L{inlineCallbacks}.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         Iterate the generator produced by an C{@}L{inlineCallbacks}-decorated\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         function, C{gen}, C{send()}ing it the results of each value C{yield}ed by\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         that generator, until a L{Deferred} is yielded, at which point a callback\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         is added to that L{Deferred} to call this function again.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         @param result: The last result seen by this generator.  Note that this is\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             never a L{Deferred} - by the time this function is invoked, the\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             L{Deferred} has been called back and this will be a particular result\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             at a point in its callback chain.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         @param gen: a generator object returned by calling a function or method\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             decorated with C{@}L{inlineCallbacks}\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         @param status: a L{_CancellationStatus} tracking the current status of C{gen}\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         \"\"\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # This function is complicated by the need to prevent unbounded recursion\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # arising from repeatedly yielding immediately ready deferreds.  This while\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # loop and the waiting variable solve that by manually unfolding the\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # recursion.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # waiting for result?  # result\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         waiting: List[Any] = [True, None]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # Get the current contextvars Context object.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         current_context = _copy_context()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         while 1:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             try:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 # Send the last result back as the result of the yield expression.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 isFailure = isinstance(result, Failure)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 if isFailure:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                     result = current_context.run(\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                         cast(Failure, result).throwExceptionIntoGenerator, gen\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                     )\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 else:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >                   result = current_context.run(gen.send, result)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:1660: \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:62: in run\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return f(*args, **kwargs)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/scrapyrt/core.py:42: in crawl\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     self.engine = self._create_engine()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/crawler.py:101: in _create_engine\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return ExecutionEngine(self, lambda _: self.stop())\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/engine.py:69: in __init__\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     self.downloader = downloader_cls(crawler)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py:83: in __init__\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:53: in from_crawler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return cls.from_settings(crawler.settings, crawler)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:34: in from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mwcls = load_object(clspath)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py:61: in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py:126: in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py:27: in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import TunnelError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py:23: in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py:11: in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     import logging\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from OpenSSL import SSL\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from service_identity.exceptions import CertificateError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from twisted.internet._sslverify import ClientTLSOptions, verifyHostname, VerificationError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from twisted.internet.ssl import AcceptableCiphers\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.utils.ssl import x509name_to_string, get_temp_key_info\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     logger = logging.getLogger(__name__)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3 = 'SSLv3'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLS = 'TLS'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLSv10 = 'TLSv1.0'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLSv11 = 'TLSv1.1'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLSv12 = 'TLSv1.2'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     openssl_methods = {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLS: SSL.SSLv23_METHOD,                      # protocol negotiation (recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLSv10: SSL.TLSv1_METHOD,                    # TLS 1.0 only\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLSv11: getattr(SSL, 'TLSv1_1_METHOD', 5),   # TLS 1.1 only\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLSv12: getattr(SSL, 'TLSv1_2_METHOD', 6),   # TLS 1.2 only\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     }\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E   AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py:23: AttributeError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ----------------------------- Captured stdout call -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ------------------------------ Captured log call -------------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"http\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Traceback (most recent call last):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     dhcls = load_object(path)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"https\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Traceback (most recent call last):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     dhcls = load_object(path)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.s3.S3DownloadHandler\" for scheme \"s3\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Traceback (most recent call last):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     dhcls = load_object(path)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/s3.py\", line 3, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http import HTTPDownloadHandler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ________________ TestCrawler.test_crawl_start_requests_disabled ________________\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | result = None, gen = <generator object crawl at 0x7fc15f481728>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | status = _CancellationStatus(deferred=<Deferred at 0x7fc15f1aa0b8 current result: None>, waitingOn=None)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @_extraneous\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def _inlineCallbacks(\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         result: object,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         gen: Union[\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             Generator[Deferred[_T], object, None],\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             Coroutine[Deferred[_T], object, None],\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         ],\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         status: _CancellationStatus,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ) -> None:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         \"\"\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         Carry out the work of L{inlineCallbacks}.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         Iterate the generator produced by an C{@}L{inlineCallbacks}-decorated\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         function, C{gen}, C{send()}ing it the results of each value C{yield}ed by\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         that generator, until a L{Deferred} is yielded, at which point a callback\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         is added to that L{Deferred} to call this function again.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         @param result: The last result seen by this generator.  Note that this is\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             never a L{Deferred} - by the time this function is invoked, the\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             L{Deferred} has been called back and this will be a particular result\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             at a point in its callback chain.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         @param gen: a generator object returned by calling a function or method\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             decorated with C{@}L{inlineCallbacks}\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         @param status: a L{_CancellationStatus} tracking the current status of C{gen}\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         \"\"\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # This function is complicated by the need to prevent unbounded recursion\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # arising from repeatedly yielding immediately ready deferreds.  This while\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # loop and the waiting variable solve that by manually unfolding the\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # recursion.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # waiting for result?  # result\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         waiting: List[Any] = [True, None]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # Get the current contextvars Context object.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         current_context = _copy_context()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         while 1:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             try:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 # Send the last result back as the result of the yield expression.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 isFailure = isinstance(result, Failure)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 if isFailure:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                     result = current_context.run(\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                         cast(Failure, result).throwExceptionIntoGenerator, gen\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                     )\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 else:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >                   result = current_context.run(gen.send, result)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:1660: \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:62: in run\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return f(*args, **kwargs)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/scrapyrt/core.py:42: in crawl\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     self.engine = self._create_engine()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/crawler.py:101: in _create_engine\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return ExecutionEngine(self, lambda _: self.stop())\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/engine.py:69: in __init__\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     self.downloader = downloader_cls(crawler)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py:83: in __init__\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:53: in from_crawler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return cls.from_settings(crawler.settings, crawler)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:34: in from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mwcls = load_object(clspath)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py:61: in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py:126: in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py:27: in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import TunnelError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py:23: in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py:11: in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     import logging\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from OpenSSL import SSL\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from service_identity.exceptions import CertificateError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from twisted.internet._sslverify import ClientTLSOptions, verifyHostname, VerificationError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from twisted.internet.ssl import AcceptableCiphers\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.utils.ssl import x509name_to_string, get_temp_key_info\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     logger = logging.getLogger(__name__)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3 = 'SSLv3'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLS = 'TLS'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLSv10 = 'TLSv1.0'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLSv11 = 'TLSv1.1'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLSv12 = 'TLSv1.2'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     openssl_methods = {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLS: SSL.SSLv23_METHOD,                      # protocol negotiation (recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLSv10: SSL.TLSv1_METHOD,                    # TLS 1.0 only\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLSv11: getattr(SSL, 'TLSv1_1_METHOD', 5),   # TLS 1.1 only\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLSv12: getattr(SSL, 'TLSv1_2_METHOD', 6),   # TLS 1.2 only\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     }\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E   AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py:23: AttributeError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ----------------------------- Captured stdout call -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ------------------------------ Captured log call -------------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"http\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Traceback (most recent call last):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     dhcls = load_object(path)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"https\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Traceback (most recent call last):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     dhcls = load_object(path)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.s3.S3DownloadHandler\" for scheme \"s3\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Traceback (most recent call last):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     dhcls = load_object(path)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/s3.py\", line 3, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http import HTTPDownloadHandler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ________________ TestCrawler.test_crawl_start_requests_enabled _________________\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | result = None, gen = <generator object crawl at 0x7fc15f35eba0>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | status = _CancellationStatus(deferred=<Deferred at 0x7fc15f089b38 current result: None>, waitingOn=None)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @_extraneous\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def _inlineCallbacks(\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         result: object,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         gen: Union[\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             Generator[Deferred[_T], object, None],\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             Coroutine[Deferred[_T], object, None],\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         ],\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         status: _CancellationStatus,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ) -> None:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         \"\"\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         Carry out the work of L{inlineCallbacks}.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         Iterate the generator produced by an C{@}L{inlineCallbacks}-decorated\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         function, C{gen}, C{send()}ing it the results of each value C{yield}ed by\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         that generator, until a L{Deferred} is yielded, at which point a callback\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         is added to that L{Deferred} to call this function again.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         @param result: The last result seen by this generator.  Note that this is\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             never a L{Deferred} - by the time this function is invoked, the\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             L{Deferred} has been called back and this will be a particular result\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             at a point in its callback chain.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         @param gen: a generator object returned by calling a function or method\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             decorated with C{@}L{inlineCallbacks}\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         @param status: a L{_CancellationStatus} tracking the current status of C{gen}\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         \"\"\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # This function is complicated by the need to prevent unbounded recursion\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # arising from repeatedly yielding immediately ready deferreds.  This while\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # loop and the waiting variable solve that by manually unfolding the\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # recursion.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # waiting for result?  # result\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         waiting: List[Any] = [True, None]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         # Get the current contextvars Context object.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         current_context = _copy_context()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         while 1:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             try:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 # Send the last result back as the result of the yield expression.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 isFailure = isinstance(result, Failure)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 if isFailure:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                     result = current_context.run(\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                         cast(Failure, result).throwExceptionIntoGenerator, gen\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                     )\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                 else:\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >                   result = current_context.run(gen.send, result)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:1660: \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/twisted/internet/defer.py:62: in run\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return f(*args, **kwargs)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/scrapyrt/core.py:42: in crawl\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     self.engine = self._create_engine()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/crawler.py:101: in _create_engine\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return ExecutionEngine(self, lambda _: self.stop())\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/engine.py:69: in __init__\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     self.downloader = downloader_cls(crawler)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py:83: in __init__\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:53: in from_crawler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return cls.from_settings(crawler.settings, crawler)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/middleware.py:34: in from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mwcls = load_object(clspath)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py:61: in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py:126: in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/downloadermiddlewares/retry.py:27: in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import TunnelError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py:23: in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py:11: in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     import logging\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from OpenSSL import SSL\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from service_identity.exceptions import CertificateError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from twisted.internet._sslverify import ClientTLSOptions, verifyHostname, VerificationError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from twisted.internet.ssl import AcceptableCiphers\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.utils.ssl import x509name_to_string, get_temp_key_info\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     logger = logging.getLogger(__name__)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3 = 'SSLv3'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLS = 'TLS'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLSv10 = 'TLSv1.0'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLSv11 = 'TLSv1.1'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_TLSv12 = 'TLSv1.2'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     openssl_methods = {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLS: SSL.SSLv23_METHOD,                      # protocol negotiation (recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLSv10: SSL.TLSv1_METHOD,                    # TLS 1.0 only\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLSv11: getattr(SSL, 'TLSv1_1_METHOD', 5),   # TLS 1.1 only\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         METHOD_TLSv12: getattr(SSL, 'TLSv1_2_METHOD', 6),   # TLS 1.2 only\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     }\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E   AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py:23: AttributeError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ----------------------------- Captured stdout call -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ------------------------------ Captured log call -------------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"http\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Traceback (most recent call last):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     dhcls = load_object(path)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.http.HTTPDownloadHandler\" for scheme \"https\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Traceback (most recent call last):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     dhcls = load_object(path)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ERROR    scrapy.core.downloader.handlers:__init__.py:63 Loading \"scrapy.core.downloader.handlers.s3.S3DownloadHandler\" for scheme \"s3\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | Traceback (most recent call last):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/__init__.py\", line 49, in _load_handler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     dhcls = load_object(path)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/utils/misc.py\", line 61, in load_object\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     mod = import_module(module)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     return _bootstrap._gcd_import(name[level:], package, level)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/s3.py\", line 3, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http import HTTPDownloadHandler\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http.py\", line 2, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.handlers.http11 import (\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.contextfactory import load_context_factory_from_settings\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/contextfactory.py\", line 11, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from scrapy.core.downloader.tls import DEFAULT_CIPHERS, openssl_methods, ScrapyClientTLSOptions\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   File \"/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/scrapy/core/downloader/tls.py\", line 23, in <module>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     METHOD_SSLv3: SSL.SSLv3_METHOD,                     # SSL 3 (NOT recommended)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | AttributeError: module 'OpenSSL.SSL' has no attribute 'SSLv3_METHOD'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _ TestCrawlResourceIntegration.test_no_url_but_start_requests_present[perform_get] _\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f943f28>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15f4634a8>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | method = <function perform_get at 0x7fc15f91a400>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @pytest.mark.parametrize(\"method\", [\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         perform_get, perform_post\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ])\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_no_url_but_start_requests_present(self, server, method):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = method(server.url(\"crawl.json\"), {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             'spider_name': \"test_with_sr\",\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"start_requests\": True\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }, {})\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res.status_code == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       assert 500 == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E        +  where 500 = <Response [500]>.status_code\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:223: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:08+0000 [-] Log opened.\\n2023-06-28 10:47:08+0000 [-] Site starting on 26613\\n2023-06-28 10:47:08+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f0f7d376cc0>\\n2023-06-28 10:47:08+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _ TestCrawlResourceIntegration.test_no_url_but_start_requests_present[perform_post] _\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f943f98>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15f241d30>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | method = <function perform_post at 0x7fc15f91aa60>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @pytest.mark.parametrize(\"method\", [\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         perform_get, perform_post\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ])\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_no_url_but_start_requests_present(self, server, method):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = method(server.url(\"crawl.json\"), {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             'spider_name': \"test_with_sr\",\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"start_requests\": True\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }, {})\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res.status_code == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       assert 500 == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E        +  where 500 = <Response [500]>.status_code\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:223: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:09+0000 [-] Log opened.\\n2023-06-28 10:47:09+0000 [-] Site starting on 27222\\n2023-06-28 10:47:09+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f38c7b29cc0>\\n2023-06-28 10:47:09+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ___ TestCrawlResourceIntegration.test_no_request_but_start_requests_present ____\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f915080>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15f088b38>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_no_request_but_start_requests_present(self, server):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         \"\"\"Test for POST handler checking if everything works fine\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         if there is no 'request' argument, but 'start_requests' are\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         present. Not checked above because of the way default test fixtures\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         are written.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         \"\"\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         post_data = {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"no_request\": {},\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"start_requests\": True,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"spider_name\": \"test_with_sr\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         post_data.update(post_data)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = requests.post(server.url(\"crawl.json\"),\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                             json=post_data)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res.status_code == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       assert 500 == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E        +  where 500 = <Response [500]>.status_code\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:255: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:11+0000 [-] Log opened.\\n2023-06-28 10:47:11+0000 [-] Site starting on 18283\\n2023-06-28 10:47:11+0000 [-] Starting factory <twisted.web.server.Site object at 0x7fee2e564cc0>\\n2023-06-28 10:47:11+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _ TestCrawlResourceIntegration.test_url_and_start_requests_present[perform_get] _\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f9152e8>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15f24f390>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | method = <function perform_get at 0x7fc15f91a400>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @pytest.mark.parametrize(\"method\", [\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         perform_get, perform_post\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ])\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_url_and_start_requests_present(self, server, method):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         spider_data = {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"url\": server.target_site.url(\"page3.html\")\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         api_params = {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"spider_name\": \"test_with_sr\",\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"start_requests\": True,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = method(server.url(\"crawl.json\"), api_params,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      spider_data)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res.status_code == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       assert 500 == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E        +  where 500 = <Response [500]>.status_code\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:291: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:14+0000 [-] Log opened.\\n2023-06-28 10:47:14+0000 [-] Site starting on 32362\\n2023-06-28 10:47:14+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f3f0693fc88>\\n2023-06-28 10:47:14+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _ TestCrawlResourceIntegration.test_url_and_start_requests_present[perform_post] _\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f915358>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15ef0cd68>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | method = <function perform_post at 0x7fc15f91aa60>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @pytest.mark.parametrize(\"method\", [\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         perform_get, perform_post\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ])\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_url_and_start_requests_present(self, server, method):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         spider_data = {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"url\": server.target_site.url(\"page3.html\")\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         api_params = {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"spider_name\": \"test_with_sr\",\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"start_requests\": True,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = method(server.url(\"crawl.json\"), api_params,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      spider_data)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res.status_code == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       assert 500 == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E        +  where 500 = <Response [500]>.status_code\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:291: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:16+0000 [-] Log opened.\\n2023-06-28 10:47:16+0000 [-] Site starting on 23802\\n2023-06-28 10:47:16+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f412c553c18>\\n2023-06-28 10:47:16+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _____________ TestCrawlResourceIntegration.test_crawl[perform_get] _____________\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f915278>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15f0a50b8>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | method = <function perform_get at 0x7fc15f91a400>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @pytest.mark.parametrize(\"method\", [\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         perform_get, perform_post\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ])\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_crawl(self, server, method):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         url = server.url(\"crawl.json\")\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = method(url,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"spider_name\": \"test\"},\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"url\": server.target_site.url(\"page1.html\")})\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         expected_items = [{\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             u'name': ['Page 1'],\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res_json = res.json()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res_json[\"status\"] == \"ok\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       AssertionError: assert 'error' == 'ok'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E         - ok\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E         + error\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:365: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:28+0000 [-] Log opened.\\n2023-06-28 10:47:28+0000 [-] Site starting on 17847\\n2023-06-28 10:47:28+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f7ba3d04cc0>\\n2023-06-28 10:47:28+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ____________ TestCrawlResourceIntegration.test_crawl[perform_post] _____________\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f915048>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15ef34da0>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | method = <function perform_post at 0x7fc15f91aa60>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @pytest.mark.parametrize(\"method\", [\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         perform_get, perform_post\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ])\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_crawl(self, server, method):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         url = server.url(\"crawl.json\")\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = method(url,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"spider_name\": \"test\"},\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"url\": server.target_site.url(\"page1.html\")})\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         expected_items = [{\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             u'name': ['Page 1'],\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res_json = res.json()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res_json[\"status\"] == \"ok\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       AssertionError: assert 'error' == 'ok'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E         - ok\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E         + error\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:365: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:30+0000 [-] Log opened.\\n2023-06-28 10:47:30+0000 [-] Site starting on 20534\\n2023-06-28 10:47:30+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f58749c4cc0>\\n2023-06-28 10:47:30+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ________ TestCrawlResourceIntegration.test_passing_errback[perform_get] ________\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f9159b0>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15f1ad780>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | method = <function perform_get at 0x7fc15f91a400>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @pytest.mark.parametrize(\"method\", [\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         perform_get, perform_post\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ])\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_passing_errback(self, server, method):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         url = server.url(\"crawl.json\")\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = method(url,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"spider_name\": \"test\"},\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"url\": server.target_site.url(\"err/503\"),\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                       'errback': 'some_errback'})\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res_json = res.json()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res_json.get('stats').get('log_count/ERROR') == 2\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       AttributeError: 'NoneType' object has no attribute 'get'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:395: AttributeError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:34+0000 [-] Log opened.\\n2023-06-28 10:47:34+0000 [-] Site starting on 26398\\n2023-06-28 10:47:34+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f8302e0ac18>\\n2023-06-28 10:47:34+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _______ TestCrawlResourceIntegration.test_passing_errback[perform_post] ________\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f915a20>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15ef293c8>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | method = <function perform_post at 0x7fc15f91aa60>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @pytest.mark.parametrize(\"method\", [\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         perform_get, perform_post\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ])\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_passing_errback(self, server, method):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         url = server.url(\"crawl.json\")\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = method(url,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"spider_name\": \"test\"},\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"url\": server.target_site.url(\"err/503\"),\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                       'errback': 'some_errback'})\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res_json = res.json()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res_json.get('stats').get('log_count/ERROR') == 2\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       AttributeError: 'NoneType' object has no attribute 'get'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:395: AttributeError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:36+0000 [-] Log opened.\\n2023-06-28 10:47:36+0000 [-] Site starting on 18064\\n2023-06-28 10:47:36+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f420a94fcc0>\\n2023-06-28 10:47:36+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _________ TestCrawlResourceIntegration.test_bytes_in_item[perform_get] _________\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f915b70>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15ee04dd8>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | method = <function perform_get at 0x7fc15f91a400>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @pytest.mark.parametrize(\"method\", [\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         perform_get, perform_post\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ])\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_bytes_in_item(self, server, method):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         url = server.url(\"crawl.json\")\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = method(url,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"spider_name\": \"test\"},\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"url\": server.target_site.url(\"page1.html\"),\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                       'callback': 'return_bytes'})\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res.status_code == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       assert 500 == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E        +  where 500 = <Response [500]>.status_code\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:414: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:37+0000 [-] Log opened.\\n2023-06-28 10:47:37+0000 [-] Site starting on 28288\\n2023-06-28 10:47:37+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f840bf0dcc0>\\n2023-06-28 10:47:37+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ________ TestCrawlResourceIntegration.test_bytes_in_item[perform_post] _________\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f915be0>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15f008390>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | method = <function perform_post at 0x7fc15f91aa60>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     @pytest.mark.parametrize(\"method\", [\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         perform_get, perform_post\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     ])\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_bytes_in_item(self, server, method):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         url = server.url(\"crawl.json\")\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = method(url,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"spider_name\": \"test\"},\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                      {\"url\": server.target_site.url(\"page1.html\"),\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |                       'callback': 'return_bytes'})\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res.status_code == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       assert 500 == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E        +  where 500 = <Response [500]>.status_code\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:414: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:39+0000 [-] Log opened.\\n2023-06-28 10:47:39+0000 [-] Site starting on 14861\\n2023-06-28 10:47:39+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f0a2f57ecc0>\\n2023-06-28 10:47:39+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | __________ TestCrawlResourceIntegration.test_crawl_with_argument_get ___________\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f915c88>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15f241d30>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_crawl_with_argument_get(self, server):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         url = server.url(\"crawl.json\")\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         postcode = \"43-300\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         argument = json.dumps({\"postcode\": postcode})\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         argument = quote(argument)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = perform_get(url, {\"spider_name\": \"test\"}, {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"url\": server.target_site.url(\"page1.html\"),\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"crawl_args\": argument,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"callback\": 'return_argument'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         })\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         expected_items = [{\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             u'name': postcode,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res_json = res.json()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res_json[\"status\"] == \"ok\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       AssertionError: assert 'error' == 'ok'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E         - ok\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E         + error\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:431: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:41+0000 [-] Log opened.\\n2023-06-28 10:47:41+0000 [-] Site starting on 13622\\n2023-06-28 10:47:41+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f4ddb019cc0>\\n2023-06-28 10:47:41+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | __________ TestCrawlResourceIntegration.test_crawl_with_argument_post __________\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f915d68>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15f9379e8>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_crawl_with_argument_post(self, server):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         url = server.url(\"crawl.json\")\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         postcode = \"43-300\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         argument = {\"postcode\": postcode}\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = perform_post(url, {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"spider_name\": \"test\",\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"crawl_args\": argument\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }, {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"url\": server.target_site.url(\"page1.html\"),\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"callback\": 'return_argument'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         })\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         expected_items = [{\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             u'name': postcode,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         }]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res_json = res.json()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res.status_code == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       assert 500 == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E        +  where 500 = <Response [500]>.status_code\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:452: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:42+0000 [-] Log opened.\\n2023-06-28 10:47:42+0000 [-] Site starting on 18934\\n2023-06-28 10:47:42+0000 [-] Starting factory <twisted.web.server.Site object at 0x7f9a6331dc88>\\n2023-06-28 10:47:42+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | __ TestCrawlResourceIntegration.test_crawl_with_argument_attribute_collision ___\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | self = <tests.test_resource_crawl.TestCrawlResourceIntegration object at 0x7fc15f69b198>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | server = <tests.servers.ScrapyrtTestServer object at 0x7fc15ef34390>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def test_crawl_with_argument_attribute_collision(self, server):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         \"\"\"If there is attribute collision and some argument to spider\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |          passed via API, and this argument collides with spider attribute,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |          argument from request overrides spider attribute.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         \"\"\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         url = server.url(\"crawl.json\")\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         argument = quote(json.dumps({\"some_attribute\": \"string\"}))\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res = perform_get(url, {\"spider_name\": \"test\"}, {\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"url\": server.target_site.url(\"page1.html\"),\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             \"crawl_args\": argument,\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         })\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         def check_res(res):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             res_json = res.json()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             assert res_json[\"status\"] == \"ok\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             assert res.status_code == 200\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             assert res_json['items']\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |             assert len(res_json['items']) == 1\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       check_res(res)\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:525: \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | res = <Response [500]>\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     def check_res(res):\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |         res_json = res.json()\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | >       assert res_json[\"status\"] == \"ok\"\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E       AssertionError: assert 'error' == 'ok'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E         - ok\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | E         + error\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/tests/test_resource_crawl.py:520: AssertionError\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ---------------------------- Captured stdout setup -----------------------------\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | b'/opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\\n  from cryptography.hazmat.bindings.openssl.binding import Binding\\n2023-06-28 10:47:47+0000 [-] Log opened.\\n2023-06-28 10:47:47+0000 [-] Site starting on 22598\\n2023-06-28 10:47:47+0000 [-] Starting factory <twisted.web.server.Site object at 0x7efc4a1a5c18>\\n2023-06-28 10:47:47+0000 [-] Running with reactor: EPollReactor. \\n'\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | =============================== warnings summary ===============================\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ../../../opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |   /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages/OpenSSL/_util.py:6: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography will remove support for Python 3.6.\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   |     from cryptography.hazmat.bindings.openssl.binding import Binding\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | \n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | - generated xml file: /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/report.xml -\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | =========================== short test summary info ============================\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_crawler.py::TestCrawler::test_crawl_start_requests_default\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_crawler.py::TestCrawler::test_crawl_start_requests_disabled\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_crawler.py::TestCrawler::test_crawl_start_requests_enabled\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_no_url_but_start_requests_present[perform_get]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_no_url_but_start_requests_present[perform_post]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_no_request_but_start_requests_present\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_url_and_start_requests_present[perform_get]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_url_and_start_requests_present[perform_post]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_crawl[perform_get]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_crawl[perform_post]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_passing_errback[perform_get]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_passing_errback[perform_post]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_bytes_in_item[perform_get]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_bytes_in_item[perform_post]\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_crawl_with_argument_get\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_crawl_with_argument_post\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | FAILED tests/test_resource_crawl.py::TestCrawlResourceIntegration::test_crawl_with_argument_attribute_collision\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   | ================== 17 failed, 87 passed, 1 warning in 57.51s ===================\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build]   \u274c  Failure - Main Test with pytest\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build] exitcode '1': failure\n[effc28c8-ac64-4abc-a503-59bd7f3d33fc/build] \ud83c\udfc1  Job failed\n",
        "stderr": "Error: Job 'build' failed\n",
        "workflow": "/tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/scrapinghub-scrapyrt/.github/workflows/main-crawler.yml",
        "build_tool": "pytest",
        "elapsed_time": 189.87637543678284
    }
}