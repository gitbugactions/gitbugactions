{
    "repository": "jamesturk/scrapelib",
    "stars": 193,
    "language": "python",
    "size": 954,
    "clone_url": "https://github.com/jamesturk/scrapelib.git",
    "timestamp": "2023-06-28T09:44:25.776686Z",
    "clone_success": true,
    "number_of_actions": 2,
    "number_of_test_actions": 1,
    "actions_successful": true,
    "actions_build_tools": [
        "unknown",
        "pytest"
    ],
    "actions_test_build_tools": [
        "pytest"
    ],
    "actions_run": {
        "failed": false,
        "tests": [
            {
                "classname": "scrapelib.tests.test_cache",
                "name": "test_default_key_for_request",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_cache",
                "name": "test_default_should_cache_response",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_cache",
                "name": "test_no_cache_request",
                "time": 8.812,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_cache",
                "name": "test_simple_cache_request",
                "time": 30.847,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_cache",
                "name": "test_cache_write_only",
                "time": 31.185,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_cache",
                "name": "test_memory_cache",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_cache",
                "name": "test_file_cache",
                "time": 0.016,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_cache",
                "name": "test_sqlite_cache",
                "time": 0.045,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_fields",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_get",
                "time": 3.69,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_post",
                "time": 1.24,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_all_parameters_to_requests",
                "time": 0.001,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_request_throttling",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_user_agent",
                "time": 7.116,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_user_agent_from_headers",
                "time": 2.532,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_404",
                "time": 3.126,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_500",
                "time": 6.342,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_caching",
                "time": 60.242,
                "results": [
                    {
                        "result": "Failure",
                        "message": "scrapelib.HTTPError: 504 while retrieving http://httpbin.org/status/200",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_urlretrieve",
                "time": 0.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_retry",
                "time": 1.011,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_retry_404",
                "time": 2.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_retry_ssl",
                "time": 0.002,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_timeout",
                "time": 0.022,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_timeout_arg",
                "time": 0.018,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_timeout_retry",
                "time": 0.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_disable_compression",
                "time": 10.239,
                "results": [
                    {
                        "result": "Failure",
                        "message": "scrapelib.HTTPError: 504 while retrieving http://httpbin.org/headers",
                        "type": null
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_callable_headers",
                "time": 4.087,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_headers_weirdness",
                "time": 8.716,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_ftp_uses_urllib2",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_ftp_retries",
                "time": 0.009,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_ftp_method_restrictions",
                "time": 0.003,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_basic_stats",
                "time": 3.005,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            },
            {
                "classname": "scrapelib.tests.test_scraper",
                "name": "test_reset_stats",
                "time": 1.004,
                "results": [
                    {
                        "result": "Passed",
                        "message": "",
                        "type": ""
                    }
                ],
                "stdout": null,
                "stderr": null
            }
        ],
        "stdout": "[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \ud83d\ude80  Start image=crawlergpt:latest\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker pull image=crawlergpt:latest platform= username= forcePull=false\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker create image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker run image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/jamesturk-scrapelib] user=0 workdir=\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2601  git clone 'https://github.com/actions/setup-python' # ref=v2\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2601  git clone 'https://github.com/snok/install-poetry' # ref=v1.2.1\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \u2b50 Run Pre install Poetry\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2705  Success - Pre install Poetry\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \ud83e\uddea  Matrix: map[python-version:3.7]\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \u2b50 Run Main actions/checkout@v2\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2705  Success - Main actions/checkout@v2\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \u2b50 Run Main setup Python 3.7\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker cp src=/tmp/act-cache/c90f71ba-f5e6-4bee-95f9-9dfe1fce9d4a/act/actions-setup-python@v2/ dst=/var/run/act/actions/actions-setup-python@v2/\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /var/run/act/actions/actions-setup-python@v2/] user=0 workdir=\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker exec cmd=[node /var/run/act/actions/actions-setup-python@v2/dist/setup/index.js] user= workdir=\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::Semantic version spec of 3.7 is 3.7\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::isExplicit: \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::explicit? false\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::isExplicit: 2.7.18\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::explicit? true\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::isExplicit: 3.5.10\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::explicit? true\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::isExplicit: 3.6.14\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::explicit? true\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::isExplicit: 3.7.11\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::explicit? true\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::isExplicit: 3.8.11\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::explicit? true\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::isExplicit: 3.9.6\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::explicit? true\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::evaluating 6 versions\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::matched: 3.7.11\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::checking cache: /opt/hostedtoolcache/Python/3.7.11/x64\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udcac  ::debug::Found tool in cache Python 3.7.11 x64\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Successfully setup CPython (3.7.11)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2753 add-matcher /run/act/actions/actions-setup-python@v2/.github/python.json\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2705  Success - Main setup Python 3.7\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2699  ::set-env:: pythonLocation=/opt/hostedtoolcache/Python/3.7.11/x64\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2699  ::set-env:: LD_LIBRARY_PATH=/opt/hostedtoolcache/Python/3.7.11/x64/lib\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2699  ::set-output:: python-version=3.7.11\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.7.11/x64\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.7.11/x64/bin\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \u2b50 Run Main install Poetry\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker cp src=/tmp/act-cache/c90f71ba-f5e6-4bee-95f9-9dfe1fce9d4a/act/snok-install-poetry@v1.2.1/ dst=/var/run/act/actions/snok-install-poetry@v1.2.1/\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /var/run/act/actions/snok-install-poetry@v1.2.1/] user=0 workdir=\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \u2b50 Run Main Install and configure Poetry\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/2-composite-0.sh] user= workdir=\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \u001b[33mSetting Poetry installation path as /home/runneradmin/.local/\u001b[0m\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \u001b[33mInstalling Poetry \ud83d\udc77\u001b[0m\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Retrieving Poetry metadata\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | # Welcome to Poetry!\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | This will download and install the latest version of Poetry,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | a dependency and package manager for Python.\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | It will add the `poetry` command to Poetry's bin directory, located at:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | /home/runneradmin/.local/bin\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | You can uninstall at any time by executing this script with the --uninstall option,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | and these changes will be reverted.\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Installing Poetry (1.5.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Installing Poetry (1.5.1): Creating environment\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Installing Poetry (1.5.1): Installing Poetry\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Installing Poetry (1.5.1): Creating script\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Installing Poetry (1.5.1): Done\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Poetry (1.5.1) is installed now. Great!\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | To get started you need Poetry's bin directory (/home/runneradmin/.local/bin) in your `PATH`\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | environment variable.\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Add `export PATH=\"/home/runneradmin/.local/bin:$PATH\"` to your shell configuration file.\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Alternatively, you can call Poetry explicitly with `/home/runneradmin/.local/bin/poetry`.\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | You can test that everything is set up by executing:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | `poetry --version`\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \u001b[33mInstallation completed. Configuring settings \ud83d\udee0\u001b[0m\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \u001b[33mDone \u2705\u001b[0m\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \u001b[33mIf you are creating a venv in your project, you can activate it by running 'source .venv/bin/activate'. If you're running this in an OS matrix, you can use 'source $VENV' instead, as an OS agnostic option\u001b[0m\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2705  Success - Main Install and configure Poetry\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2699  ::set-env:: VENV=.venv/bin/activate\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2699  ::add-path:: /home/runneradmin/.local//bin\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2705  Success - Main install Poetry\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2699  ::set-env:: VENV=.venv/bin/activate\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2699  ::add-path:: /home/runneradmin/.local//bin\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \u2b50 Run Main set poetry config path\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/3] user= workdir=\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2705  Success - Main set poetry config path\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \u2b50 Run Main install dependencies\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/4] user= workdir=\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Creating virtualenv scrapelib-Fd-P0jKX-py3.7 in /home/runneradmin/.virtualenvs\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Updating dependencies\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Resolving dependencies...\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Package operations: 48 installs, 0 updates, 0 removals\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing six (1.16.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing typing-extensions (4.6.3)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing zipp (3.15.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing importlib-metadata (4.13.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing markupsafe (2.1.3)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing python-dateutil (2.8.2)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing pyyaml (6.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing click (8.1.3)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing ghp-import (2.1.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing jinja2 (3.1.2)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing markdown (3.3.7)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing mergedeep (1.3.4)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing packaging (23.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing pyyaml-env-tag (0.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing watchdog (3.0.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing certifi (2023.5.7)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing charset-normalizer (3.1.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing exceptiongroup (1.1.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing idna (3.4)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing iniconfig (2.0.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing mkdocs (1.4.3)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing pluggy (1.2.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing tomli (2.0.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing urllib3 (1.26.16)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing coverage (6.5.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing docopt (0.6.2)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing mccabe (0.6.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing mkdocs-autorefs (0.4.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing mkdocs-material-extensions (1.1.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing mypy-extensions (1.0.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing pycodestyle (2.7.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing pyflakes (2.3.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing pygments (2.15.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing pymdown-extensions (10.0.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing pytest (7.4.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing requests (2.31.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing toml (0.10.2)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing typed-ast (1.5.4)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing types-urllib3 (1.26.25.13)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing coveralls (3.3.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing flake8 (3.9.2)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing mkdocs-material (8.5.11)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing mkdocstrings (0.19.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing mock (4.0.3)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing mypy (0.961)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing pytest-cov (2.12.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing types-mock (4.0.15.2)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |   \u2022 Installing types-requests (2.31.0.1)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Writing lock file\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Installing the current project: scrapelib (2.2.0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2705  Success - Main install dependencies\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \u2b50 Run Main lint with mypy\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/5] user= workdir=\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | Success: no issues found in 7 source files\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2705  Success - Main lint with mypy\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \u2b50 Run Main lint with flake8\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/6] user= workdir=\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2705  Success - Main lint with flake8\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \u2b50 Run Main pytest\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/7] user= workdir=\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | ============================= test session starts ==============================\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | platform linux -- Python 3.7.11, pytest-7.4.0, pluggy-1.2.0\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | rootdir: /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/jamesturk-scrapelib\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | plugins: cov-2.12.1\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | collected 33 items\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | scrapelib/tests/test_cache.py ........                                   [ 24%]\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | scrapelib/tests/test_scraper.py .........F.......F.......                [100%]\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | =================================== FAILURES ===================================\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | _________________________________ test_caching _________________________________\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     def test_caching() -> None:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         cache_dir = tempfile.mkdtemp()\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         s = Scraper(requests_per_minute=0)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         s.cache_storage = MemoryCache()\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         s.cache_write_only = False\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | >       resp = s.get(HTTPBIN + \"status/200\")\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | scrapelib/tests/test_scraper.py:183: \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | /home/runneradmin/.virtualenvs/scrapelib-Fd-P0jKX-py3.7/lib/python3.7/site-packages/requests/sessions.py:602: in get\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     return self.request(\"GET\", url, **kwargs)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | self = <scrapelib.Scraper object at 0x7f87c5ae8c90>, method = 'GET'\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | url = 'http://httpbin.org/status/200', params = None, data = None\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | headers = None, cookies = None, files = None, auth = None, timeout = None\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | allow_redirects = True, proxies = None, hooks = None, stream = None\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | verify = True, cert = None, json = None, retry_on_404 = False\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | ciphers_list_addition = None\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     def request(  # type: ignore\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         self,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         method: str,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         url: Union[str, bytes, Text],\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         params: Union[None, bytes, MutableMapping[Text, Text]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         data: _Data = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         headers: Optional[MutableMapping[Text, Text]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         cookies: Union[None, RequestsCookieJar, MutableMapping[Text, Text]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         files: Optional[MutableMapping[Text, IO[Any]]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         auth: _AuthType = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         timeout: Union[None, float, Tuple[float, float], Tuple[float, None]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         allow_redirects: Optional[bool] = True,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         proxies: Optional[MutableMapping[Text, Text]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         hooks: Optional[_HooksInput] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         stream: Optional[bool] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         verify: Union[None, bool, Text] = True,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         cert: Union[Text, Tuple[Text, Text], None] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         json: Optional[Any] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         retry_on_404: bool = False,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         ciphers_list_addition: Union[Text, None] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     ) -> CacheResponse:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         _log.info(\"{} - {!r}\".format(method.upper(), url))\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # allow modification of SSL ciphers list to accommodate misconfigured servers\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # for example 'HIGH:!DH:!aNULL' to bypass \"dh key too small\" error\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # https://stackoverflow.com/questions/38015537/python-requests-exceptions-sslerror-dh-key-too-small\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         if ciphers_list_addition:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS += ciphers_list_addition  # type: ignore\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             try:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |                 requests.packages.urllib3.contrib.pyopenssl.DEFAULT_SSL_CIPHER_LIST += ciphers_list_addition  # type: ignore\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             except AttributeError:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |                 # no pyopenssl support used / needed / available\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |                 pass\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # apply global timeout\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         if not timeout:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             timeout = self.timeout\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # ordering matters here:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # func headers are applied on top of class headers\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # param headers are applied on top of those\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         if self._header_func:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             func_headers = requests.structures.CaseInsensitiveDict(\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |                 self._header_func(url)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             )\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         else:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             func_headers = requests.structures.CaseInsensitiveDict()\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         final_headers = requests.sessions.merge_setting(\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             func_headers,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             self.headers,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             dict_class=requests.structures.CaseInsensitiveDict,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         )\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         final_headers = requests.sessions.merge_setting(\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             headers, final_headers, dict_class=requests.structures.CaseInsensitiveDict\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         )\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         _start_time = time.time()\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         resp = super().request(\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             method,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             url,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             timeout=timeout,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             headers=final_headers,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             params=params,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             data=data,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             cookies=cookies,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             files=files,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             auth=auth,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             allow_redirects=allow_redirects,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             proxies=proxies,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             hooks=hooks,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             stream=stream,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             verify=verify,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             cert=cert,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             json=json,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             retry_on_404=retry_on_404,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         )\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         self._total_requests += 1\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         self._total_time += time.time() - _start_time\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         if self.raise_errors and not self.accept_response(resp):\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | >           raise HTTPError(resp)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | E           scrapelib.HTTPError: 504 while retrieving http://httpbin.org/status/200\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | scrapelib/__init__.py:601: HTTPError\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | ___________________________ test_disable_compression ___________________________\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     def test_disable_compression() -> None:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         s = Scraper()\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         s.disable_compression = True\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # compression disabled\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | >       data = s.get(HTTPBIN + \"headers\")\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | scrapelib/tests/test_scraper.py:344: \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | /home/runneradmin/.virtualenvs/scrapelib-Fd-P0jKX-py3.7/lib/python3.7/site-packages/requests/sessions.py:602: in get\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     return self.request(\"GET\", url, **kwargs)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | self = <scrapelib.Scraper object at 0x7f87c5ac1790>, method = 'GET'\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | url = 'http://httpbin.org/headers', params = None, data = None, headers = None\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | cookies = None, files = None, auth = None, timeout = None\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | allow_redirects = True, proxies = None, hooks = None, stream = None\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | verify = True, cert = None, json = None, retry_on_404 = False\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | ciphers_list_addition = None\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     def request(  # type: ignore\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         self,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         method: str,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         url: Union[str, bytes, Text],\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         params: Union[None, bytes, MutableMapping[Text, Text]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         data: _Data = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         headers: Optional[MutableMapping[Text, Text]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         cookies: Union[None, RequestsCookieJar, MutableMapping[Text, Text]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         files: Optional[MutableMapping[Text, IO[Any]]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         auth: _AuthType = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         timeout: Union[None, float, Tuple[float, float], Tuple[float, None]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         allow_redirects: Optional[bool] = True,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         proxies: Optional[MutableMapping[Text, Text]] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         hooks: Optional[_HooksInput] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         stream: Optional[bool] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         verify: Union[None, bool, Text] = True,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         cert: Union[Text, Tuple[Text, Text], None] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         json: Optional[Any] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         retry_on_404: bool = False,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         ciphers_list_addition: Union[Text, None] = None,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     ) -> CacheResponse:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         _log.info(\"{} - {!r}\".format(method.upper(), url))\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # allow modification of SSL ciphers list to accommodate misconfigured servers\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # for example 'HIGH:!DH:!aNULL' to bypass \"dh key too small\" error\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # https://stackoverflow.com/questions/38015537/python-requests-exceptions-sslerror-dh-key-too-small\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         if ciphers_list_addition:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS += ciphers_list_addition  # type: ignore\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             try:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |                 requests.packages.urllib3.contrib.pyopenssl.DEFAULT_SSL_CIPHER_LIST += ciphers_list_addition  # type: ignore\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             except AttributeError:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |                 # no pyopenssl support used / needed / available\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |                 pass\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # apply global timeout\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         if not timeout:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             timeout = self.timeout\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # ordering matters here:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # func headers are applied on top of class headers\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         # param headers are applied on top of those\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         if self._header_func:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             func_headers = requests.structures.CaseInsensitiveDict(\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |                 self._header_func(url)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             )\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         else:\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             func_headers = requests.structures.CaseInsensitiveDict()\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         final_headers = requests.sessions.merge_setting(\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             func_headers,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             self.headers,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             dict_class=requests.structures.CaseInsensitiveDict,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         )\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         final_headers = requests.sessions.merge_setting(\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             headers, final_headers, dict_class=requests.structures.CaseInsensitiveDict\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         )\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         _start_time = time.time()\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         resp = super().request(\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             method,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             url,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             timeout=timeout,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             headers=final_headers,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             params=params,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             data=data,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             cookies=cookies,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             files=files,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             auth=auth,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             allow_redirects=allow_redirects,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             proxies=proxies,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             hooks=hooks,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             stream=stream,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             verify=verify,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             cert=cert,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             json=json,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |             retry_on_404=retry_on_404,\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         )\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         self._total_requests += 1\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         self._total_time += time.time() - _start_time\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |     \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   |         if self.raise_errors and not self.accept_response(resp):\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | >           raise HTTPError(resp)\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | E           scrapelib.HTTPError: 504 while retrieving http://httpbin.org/headers\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | \n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | scrapelib/__init__.py:601: HTTPError\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | - generated xml file: /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/jamesturk-scrapelib/report.xml -\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | =========================== short test summary info ============================\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | FAILED scrapelib/tests/test_scraper.py::test_caching - scrapelib.HTTPError: 504 while retrieving http://httpbin.org/status/200\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | FAILED scrapelib/tests/test_scraper.py::test_disable_compression - scrapelib.HTTPError: 504 while retrieving http://httpbin.org/headers\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   | =================== 2 failed, 31 passed in 186.01s (0:03:06) ===================\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u274c  Failure - Main pytest\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] exitcode '1': failure\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \u2b50 Run Post install Poetry\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker cp src=/tmp/act-cache/c90f71ba-f5e6-4bee-95f9-9dfe1fce9d4a/act/snok-install-poetry@v1.2.1/ dst=/var/run/act/actions/snok-install-poetry@v1.2.1/\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /var/run/act/actions/snok-install-poetry@v1.2.1/] user=0 workdir=\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build]   \u2705  Success - Post install Poetry\n[0c5d22a3-d086-48e8-a73e-7c0450cfab78/build] \ud83c\udfc1  Job failed\n",
        "stderr": "Error: Job 'build' failed\n",
        "workflow": "/tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/jamesturk-scrapelib/.github/workflows/test-crawler.yml",
        "build_tool": "pytest",
        "elapsed_time": 309.018390417099
    }
}