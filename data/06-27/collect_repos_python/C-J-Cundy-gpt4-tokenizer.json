{
    "repository": "C-J-Cundy/gpt4-tokenizer",
    "stars": 60,
    "language": "python",
    "size": 1393,
    "clone_url": "https://github.com/C-J-Cundy/gpt4-tokenizer.git",
    "timestamp": "2023-07-01T18:23:30.130201Z",
    "clone_success": true,
    "number_of_actions": 0,
    "number_of_test_actions": 0,
    "actions_successful": false,
    "actions_build_tools": [],
    "actions_test_build_tools": []
}