{
    "repository": "databricks/koalas",
    "stars": 3278,
    "language": "python",
    "size": 12291,
    "clone_url": "https://github.com/databricks/koalas.git",
    "timestamp": "2023-06-28T13:31:08.042923Z",
    "clone_success": true,
    "number_of_actions": 1,
    "number_of_test_actions": 1,
    "actions_successful": false,
    "actions_build_tools": [
        "pytest"
    ],
    "actions_test_build_tools": [
        "pytest"
    ],
    "actions_run": {
        "failed": true,
        "tests": [],
        "stdout": "[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ] \ud83d\ude80  Start image=crawlergpt:latest\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)] \ud83d\ude80  Start image=crawlergpt:latest\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker pull image=crawlergpt:latest platform= username= forcePull=false\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udc33  docker pull image=crawlergpt:latest platform= username= forcePull=false\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker create image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udc33  docker create image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udc33  docker run image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker run image=crawlergpt:latest platform= entrypoint=[\"tail\" \"-f\" \"/dev/null\"] cmd=[]\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/databricks-koalas] user=0 workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/databricks-koalas] user=0 workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2601  git clone 'https://github.com/actions/setup-java' # ref=v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2601  git clone 'https://github.com/actions/setup-java' # ref=v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2601  git clone 'https://github.com/codecov/codecov-action' # ref=v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2601  git clone 'https://github.com/actions/cache' # ref=v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)] \ud83e\uddea  Matrix: map[logger:databricks.koalas.usage_logging.usage_logger numpy-version:1.19.5 pandas-version:0.24.2 pyarrow-version:0.14.1 python-version:3.6 spark-version:2.4.7]\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)] \u2b50 Run Main actions/checkout@v2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2705  Success - Main actions/checkout@v2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)] \u2b50 Run Main actions/setup-java@v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udc33  docker cp src=/tmp/act-cache/57b03219-d376-4c76-9711-c67898d6041b/act/actions-setup-java@v1/ dst=/var/run/act/actions/actions-setup-java@v1/\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /var/run/act/actions/actions-setup-java@v1/] user=0 workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udc33  docker exec cmd=[node /var/run/act/actions/actions-setup-java@v1/dist/setup/index.js] user= workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::isExplicit: \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::explicit? false\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::evaluating 0 versions\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::match not found\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::Downloading JDK from Azul\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::Searching for files with extension: -linux_x64.tar.gz\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::Downloading https://static.azul.com/zulu/bin/zulu8.70.0.23-ca-jdk8.0.372-linux_x64.tar.gz\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::Downloading /tmp/9832a9ab-dc9c-496f-ab1c-255d77af283a\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::download complete\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | [command]/usr/bin/tar --version\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | tar (GNU tar) 1.30\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | Copyright (C) 2017 Free Software Foundation, Inc.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | License GPLv3+: GNU GPL version 3 or later <https://gnu.org/licenses/gpl.html>.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | This is free software: you are free to change and redistribute it.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | There is NO WARRANTY, to the extent permitted by law.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | Written by John Gilmore and Jay Fenlason.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | [command]/usr/bin/tar xz --warning=no-unknown-keyword -C /tmp/temp_163447708 -f /tmp/9832a9ab-dc9c-496f-ab1c-255d77af283a\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::jdk extracted to /tmp/temp_163447708/zulu8.70.0.23-ca-jdk8.0.372-linux_x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::Caching tool jdk 8.0.372 x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::source dir: /tmp/temp_163447708/zulu8.70.0.23-ca-jdk8.0.372-linux_x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::destination /opt/hostedtoolcache/jdk/8.0.372/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::finished caching tool\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2753 add-matcher /run/act/actions/actions-setup-java@v1/.github/java.json\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | creating settings.xml with server-id: github; environment variables: username=$GITHUB_ACTOR, password=$GITHUB_TOKEN, and gpg-passphrase=null\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udcac  ::debug::created directory /home/runneradmin/.m2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | writing /home/runneradmin/.m2/settings.xml\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2705  Success - Main actions/setup-java@v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2699  ::set-env:: JAVA_HOME_8.0.372_x64=/opt/hostedtoolcache/jdk/8.0.372/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2699  ::set-env:: JAVA_HOME=/opt/hostedtoolcache/jdk/8.0.372/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2699  ::set-env:: JAVA_HOME_8_0_372_X64=/opt/hostedtoolcache/jdk/8.0.372/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2699  ::set-output:: path=/opt/hostedtoolcache/jdk/8.0.372/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2699  ::set-output:: version=8.0.372\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2699  ::add-path:: /opt/hostedtoolcache/jdk/8.0.372/x64/bin\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)] \u2b50 Run Main Install dependencies\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/2] user= workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2601  git clone 'https://github.com/actions/setup-python' # ref=v2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | Collecting package metadata (current_repodata.json): ...working... done\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | Solving environment: ...working... done\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | ## Package Plan ##\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   environment location: /usr/share/miniconda\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   added / updated specs:\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     - conda\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | The following packages will be downloaded:\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     package                    |            build\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     ---------------------------|-----------------\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     _openmp_mutex-5.1          |            1_gnu          21 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     ca-certificates-2023.05.30 |       h06a4308_0         120 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     certifi-2023.5.7           |   py39h06a4308_0         152 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     cffi-1.15.1                |   py39h5eee18b_3         242 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     charset-normalizer-2.0.4   |     pyhd3eb1b0_0          35 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     conda-package-handling-2.1.0|   py39h06a4308_0         268 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     conda-package-streaming-0.8.0|   py39h06a4308_0          27 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     cryptography-39.0.1        |   py39h9ce1e76_2         1.4 MB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     idna-3.4                   |   py39h06a4308_0          93 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     ld_impl_linux-64-2.38      |       h1181459_1         654 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     libffi-3.4.4               |       h6a678d5_0         142 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     libgcc-ng-11.2.0           |       h1234567_1         5.3 MB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     libgomp-11.2.0             |       h1234567_1         474 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     libstdcxx-ng-11.2.0        |       h1234567_1         4.7 MB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     ncurses-6.4                |       h6a678d5_0         914 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     openssl-3.0.9              |       h7f8727e_0         5.2 MB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     pip-23.1.2                 |   py39h06a4308_0         2.5 MB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     pycosat-0.6.4              |   py39h5eee18b_0          84 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     pycparser-2.21             |     pyhd3eb1b0_0          94 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     pyopenssl-23.0.0           |   py39h06a4308_0          96 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     python-3.9.16              |       h955ad1f_3        25.1 MB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     readline-8.2               |       h5eee18b_0         357 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     requests-2.29.0            |   py39h06a4308_0          96 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     setuptools-67.8.0          |   py39h06a4308_0         1.0 MB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     sqlite-3.41.2              |       h5eee18b_0         1.2 MB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     tk-8.6.12                  |       h1ccaba5_0         3.0 MB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     tzdata-2023c               |       h04d1e81_0         116 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     urllib3-1.26.16            |   py39h06a4308_0         201 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     wheel-0.38.4               |   py39h06a4308_0          64 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     xz-5.4.2                   |       h5eee18b_0         642 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     zlib-1.2.13                |       h5eee18b_0         103 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     zstandard-0.19.0           |   py39h5eee18b_0         474 KB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |     ------------------------------------------------------------\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |                                            Total:        54.8 MB\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | The following NEW packages will be INSTALLED:\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   conda-package-str~ pkgs/main/linux-64::conda-package-streaming-0.8.0-py39h06a4308_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   zstandard          pkgs/main/linux-64::zstandard-0.19.0-py39h5eee18b_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | The following packages will be REMOVED:\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   chardet-4.0.0-py39h06a4308_1003\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   six-1.16.0-pyhd3eb1b0_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   tqdm-4.61.2-pyhd3eb1b0_1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | The following packages will be UPDATED:\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   _openmp_mutex                                   4.5-1_gnu --> 5.1-1_gnu\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   ca-certificates                       2021.7.5-h06a4308_1 --> 2023.05.30-h06a4308_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   certifi                          2021.5.30-py39h06a4308_0 --> 2023.5.7-py39h06a4308_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   cffi                                1.14.6-py39h400218f_0 --> 1.15.1-py39h5eee18b_3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   conda-package-han~                   1.7.3-py39h27cfd23_1 --> 2.1.0-py39h06a4308_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   cryptography                         3.4.7-py39hd23ed53_0 --> 39.0.1-py39h9ce1e76_2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   idna               pkgs/main/noarch::idna-2.10-pyhd3eb1b~ --> pkgs/main/linux-64::idna-3.4-py39h06a4308_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   ld_impl_linux-64                        2.35.1-h7274673_9 --> 2.38-h1181459_1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   libffi                                     3.3-he6710b0_2 --> 3.4.4-h6a678d5_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   libgcc-ng                               9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   libgomp                                 9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   libstdcxx-ng                            9.3.0-hd4cf53a_17 --> 11.2.0-h1234567_1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   ncurses                                    6.2-he6710b0_1 --> 6.4-h6a678d5_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   openssl                                 1.1.1k-h27cfd23_0 --> 3.0.9-h7f8727e_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   pip                                 21.1.3-py39h06a4308_0 --> 23.1.2-py39h06a4308_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   pycosat                              0.6.3-py39h27cfd23_0 --> 0.6.4-py39h5eee18b_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   pycparser                                       2.20-py_2 --> 2.21-pyhd3eb1b0_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   pyopenssl          pkgs/main/noarch::pyopenssl-20.0.1-py~ --> pkgs/main/linux-64::pyopenssl-23.0.0-py39h06a4308_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   python                                   3.9.5-h12debd9_4 --> 3.9.16-h955ad1f_3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   readline                                   8.1-h27cfd23_0 --> 8.2-h5eee18b_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   requests           pkgs/main/noarch::requests-2.25.1-pyh~ --> pkgs/main/linux-64::requests-2.29.0-py39h06a4308_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   setuptools                          52.0.0-py39h06a4308_0 --> 67.8.0-py39h06a4308_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   sqlite                                  3.36.0-hc218d9a_0 --> 3.41.2-h5eee18b_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   tk                                      8.6.10-hbc83047_0 --> 8.6.12-h1ccaba5_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   tzdata                                   2021a-h52ac0ba_0 --> 2023c-h04d1e81_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   urllib3            pkgs/main/noarch::urllib3-1.26.6-pyhd~ --> pkgs/main/linux-64::urllib3-1.26.16-py39h06a4308_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   wheel              pkgs/main/noarch::wheel-0.36.2-pyhd3e~ --> pkgs/main/linux-64::wheel-0.38.4-py39h06a4308_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   xz                                       5.2.5-h7b6447c_0 --> 5.4.2-h5eee18b_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   zlib                                    1.2.11-h7b6447c_3 --> 1.2.13-h5eee18b_0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | Proceed ([y]/n)? \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | Preparing transaction: ...working... done\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | Verifying transaction: ...working... failed\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | EnvironmentNotWritableError: The current user does not have write permissions to the target environment.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   environment location: /usr/share/miniconda\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   uid: 1012\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   |   gid: 1013\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u274c  Failure - Main Install dependencies\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)] exitcode '1': failure\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)] \u2b50 Run Post actions/setup-java@v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \ud83d\udc33  docker exec cmd=[node /var/run/act/actions/actions-setup-java@v1/dist/cleanup/index.js] user= workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)]   \u2705  Success - Post actions/setup-java@v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/Conda (Python, Spark, pandas, PyArrow)] \ud83c\udfc1  Job failed\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2601  git clone 'https://github.com/codecov/codecov-action' # ref=v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ] \ud83e\uddea  Matrix: map[numpy-version:1.18.5 pandas-version:0.23.4 pyarrow-version:0.16.0 python-version:3.5 spark-version:2.3.4]\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ] \u2b50 Run Main actions/checkout@v2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2705  Success - Main actions/checkout@v2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ] \u2b50 Run Main actions/setup-java@v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker cp src=/tmp/act-cache/57b03219-d376-4c76-9711-c67898d6041b/act/actions-setup-java@v1/ dst=/var/run/act/actions/actions-setup-java@v1/\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /var/run/act/actions/actions-setup-java@v1/] user=0 workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker exec cmd=[node /var/run/act/actions/actions-setup-java@v1/dist/setup/index.js] user= workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::isExplicit: \n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::explicit? false\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::evaluating 0 versions\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::match not found\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::Downloading JDK from Azul\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::Searching for files with extension: -linux_x64.tar.gz\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::Downloading https://static.azul.com/zulu/bin/zulu8.70.0.23-ca-jdk8.0.372-linux_x64.tar.gz\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::Downloading /tmp/6f60e8a4-46ed-47bc-ae4b-934bfa27ded4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::download complete\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | [command]/usr/bin/tar --version\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | tar (GNU tar) 1.30\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Copyright (C) 2017 Free Software Foundation, Inc.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | License GPLv3+: GNU GPL version 3 or later <https://gnu.org/licenses/gpl.html>.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | This is free software: you are free to change and redistribute it.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | There is NO WARRANTY, to the extent permitted by law.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Written by John Gilmore and Jay Fenlason.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | [command]/usr/bin/tar xz --warning=no-unknown-keyword -C /tmp/temp_860809344 -f /tmp/6f60e8a4-46ed-47bc-ae4b-934bfa27ded4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::jdk extracted to /tmp/temp_860809344/zulu8.70.0.23-ca-jdk8.0.372-linux_x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::Caching tool jdk 8.0.372 x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::source dir: /tmp/temp_860809344/zulu8.70.0.23-ca-jdk8.0.372-linux_x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::destination /opt/hostedtoolcache/jdk/8.0.372/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::finished caching tool\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2753 add-matcher /run/act/actions/actions-setup-java@v1/.github/java.json\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating settings.xml with server-id: github; environment variables: username=$GITHUB_ACTOR, password=$GITHUB_TOKEN, and gpg-passphrase=null\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::created directory /home/runneradmin/.m2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | writing /home/runneradmin/.m2/settings.xml\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2705  Success - Main actions/setup-java@v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2699  ::set-env:: JAVA_HOME_8.0.372_x64=/opt/hostedtoolcache/jdk/8.0.372/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2699  ::set-env:: JAVA_HOME=/opt/hostedtoolcache/jdk/8.0.372/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2699  ::set-env:: JAVA_HOME_8_0_372_X64=/opt/hostedtoolcache/jdk/8.0.372/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2699  ::set-output:: path=/opt/hostedtoolcache/jdk/8.0.372/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2699  ::set-output:: version=8.0.372\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2699  ::add-path:: /opt/hostedtoolcache/jdk/8.0.372/x64/bin\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ] \u2b50 Run Main actions/cache@v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker cp src=/tmp/act-cache/57b03219-d376-4c76-9711-c67898d6041b/act/actions-cache@v1/ dst=/var/run/act/actions/actions-cache@v1/\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /var/run/act/actions/actions-cache@v1/] user=0 workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker exec cmd=[node /var/run/act/actions/actions-cache@v1/dist/restore/index.js] user= workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::Cache Path: /home/runneradmin/.cache/pip\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::Resolved Keys:\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::[\"Linux-pip-6c18c3934d08f0a194395e0a377a1144d309b71eb061369a08b4eeb8a164bae0\",\"Linux-pip-\"]\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::Resource Url: http://130.242.72.40:34111/_apis/artifactcache/cache?keys=Linux-pip-6c18c3934d08f0a194395e0a377a1144d309b71eb061369a08b4eeb8a164bae0%252CLinux-pip-\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Cache not found for input keys: Linux-pip-6c18c3934d08f0a194395e0a377a1144d309b71eb061369a08b4eeb8a164bae0, Linux-pip-.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2705  Success - Main actions/cache@v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ] \u2b50 Run Main actions/setup-python@v2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker cp src=/tmp/act-cache/57b03219-d376-4c76-9711-c67898d6041b/act/actions-setup-python@v2/ dst=/var/run/act/actions/actions-setup-python@v2/\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker exec cmd=[chown -R 1012:1013 /var/run/act/actions/actions-setup-python@v2/] user=0 workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker exec cmd=[node /var/run/act/actions/actions-setup-python@v2/dist/setup/index.js] user= workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::Semantic version spec of 3.5 is 3.5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::isExplicit: \n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::explicit? false\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::isExplicit: 2.7.18\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::explicit? true\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::isExplicit: 3.5.10\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::explicit? true\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::isExplicit: 3.6.14\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::explicit? true\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::isExplicit: 3.7.11\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::explicit? true\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::isExplicit: 3.8.11\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::explicit? true\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::isExplicit: 3.9.6\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::explicit? true\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::evaluating 6 versions\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::matched: 3.5.10\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::checking cache: /opt/hostedtoolcache/Python/3.5.10/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udcac  ::debug::Found tool in cache Python 3.5.10 x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Successfully setup CPython (3.5.10)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2753 add-matcher /run/act/actions/actions-setup-python@v2/.github/python.json\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2705  Success - Main actions/setup-python@v2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2699  ::set-env:: pythonLocation=/opt/hostedtoolcache/Python/3.5.10/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2699  ::set-env:: LD_LIBRARY_PATH=/opt/hostedtoolcache/Python/3.5.10/x64/lib\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2699  ::set-output:: python-version=3.5.10\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.5.10/x64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2699  ::add-path:: /opt/hostedtoolcache/Python/3.5.10/x64/bin\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ] \u2b50 Run Main Install dependencies\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/4] user= workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Reading package lists...\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Building dependency tree...\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Reading state information...\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | The following NEW packages will be installed:\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   xclip\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Need to get 18.4 kB of archives.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | After this operation, 60.4 kB of additional disk space will be used.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 xclip amd64 0.13-1 [18.4 kB]\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Fetched 18.4 kB in 0s (125 kB/s)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Selecting previously unselected package xclip.\r\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | (Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 193678 files and directories currently installed.)\r\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Preparing to unpack .../xclip_0.13-1_amd64.deb ...\r\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Unpacking xclip (0.13-1) ...\r\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Setting up xclip (0.13-1) ...\r\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | DEPRECATION: Python 3.5 reached the end of its life on September 13th, 2020. Please upgrade your Python as Python 3.5 is no longer maintained. pip 21.0 will drop support for Python 3.5 in January 2021. pip 21.0 will remove support for this functionality.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting wheel\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (28.8.0)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Installing collected packages: wheel\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Successfully installed wheel-0.37.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | running bdist_wheel\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | running build\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | running build_py\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/lib\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/lib/databricks\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/conftest.py -> build/lib/databricks\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/__init__.py -> build/lib/databricks\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/groupby.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/strings.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/sql.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/version.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/utils.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/series.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/mlflow.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/frame.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/exceptions.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/generic.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/datetimes.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/__init__.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/ml.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/config.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/accessors.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/indexing.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/base.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/namespace.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/numpy_compat.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/internal.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/categorical.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/window.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/extensions.py -> build/lib/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/lib/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/indexes/numeric.py -> build/lib/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/indexes/datetimes.py -> build/lib/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/indexes/__init__.py -> build/lib/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/indexes/multi.py -> build/lib/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/indexes/category.py -> build/lib/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/indexes/base.py -> build/lib/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/lib/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/missing/groupby.py -> build/lib/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/missing/series.py -> build/lib/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/missing/frame.py -> build/lib/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/missing/common.py -> build/lib/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/missing/__init__.py -> build/lib/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/missing/indexes.py -> build/lib/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/missing/window.py -> build/lib/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/lib/databricks/koalas/plot\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/plot/matplotlib.py -> build/lib/databricks/koalas/plot\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/plot/plotly.py -> build/lib/databricks/koalas/plot\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/plot/core.py -> build/lib/databricks/koalas/plot\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/plot/__init__.py -> build/lib/databricks/koalas/plot\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/lib/databricks/koalas/spark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/spark/functions.py -> build/lib/databricks/koalas/spark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/spark/utils.py -> build/lib/databricks/koalas/spark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/spark/__init__.py -> build/lib/databricks/koalas/spark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/spark/accessors.py -> build/lib/databricks/koalas/spark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/lib/databricks/koalas/typedef\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/typedef/string_typehints.py -> build/lib/databricks/koalas/typedef\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/typedef/__init__.py -> build/lib/databricks/koalas/typedef\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/typedef/typehints.py -> build/lib/databricks/koalas/typedef\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/lib/databricks/koalas/usage_logging\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/usage_logging/usage_logger.py -> build/lib/databricks/koalas/usage_logging\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying databricks/koalas/usage_logging/__init__.py -> build/lib/databricks/koalas/usage_logging\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | installing to build/bdist.linux-x86_64/wheel\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | running install\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | running install_lib\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/bdist.linux-x86_64\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/bdist.linux-x86_64/wheel\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/bdist.linux-x86_64/wheel/databricks\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/conftest.py -> build/bdist.linux-x86_64/wheel/databricks\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/groupby.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/strings.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/sql.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/version.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/bdist.linux-x86_64/wheel/databricks/koalas/usage_logging\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/usage_logging/usage_logger.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/usage_logging\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/usage_logging/__init__.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/usage_logging\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/utils.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/series.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/mlflow.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/frame.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/bdist.linux-x86_64/wheel/databricks/koalas/plot\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/plot/matplotlib.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/plot\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/plot/plotly.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/plot\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/plot/core.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/plot\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/plot/__init__.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/plot\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/bdist.linux-x86_64/wheel/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/indexes/numeric.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/indexes/datetimes.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/indexes/__init__.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/indexes/multi.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/indexes/category.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/indexes/base.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/indexes\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/exceptions.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/generic.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/bdist.linux-x86_64/wheel/databricks/koalas/spark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/spark/functions.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/spark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/spark/utils.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/spark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/spark/__init__.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/spark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/spark/accessors.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/spark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/datetimes.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/__init__.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/bdist.linux-x86_64/wheel/databricks/koalas/typedef\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/typedef/string_typehints.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/typedef\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/typedef/__init__.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/typedef\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/typedef/typehints.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/typedef\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/bdist.linux-x86_64/wheel/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/missing/groupby.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/missing/series.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/missing/frame.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/missing/common.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/missing/__init__.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/missing/indexes.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/missing/window.py -> build/bdist.linux-x86_64/wheel/databricks/koalas/missing\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/ml.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/config.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/accessors.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/indexing.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/base.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/namespace.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/numpy_compat.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/internal.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/categorical.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/window.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/koalas/extensions.py -> build/bdist.linux-x86_64/wheel/databricks/koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | copying build/lib/databricks/__init__.py -> build/bdist.linux-x86_64/wheel/databricks\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | running install_egg_info\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | running egg_info\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating koalas.egg-info\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | writing requirements to koalas.egg-info/requires.txt\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | writing dependency_links to koalas.egg-info/dependency_links.txt\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | writing koalas.egg-info/PKG-INFO\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | writing top-level names to koalas.egg-info/top_level.txt\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | writing manifest file 'koalas.egg-info/SOURCES.txt'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | reading manifest file 'koalas.egg-info/SOURCES.txt'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | reading manifest template 'MANIFEST.in'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'project_urls'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   warnings.warn(msg)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'long_description_content_type'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   warnings.warn(msg)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | warning: no previously-included files matching '*.py[cod]' found anywhere in distribution\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | warning: no previously-included files matching '__pycache__' found anywhere in distribution\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | writing manifest file 'koalas.egg-info/SOURCES.txt'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Copying koalas.egg-info to build/bdist.linux-x86_64/wheel/koalas-1.8.2-py3.5.egg-info\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | running install_scripts\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating build/bdist.linux-x86_64/wheel/koalas-1.8.2.dist-info/WHEEL\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | creating 'dist/koalas-1.8.2-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/__init__.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/conftest.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/__init__.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/accessors.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/base.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/categorical.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/config.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/datetimes.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/exceptions.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/extensions.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/frame.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/generic.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/groupby.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/indexing.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/internal.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/ml.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/mlflow.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/namespace.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/numpy_compat.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/series.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/sql.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/strings.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/utils.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/version.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/window.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/indexes/__init__.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/indexes/base.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/indexes/category.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/indexes/datetimes.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/indexes/multi.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/indexes/numeric.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/missing/__init__.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/missing/common.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/missing/frame.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/missing/groupby.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/missing/indexes.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/missing/series.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/missing/window.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/plot/__init__.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/plot/core.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/plot/matplotlib.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/plot/plotly.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/spark/__init__.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/spark/accessors.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/spark/functions.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/spark/utils.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/typedef/__init__.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/typedef/string_typehints.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/typedef/typehints.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/usage_logging/__init__.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'databricks/koalas/usage_logging/usage_logger.py'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'koalas-1.8.2.dist-info/LICENSE'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'koalas-1.8.2.dist-info/METADATA'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'koalas-1.8.2.dist-info/WHEEL'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'koalas-1.8.2.dist-info/top_level.txt'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | adding 'koalas-1.8.2.dist-info/RECORD'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | removing build/bdist.linux-x86_64/wheel\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | DEPRECATION: Python 3.5 reached the end of its life on September 13th, 2020. Please upgrade your Python as Python 3.5 is no longer maintained. pip 21.0 will drop support for Python 3.5 in January 2021. pip 21.0 will remove support for this functionality.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pandas>=0.23.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pandas-0.25.3-cp35-cp35m-manylinux1_x86_64.whl (10.3 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pyarrow>=0.10\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pyarrow-2.0.0-cp35-cp35m-manylinux2014_x86_64.whl (17.6 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting numpy<1.20.0,>=1.14\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting mlflow>=1.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading mlflow-1.14.1-py3-none-any.whl (14.2 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting plotly>=4.8\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting matplotlib<3.3.0,>=3.0.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading matplotlib-3.0.3-cp35-cp35m-manylinux1_x86_64.whl (13.0 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting sphinx<3.1.0,>=2.0.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading Sphinx-3.0.4-py3-none-any.whl (2.8 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting nbsphinx\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading nbsphinx-0.7.1-py3-none-any.whl (24 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting nbconvert!=6.0.*\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading nbconvert-5.6.1-py2.py3-none-any.whl (455 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting nbformat<5.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading nbformat-5.0.8-py3-none-any.whl (172 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting numpydoc>=1.1.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading numpydoc-1.1.0-py3-none-any.whl (47 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pypandoc\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pypandoc-1.7.5.tar.gz (23.2 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Installing build dependencies: started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Installing build dependencies: finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Getting requirements to build wheel: started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Getting requirements to build wheel: finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Preparing wheel metadata: started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Preparing wheel metadata: finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting ipython\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading ipython-7.9.0-py3-none-any.whl (775 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pydata-sphinx-theme\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pydata_sphinx_theme-0.7.2-py3-none-any.whl (1.4 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting docutils==0.16\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting mypy\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading mypy-0.910-cp35-cp35m-manylinux2010_x86_64.whl (21.2 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting flake8\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading flake8-3.9.2-py2.py3-none-any.whl (73 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pytest\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pytest-6.1.2-py3-none-any.whl (272 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pytest-cov\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pytest_cov-2.12.1-py2.py3-none-any.whl (20 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting scikit-learn\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading scikit_learn-0.22.2.post1-cp35-cp35m-manylinux1_x86_64.whl (7.0 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting openpyxl\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading openpyxl-2.6.4.tar.gz (173 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting xlrd<2.0.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting kiwisolver>=1.0.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading kiwisolver-1.1.0-cp35-cp35m-manylinux1_x86_64.whl (90 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting python-dateutil>=2.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting cycler>=0.10\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting sqlparse>=0.3.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting requests>=2.17.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting click>=7.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting gunicorn\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting prometheus-flask-exporter\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading prometheus_flask_exporter-0.22.4-py3-none-any.whl (18 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pytz\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting docker>=4.0.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting querystring-parser\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting sqlalchemy\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading SQLAlchemy-1.3.24-cp35-cp35m-manylinux2010_x86_64.whl (1.3 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting gitpython>=2.1.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading GitPython-3.1.14-py3-none-any.whl (159 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting entrypoints\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting protobuf>=3.6.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting databricks-cli>=0.8.7\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading databricks-cli-0.17.7.tar.gz (83 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pyyaml\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading PyYAML-5.3.1.tar.gz (269 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting Flask\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading Flask-1.1.4-py2.py3-none-any.whl (94 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting cloudpickle\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting alembic<=1.4.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading alembic-1.4.1.tar.gz (1.1 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting bleach\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading bleach-3.3.1-py2.py3-none-any.whl (146 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting defusedxml\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pandocfilters>=1.4.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pygments\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting jupyter-core\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading jupyter_core-4.6.3-py2.py3-none-any.whl (83 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting jinja2>=2.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting mistune<2,>=0.8.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting traitlets>=4.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting testpath\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading testpath-0.6.0-py3-none-any.whl (83 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting ipython-genutils\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting jsonschema!=2.5.0,>=2.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting six\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting retrying>=1.3.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting sphinxcontrib-devhelp\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting sphinxcontrib-qthelp\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting sphinxcontrib-htmlhelp\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl (96 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting babel>=1.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading Babel-2.9.1-py2.py3-none-any.whl (8.8 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting imagesize\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting sphinxcontrib-applehelp\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting sphinxcontrib-serializinghtml\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.1.0,>=2.0.0->-r requirements-dev.txt (line 12)) (28.8.0)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting sphinxcontrib-jsmath\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting packaging\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting alabaster<0.8,>=0.7\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading alabaster-0.7.12-py2.py3-none-any.whl (14 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting snowballstemmer>=1.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting Mako\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting python-editor>=0.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pyjwt>=1.7.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting oauthlib>=3.1.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting tabulate>=0.7.7\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting configparser>=0.3.5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading configparser-4.0.2-py2.py3-none-any.whl (22 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting urllib3<2.0.0,>=1.26.7\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting websocket-client>=0.32.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading websocket_client-0.59.0-py2.py3-none-any.whl (67 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting gitdb<5,>=4.0.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting smmap<5,>=3.0.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting MarkupSafe>=0.23\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading MarkupSafe-1.1.1-cp35-cp35m-manylinux1_x86_64.whl (27 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting importlib-metadata\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading importlib_metadata-2.1.3-py2.py3-none-any.whl (10 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting attrs>=17.4.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pyrsistent>=0.14.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pyrsistent-0.17.3.tar.gz (106 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting certifi>=2017.4.17\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting idna<3,>=2.5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting chardet<5,>=3.0.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting decorator\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting mccabe<0.7.0,>=0.6.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pyflakes<2.4.0,>=2.3.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pycodestyle<2.8.0,>=2.7.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting backcall\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pickleshare\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting jedi>=0.10\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting prompt-toolkit<2.1.0,>=2.0.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading prompt_toolkit-2.0.10-py3-none-any.whl (340 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pexpect\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting parso<0.8.0,>=0.7.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting wcwidth\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting toml\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting typed-ast<1.5.0,>=1.4.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading typed_ast-1.4.3-cp35-cp35m-manylinux1_x86_64.whl (743 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting typing-extensions>=3.7.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting mypy-extensions<0.5.0,>=0.4.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading mypy_extensions-0.4.4.tar.gz (4.2 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Ignoring typing: markers 'python_version < \"3.5\"' don't match your environment\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting jdcal\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading jdcal-1.4.1-py2.py3-none-any.whl (9.5 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting et_xmlfile\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading et_xmlfile-1.0.1.tar.gz (8.4 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting beautifulsoup4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pypandoc\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pypandoc-1.7.4.tar.gz (30 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Installing build dependencies: started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Installing build dependencies: finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Getting requirements to build wheel: started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Getting requirements to build wheel: finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Preparing wheel metadata: started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Preparing wheel metadata: finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pypandoc-1.7.3.tar.gz (30 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Installing build dependencies: started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Installing build dependencies: finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Getting requirements to build wheel: started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Getting requirements to build wheel: finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Preparing wheel metadata: started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Preparing wheel metadata: finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | WARNING: Discarding https://files.pythonhosted.org/packages/55/f3/1b19efde4682fe5d3019d47042512d184268c66bf024aa30e563b8b2a2ab/pypandoc-1.7.3.tar.gz#sha256=4efd2fa8a37d0005dd7d044cb7f42ea9e141df03538750ec5aed17359ba44d47 (from https://pypi.org/simple/pypandoc/). Requested pypandoc from https://files.pythonhosted.org/packages/55/f3/1b19efde4682fe5d3019d47042512d184268c66bf024aa30e563b8b2a2ab/pypandoc-1.7.3.tar.gz#sha256=4efd2fa8a37d0005dd7d044cb7f42ea9e141df03538750ec5aed17359ba44d47 (from -r requirements-dev.txt (line 19)) has different version in metadata: '1.7.2'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pypandoc-1.7.2-py2.py3-none-any.whl (29 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pypandoc-1.7.1-py3-none-any.whl (29 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting py>=1.8.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pathlib2>=2.2.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting iniconfig\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pluggy<1.0,>=0.12\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting zipp>=0.5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Using cached zipp-1.2.0-py2.py3-none-any.whl (4.8 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting coverage>=5.2.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading coverage-5.5-cp35-cp35m-manylinux2010_x86_64.whl (240 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting scipy>=0.17.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting joblib>=0.11\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting soupsieve>1.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading soupsieve-2.1-py3-none-any.whl (32 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting webencodings\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting Werkzeug<2.0,>=0.15\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting itsdangerous<2.0,>=0.24\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting ptyprocess>=0.5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting prometheus-client\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading prometheus_client-0.12.0-py2.py3-none-any.whl (57 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Building wheels for collected packages: databricks-cli, et-xmlfile, pyrsistent, alembic, pyyaml, openpyxl, mypy-extensions\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for databricks-cli (setup.py): started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for databricks-cli (setup.py): finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Created wheel for databricks-cli: filename=databricks_cli-0.17.7-py3-none-any.whl size=143864 sha256=58505252b9e2cc092a2d121734566460c4cc78d84eb5cf14bdfed5773feb96aa\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Stored in directory: /home/runneradmin/.cache/pip/wheels/38/06/21/93150a927930571988ed1a95cbe8d913d22fbd3af5f8eccf06\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for et-xmlfile (setup.py): started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for et-xmlfile (setup.py): finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Created wheel for et-xmlfile: filename=et_xmlfile-1.0.1-py3-none-any.whl size=8916 sha256=448479881ce51e8ff98081d07050e7e9b97fcfb3893a5e38b76c3b56786300f0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Stored in directory: /home/runneradmin/.cache/pip/wheels/bd/08/20/b32a8d2578f2de0b7f64f03e5880238fc3451605bc5bd04525\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for pyrsistent (setup.py): started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for pyrsistent (setup.py): finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Created wheel for pyrsistent: filename=pyrsistent-0.17.3-cp35-cp35m-linux_x86_64.whl size=129075 sha256=1fe0a44db0bcf17177966c3a626ba9c21b8696f03c6c75280609270b10d1e550\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Stored in directory: /home/runneradmin/.cache/pip/wheels/6e/ce/d7/a149c2d007203e74294d9d641ea6a6504a3d71a0540790e452\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for alembic (setup.py): started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for alembic (setup.py): finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158123 sha256=a3136e4f3ba43ae158593b0e1612023bbea5bdeb029a9e60705e0ba622036024\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Stored in directory: /home/runneradmin/.cache/pip/wheels/b6/c2/f1/a01cb44c819cb13ada674d4f7498571aa2b2718a4994bdcde5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for pyyaml (setup.py): started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for pyyaml (setup.py): finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Created wheel for pyyaml: filename=PyYAML-5.3.1-cp35-cp35m-linux_x86_64.whl size=509592 sha256=5892a4a4cefa5e4763ee7cebffe4e9fe485744b8db4a33e32099d0b85f2710b6\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Stored in directory: /home/runneradmin/.cache/pip/wheels/57/d0/2c/e2003abb5bc1a94c2e8a6fe1c03b8055d074e34c13672e7eb7\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for openpyxl (setup.py): started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for openpyxl (setup.py): finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Created wheel for openpyxl: filename=openpyxl-2.6.4-py2.py3-none-any.whl size=245632 sha256=c6afa15f1a3c2aef2bb464e0038561a185b01a3993c4a8f59c53721a41d26373\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Stored in directory: /home/runneradmin/.cache/pip/wheels/04/cc/a1/3fac901c11890ff7bcb68c2dc53824af4b5528d8bbf0fea264\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for mypy-extensions (setup.py): started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for mypy-extensions (setup.py): finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Created wheel for mypy-extensions: filename=mypy_extensions-0.4.4-py2.py3-none-any.whl size=4469 sha256=921623cc6a39074f3f341852bf62f82ef41fa101ead59062929d6f268bd707a8\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Stored in directory: /home/runneradmin/.cache/pip/wheels/26/e2/13/c27b5236e23cfc91586ccc126cbfea0ab429c04e695e7cda22\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Successfully built databricks-cli et-xmlfile pyrsistent alembic pyyaml openpyxl mypy-extensions\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Installing collected packages: zipp, six, ipython-genutils, decorator, traitlets, pyrsistent, pyparsing, MarkupSafe, importlib-metadata, attrs, Werkzeug, webencodings, urllib3, smmap, pytz, packaging, jupyter-core, jsonschema, jinja2, itsdangerous, idna, click, chardet, certifi, websocket-client, wcwidth, toml, testpath, tabulate, sqlalchemy, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, soupsieve, snowballstemmer, requests, python-editor, python-dateutil, pyjwt, pygments, py, ptyprocess, prometheus-client, pluggy, pathlib2, parso, pandocfilters, oauthlib, numpy, nbformat, mistune, Mako, iniconfig, imagesize, gitdb, Flask, entrypoints, docutils, defusedxml, configparser, bleach, babel, alabaster, typing-extensions, typed-ast, sqlparse, sphinx, scipy, retrying, querystring-parser, pyyaml, pytest, pyflakes, pycodestyle, protobuf, prompt-toolkit, prometheus-flask-exporter, pickleshare, pexpect, pandas, nbconvert, mypy-extensions, mccabe, kiwisolver, joblib, jedi, jdcal, gunicorn, gitpython, et-xmlfile, docker, databricks-cli, cycler, coverage, cloudpickle, beautifulsoup4, backcall, alembic, xlrd, scikit-learn, pytest-cov, pypandoc, pydata-sphinx-theme, pyarrow, plotly, openpyxl, numpydoc, nbsphinx, mypy, mlflow, matplotlib, ipython, flake8\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | mypy-extensions 0.4.4 requires typing>=3.5.3, which is not installed.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Successfully installed Flask-1.1.4 Mako-1.1.6 MarkupSafe-1.1.1 Werkzeug-1.0.1 alabaster-0.7.12 alembic-1.4.1 attrs-22.1.0 babel-2.9.1 backcall-0.2.0 beautifulsoup4-4.10.0 bleach-3.3.1 certifi-2021.10.8 chardet-4.0.0 click-7.1.2 cloudpickle-1.6.0 configparser-4.0.2 coverage-5.5 cycler-0.10.0 databricks-cli-0.17.7 decorator-5.1.1 defusedxml-0.7.1 docker-4.4.4 docutils-0.16 entrypoints-0.3 et-xmlfile-1.0.1 flake8-3.9.2 gitdb-4.0.7 gitpython-3.1.14 gunicorn-20.1.0 idna-2.10 imagesize-1.4.1 importlib-metadata-2.1.3 iniconfig-1.1.1 ipython-7.9.0 ipython-genutils-0.2.0 itsdangerous-1.1.0 jdcal-1.4.1 jedi-0.17.2 jinja2-2.11.3 joblib-0.14.1 jsonschema-3.2.0 jupyter-core-4.6.3 kiwisolver-1.1.0 matplotlib-3.0.3 mccabe-0.6.1 mistune-0.8.4 mlflow-1.14.1 mypy-0.910 mypy-extensions-0.4.4 nbconvert-5.6.1 nbformat-5.0.8 nbsphinx-0.7.1 numpy-1.18.5 numpydoc-1.1.0 oauthlib-3.1.0 openpyxl-2.6.4 packaging-20.9 pandas-0.25.3 pandocfilters-1.5.0 parso-0.7.1 pathlib2-2.3.7.post1 pexpect-4.8.0 pickleshare-0.7.5 plotly-4.14.3 pluggy-0.13.1 prometheus-client-0.12.0 prometheus-flask-exporter-0.22.4 prompt-toolkit-2.0.10 protobuf-3.19.6 ptyprocess-0.7.0 py-1.11.0 pyarrow-2.0.0 pycodestyle-2.7.0 pydata-sphinx-theme-0.7.2 pyflakes-2.3.1 pygments-2.11.2 pyjwt-1.7.1 pypandoc-1.7.1 pyparsing-2.4.7 pyrsistent-0.17.3 pytest-6.1.2 pytest-cov-2.12.1 python-dateutil-2.8.2 python-editor-1.0.4 pytz-2023.3 pyyaml-5.3.1 querystring-parser-1.2.4 requests-2.25.1 retrying-1.3.4 scikit-learn-0.22.2.post1 scipy-1.4.1 six-1.16.0 smmap-4.0.0 snowballstemmer-2.2.0 soupsieve-2.1 sphinx-3.0.4 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-1.0.3 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 sqlalchemy-1.3.24 sqlparse-0.4.4 tabulate-0.8.10 testpath-0.6.0 toml-0.10.2 traitlets-4.3.3 typed-ast-1.4.3 typing-extensions-3.10.0.2 urllib3-1.26.9 wcwidth-0.2.6 webencodings-0.5.1 websocket-client-0.59.0 xlrd-1.2.0 zipp-1.2.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | DEPRECATION: Python 3.5 reached the end of its life on September 13th, 2020. Please upgrade your Python as Python 3.5 is no longer maintained. pip 21.0 will drop support for Python 3.5 in January 2021. pip 21.0 will remove support for this functionality.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pandas==0.23.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pandas-0.23.4-cp35-cp35m-manylinux1_x86_64.whl (8.7 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pyarrow==0.16.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pyarrow-0.16.0-cp35-cp35m-manylinux2014_x86_64.whl (63.1 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting pyspark==2.3.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading pyspark-2.3.4.tar.gz (212.3 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: numpy==1.18.5 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (1.18.5)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: pytz>=2011k in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from pandas==0.23.4) (2023.3)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: python-dateutil>=2.5.0 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from pandas==0.23.4) (2.8.2)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: six>=1.0.0 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from pyarrow==0.16.0) (1.16.0)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting py4j==0.10.7\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Building wheels for collected packages: pyspark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for pyspark (setup.py): started\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Building wheel for pyspark (setup.py): finished with status 'done'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Created wheel for pyspark: filename=pyspark-2.3.4-py2.py3-none-any.whl size=212742815 sha256=f2ef6a240d2dda1becd2e88a856bcc44d6c846ce652fa9b36a7b73c9640e4973\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Stored in directory: /home/runneradmin/.cache/pip/wheels/18/3f/7a/1be5b2074ad6db65581066a34184b1223f30b520eb934c5343\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Successfully built pyspark\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Installing collected packages: py4j, pyspark, pyarrow, pandas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Attempting uninstall: pyarrow\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Found existing installation: pyarrow 2.0.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Uninstalling pyarrow-2.0.0:\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |       Successfully uninstalled pyarrow-2.0.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Attempting uninstall: pandas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Found existing installation: pandas 0.25.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Uninstalling pandas-0.25.3:\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |       Successfully uninstalled pandas-0.25.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Successfully installed pandas-0.23.4 py4j-0.10.7 pyarrow-0.16.0 pyspark-2.3.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | DEPRECATION: Python 3.5 reached the end of its life on September 13th, 2020. Please upgrade your Python as Python 3.5 is no longer maintained. pip 21.0 will drop support for Python 3.5 in January 2021. pip 21.0 will remove support for this functionality.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Collecting sphinx<3.0.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Downloading Sphinx-2.4.5-py3-none-any.whl (2.7 MB)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: snowballstemmer>=1.1 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (2.2.0)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: sphinxcontrib-serializinghtml in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (1.1.5)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: imagesize in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (1.4.1)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: requests>=2.5.0 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (2.25.1)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: sphinxcontrib-jsmath in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (1.0.1)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: Pygments>=2.0 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (2.11.2)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: babel!=2.0,>=1.3 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (2.9.1)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: alabaster<0.8,>=0.7 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (0.7.12)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: packaging in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (20.9)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: sphinxcontrib-htmlhelp in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (1.0.3)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: sphinxcontrib-applehelp in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (1.0.2)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (28.8.0)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: sphinxcontrib-devhelp in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (1.0.2)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: docutils<0.18,>=0.12 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (0.16)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: sphinxcontrib-qthelp in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (1.0.3)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: Jinja2>=2.3 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from sphinx<3.0.0) (2.11.3)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: pytz>=2015.7 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from babel!=2.0,>=1.3->sphinx<3.0.0) (2023.3)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: MarkupSafe>=0.23 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from Jinja2>=2.3->sphinx<3.0.0) (1.1.1)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: certifi>=2017.4.17 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from requests>=2.5.0->sphinx<3.0.0) (2021.10.8)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: chardet<5,>=3.0.2 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from requests>=2.5.0->sphinx<3.0.0) (4.0.0)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from requests>=2.5.0->sphinx<3.0.0) (1.26.9)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: idna<3,>=2.5 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from requests>=2.5.0->sphinx<3.0.0) (2.10)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Requirement already satisfied: pyparsing>=2.0.2 in /opt/hostedtoolcache/Python/3.5.10/x64/lib/python3.5/site-packages (from packaging->sphinx<3.0.0) (2.4.7)\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Installing collected packages: sphinx\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   Attempting uninstall: sphinx\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Found existing installation: Sphinx 3.0.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |     Uninstalling Sphinx-3.0.4:\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |       Successfully uninstalled Sphinx-3.0.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Successfully installed sphinx-2.4.5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | DEPRECATION: Python 3.5 reached the end of its life on September 13th, 2020. Please upgrade your Python as Python 3.5 is no longer maintained. pip 21.0 will drop support for Python 3.5 in January 2021. pip 21.0 will remove support for this functionality.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Package                       Version\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | ----------------------------- ------------\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | alabaster                     0.7.12\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | alembic                       1.4.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | attrs                         22.1.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Babel                         2.9.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | backcall                      0.2.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | beautifulsoup4                4.10.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | bleach                        3.3.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | certifi                       2021.10.8\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | chardet                       4.0.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | click                         7.1.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | cloudpickle                   1.6.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | configparser                  4.0.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | coverage                      5.5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | cycler                        0.10.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | databricks-cli                0.17.7\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | decorator                     5.1.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | defusedxml                    0.7.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | docker                        4.4.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | docutils                      0.16\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | entrypoints                   0.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | et-xmlfile                    1.0.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | flake8                        3.9.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Flask                         1.1.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | gitdb                         4.0.7\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | GitPython                     3.1.14\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | gunicorn                      20.1.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | idna                          2.10\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | imagesize                     1.4.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | importlib-metadata            2.1.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | iniconfig                     1.1.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | ipython                       7.9.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | ipython-genutils              0.2.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | itsdangerous                  1.1.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | jdcal                         1.4.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | jedi                          0.17.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Jinja2                        2.11.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | joblib                        0.14.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | jsonschema                    3.2.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | jupyter-core                  4.6.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | kiwisolver                    1.1.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Mako                          1.1.6\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | MarkupSafe                    1.1.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | matplotlib                    3.0.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | mccabe                        0.6.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | mistune                       0.8.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | mlflow                        1.14.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | mypy                          0.910\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | mypy-extensions               0.4.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | nbconvert                     5.6.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | nbformat                      5.0.8\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | nbsphinx                      0.7.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | numpy                         1.18.5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | numpydoc                      1.1.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | oauthlib                      3.1.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | openpyxl                      2.6.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | packaging                     20.9\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pandas                        0.23.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pandocfilters                 1.5.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | parso                         0.7.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pathlib2                      2.3.7.post1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pexpect                       4.8.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pickleshare                   0.7.5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pip                           20.3.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | plotly                        4.14.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pluggy                        0.13.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | prometheus-client             0.12.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | prometheus-flask-exporter     0.22.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | prompt-toolkit                2.0.10\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | protobuf                      3.19.6\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | ptyprocess                    0.7.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | py                            1.11.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | py4j                          0.10.7\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pyarrow                       0.16.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pycodestyle                   2.7.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pydata-sphinx-theme           0.7.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pyflakes                      2.3.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Pygments                      2.11.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | PyJWT                         1.7.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pypandoc                      1.7.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pyparsing                     2.4.7\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pyrsistent                    0.17.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pyspark                       2.3.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pytest                        6.1.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pytest-cov                    2.12.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | python-dateutil               2.8.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | python-editor                 1.0.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pytz                          2023.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | PyYAML                        5.3.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | querystring-parser            1.2.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | requests                      2.25.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | retrying                      1.3.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | scikit-learn                  0.22.2.post1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | scipy                         1.4.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | setuptools                    28.8.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | six                           1.16.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | smmap                         4.0.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | snowballstemmer               2.2.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | soupsieve                     2.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Sphinx                        2.4.5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | sphinxcontrib-applehelp       1.0.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | sphinxcontrib-devhelp         1.0.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | sphinxcontrib-htmlhelp        1.0.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | sphinxcontrib-jsmath          1.0.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | sphinxcontrib-qthelp          1.0.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | sphinxcontrib-serializinghtml 1.1.5\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | SQLAlchemy                    1.3.24\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | sqlparse                      0.4.4\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | tabulate                      0.8.10\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | testpath                      0.6.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | toml                          0.10.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | traitlets                     4.3.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | typed-ast                     1.4.3\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | typing-extensions             3.10.0.2\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | urllib3                       1.26.9\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | wcwidth                       0.2.6\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | webencodings                  0.5.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | websocket-client              0.59.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Werkzeug                      1.0.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | wheel                         0.37.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | xlrd                          1.2.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | zipp                          1.2.0\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2705  Success - Main Install dependencies\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ] \u2b50 Run Main Run tests\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker exec cmd=[bash --noprofile --norc -e -o pipefail /var/run/act/workflow/5] user= workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | starting python compilation test...\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | python compilation succeeded.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | The python -m black command was not found. Skipping black checks for now.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Traceback (most recent call last):\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   File \"<stdin>\", line 1, in <module>\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | ImportError: No module named 'setuptools.extern.packaging'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | downloading pycodestyle from https://raw.githubusercontent.com/PyCQA/pycodestyle/2.4.0/pycodestyle.py...\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | starting pycodestyle test...\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | pycodestyle checks passed.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Traceback (most recent call last):\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   File \"<stdin>\", line 1, in <module>\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | ImportError: No module named 'setuptools.extern.packaging'\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | starting flake8 test...\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | flake8 checks passed.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | starting mypy test...\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | mypy checks passed.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Traceback (most recent call last):\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   File \"<string>\", line 1, in <module>\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | AssertionError: Sphinx buiild requires Python 3.6+, skipping for now.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | all lint-python tests passed!\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:40:29 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | Setting default log level to \"WARN\".\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | ============================= test session starts ==============================\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | platform linux -- Python 3.5.10, pytest-6.1.2, py-1.11.0, pluggy-0.13.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | rootdir: /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/databricks-koalas\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | plugins: cov-2.12.1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | collected 851 items\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | \n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | databricks/koalas/tests/test_categorical.py \r[Stage 0:>                                                          (0 + 3) / 3]\r                                                                                \r......\r[Stage 48:>                                                         (0 + 4) / 4]/tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/databricks-koalas/databricks/koalas/__init__.py:41: FutureWarning: Koalas support for Python 3.5 is deprecated and will be dropped in the future release. At that point, existing Python 3.5 workflows that use Koalas will continue to work without modification, but Python 3.5 users will no longer get access to the latest Koalas features and bugfixes. We recommend that you upgrade to Python 3.6 or newer.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   FutureWarning,\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | WARNING:root:Found pyspark version \"2.3.4\" installed. pyspark>=2.4.0 is recommended.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/databricks-koalas/databricks/koalas/__init__.py:41: FutureWarning: Koalas support for Python 3.5 is deprecated and will be dropped in the future release. At that point, existing Python 3.5 workflows that use Koalas will continue to work without modification, but Python 3.5 users will no longer get access to the latest Koalas features and bugfixes. We recommend that you upgrade to Python 3.6 or newer.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   FutureWarning,\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | WARNING:root:Found pyspark version \"2.3.4\" installed. pyspark>=2.4.0 is recommended.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/databricks-koalas/databricks/koalas/__init__.py:41: FutureWarning: Koalas support for Python 3.5 is deprecated and will be dropped in the future release. At that point, existing Python 3.5 workflows that use Koalas will continue to work without modification, but Python 3.5 users will no longer get access to the latest Koalas features and bugfixes. We recommend that you upgrade to Python 3.6 or newer.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   FutureWarning,\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | WARNING:root:Found pyspark version \"2.3.4\" installed. pyspark>=2.4.0 is recommended.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/databricks-koalas/databricks/koalas/__init__.py:41: FutureWarning: Koalas support for Python 3.5 is deprecated and will be dropped in the future release. At that point, existing Python 3.5 workflows that use Koalas will continue to work without modification, but Python 3.5 users will no longer get access to the latest Koalas features and bugfixes. We recommend that you upgrade to Python 3.6 or newer.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   FutureWarning,\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | WARNING:root:Found pyspark version \"2.3.4\" installed. pyspark>=2.4.0 is recommended.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | \r[Stage 48:=============================>                            (2 + 2) / 4]\r                                                                                \r2023-06-28 13:40:48 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:40:49 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | .2023-06-28 13:40:51 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | ../tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/databricks-koalas/databricks/koalas/__init__.py:41: FutureWarning: Koalas support for Python 3.5 is deprecated and will be dropped in the future release. At that point, existing Python 3.5 workflows that use Koalas will continue to work without modification, but Python 3.5 users will no longer get access to the latest Koalas features and bugfixes. We recommend that you upgrade to Python 3.6 or newer.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   FutureWarning,\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | WARNING:root:Found pyspark version \"2.3.4\" installed. pyspark>=2.4.0 is recommended.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | /tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/databricks-koalas/databricks/koalas/__init__.py:41: FutureWarning: Koalas support for Python 3.5 is deprecated and will be dropped in the future release. At that point, existing Python 3.5 workflows that use Koalas will continue to work without modification, but Python 3.5 users will no longer get access to the latest Koalas features and bugfixes. We recommend that you upgrade to Python 3.6 or newer.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   |   FutureWarning,\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | WARNING:root:Found pyspark version \"2.3.4\" installed. pyspark>=2.4.0 is recommended.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | \r[Stage 109:======================================>                  (4 + 2) / 6]\r                                                                                \r.2023-06-28 13:40:58 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:40:58 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | ...2023-06-28 13:41:06 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | ..2023-06-28 13:41:08 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:08 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | .....         [  2%]\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | databricks/koalas/tests/test_config.py .......                           [  3%]\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | databricks/koalas/tests/test_csv.py 2023-06-28 13:41:14 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:14 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:15 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:15 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:15 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:15 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:16 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:16 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:16 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:17 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:17 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:17 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | \r[Stage 352:>                                                    (0 + 128) / 128]\r                                                                                \r2023-06-28 13:41:18 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:18 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:18 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:19 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:19 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   | 2023-06-28 13:41:20 WARN  WindowExec:66 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u274c  Failure - Main Run tests\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ] Get \"http://%2Fvar%2Frun%2Fdocker.sock/v1.41/containers/60d8d4e2f95f57843c19e288784508497136e272df39e93af208fa216182116f/archive?path=%2Fvar%2Frun%2Fact%2Fworkflow%2Fpathcmd.txt\": context canceled\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ] \u2b50 Run Post actions/setup-java@v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \ud83d\udc33  docker exec cmd=[node /var/run/act/actions/actions-setup-java@v1/dist/cleanup/index.js] user= workdir=\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ]   \u2705  Success - Post actions/setup-java@v1\n[a5b6a0fd-d996-46f8-b524-7687c292c442/PIP (Python, Spark, pandas, PyArrow)  ] \ud83c\udfc1  Job succeeded\n",
        "stderr": "Error: context canceled\n",
        "workflow": "/tmp/ad9c0f7e-1596-11ee-8a50-bb14de238602/databricks-koalas/.github/workflows/master-crawler.yml",
        "build_tool": "pytest",
        "elapsed_time": 631.6338028907776
    }
}